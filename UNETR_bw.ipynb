{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from src.models import UNet_CBAM\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "# from src.models.swincspunetr import SwinCSPUNETR\n",
    "# from src.models.swincspunetr_unet import SwinCSPUNETR_unet\n",
    "# from src.models.swincspunetr3plus import SwinCSPUNETR3plus\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 비율: {0: 0.0, 1: 0.16393442622950818, 2: 0.01639344262295082, 3: 0.2459016393442623, 4: 0.16393442622950818, 5: 0.2459016393442623, 6: 0.16393442622950818}\n",
      "최종 합계: 1.0\n",
      "클래스 비율 리스트: [0.0, 0.16393442622950818, 0.01639344262295082, 0.2459016393442623, 0.16393442622950818, 0.2459016393442623, 0.16393442622950818]\n"
     ]
    }
   ],
   "source": [
    "class_info = {\n",
    "    0: {\"name\": \"background\", \"weight\": 0},  # weight 없음\n",
    "    1: {\"name\": \"apo-ferritin\", \"weight\": 1000},\n",
    "    2: {\"name\": \"beta-amylase\", \"weight\": 100}, # 4130\n",
    "    3: {\"name\": \"beta-galactosidase\", \"weight\": 1500}, #3080\n",
    "    4: {\"name\": \"ribosome\", \"weight\": 1000},\n",
    "    5: {\"name\": \"thyroglobulin\", \"weight\": 1500},\n",
    "    6: {\"name\": \"virus-like-particle\", \"weight\": 1000},\n",
    "}\n",
    "\n",
    "# 가중치에 비례한 비율 계산\n",
    "raw_ratios = {\n",
    "    k: (v[\"weight\"] if v[\"weight\"] is not None else 0.01)  # 가중치 비례, None일 경우 기본값a\n",
    "    for k, v in class_info.items()\n",
    "}\n",
    "total = sum(raw_ratios.values())\n",
    "ratios = {k: v / total for k, v in raw_ratios.items()}\n",
    "\n",
    "# 최종 합계가 1인지 확인\n",
    "final_total = sum(ratios.values())\n",
    "print(\"클래스 비율:\", ratios)\n",
    "print(\"최종 합계:\", final_total)\n",
    "\n",
    "# 비율을 리스트로 변환\n",
    "ratios_list = [ratios[k] for k in sorted(ratios.keys())]\n",
    "print(\"클래스 비율 리스트:\", ratios_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.dataset import create_dataloaders, create_dataloaders_bw\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, NormalizeIntensityd,\n",
    "    Orientationd, CropForegroundd, GaussianSmoothd, ScaleIntensityd,\n",
    "    RandSpatialCropd, RandRotate90d, RandFlipd, RandGaussianNoised,\n",
    "    ToTensord, RandCropByLabelClassesd, RandCropd,RandCropByPosNegLabeld\n",
    ")\n",
    "from monai.transforms import CastToTyped\n",
    "import numpy as np\n",
    "\n",
    "train_img_dir = \"./datasets/train/images\"\n",
    "train_label_dir = \"./datasets/train/labels\"\n",
    "val_img_dir = \"./datasets/val/images\"\n",
    "val_label_dir = \"./datasets/val/labels\"\n",
    "# DATA CONFIG\n",
    "img_size =  96 # Match your patch size\n",
    "img_depth = img_size\n",
    "n_classes = 7\n",
    "batch_size = 16 # 13.8GB GPU memory required for 128x128 img size\n",
    "loader_batch = 1\n",
    "num_samples = batch_size // loader_batch # 한 이미지에서 뽑을 샘플 수\n",
    "num_repeat = 4\n",
    "# MODEL CONFIG\n",
    "num_epochs = 4000\n",
    "lamda = 0.52\n",
    "ce_weight = 0.4\n",
    "lr = 0.001\n",
    "feature_size = 48\n",
    "use_checkpoint = True\n",
    "use_v2 = True\n",
    "drop_rate= 0.25\n",
    "attn_drop_rate = 0.25\n",
    "num_bottleneck = 2\n",
    "# CLASS_WEIGHTS\n",
    "class_weights = None\n",
    "class_weights = torch.tensor([0.0001, 1, 0.001, 1.1, 1, 1.1, 1], dtype=torch.float32)  # 클래스별 가중치\n",
    "sigma = 2.0\n",
    "accumulation_steps = 1\n",
    "# INIT\n",
    "start_epoch = 0\n",
    "best_val_loss = float('inf')\n",
    "best_val_fbeta_score = 0\n",
    "\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    # GaussianSmoothd(\n",
    "    #     keys=[\"image\"],      # 변환을 적용할 키\n",
    "    #     sigma=[sigma, sigma, sigma]  # 각 축(x, y, z)의 시그마 값\n",
    "    #     ),\n",
    "])\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[img_depth, img_size, img_size],\n",
    "        num_classes=n_classes,\n",
    "        num_samples=num_samples, \n",
    "        ratios=ratios_list,\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[1, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 27/27 [00:53<00:00,  1.98s/it]\n",
      "Loading dataset: 100%|██████████| 7/7 [00:00<00:00, 12.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = None, None\n",
    "train_loader, val_loader = create_dataloaders_bw(\n",
    "    train_img_dir, \n",
    "    train_label_dir, \n",
    "    val_img_dir, \n",
    "    val_label_dir, \n",
    "    non_random_transforms = non_random_transforms, \n",
    "    val_non_random_transforms=non_random_transforms,\n",
    "    random_transforms = random_transforms, \n",
    "    batch_size = loader_batch,\n",
    "    num_workers=0,train_num_repeat=num_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://monai.io/model-zoo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import TverskyLoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def loss_fn(loss, class_weights, device):\n",
    "    \"\"\"\n",
    "    Tversky 손실에 클래스별 가중치를 적용하여 최종 스칼라 값을 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        loss: Tversky 손실 텐서 (B, num_classes, H, W, D).\n",
    "        class_weights: 클래스별 가중치 텐서 (num_classes,).\n",
    "        device: 사용할 장치 (예: 'cuda' 또는 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 최종 가중 평균 손실 값 (스칼라).\n",
    "    \"\"\"\n",
    "    # 가중치를 device로 이동\n",
    "    class_weights = class_weights.to(device)\n",
    "\n",
    "    # 클래스 차원에 가중치 적용 (B, num_classes, ...)\n",
    "    class_weights = class_weights.view(1, n_classes, 1, 1, 1)  # [1, num_classes, 1, 1, 1]\n",
    "    weighted_loss = loss * class_weights\n",
    "\n",
    "    # 모든 차원을 평균 내어 스칼라 손실 반환\n",
    "    final_loss = torch.mean(weighted_loss)\n",
    "    return final_loss\n",
    "\n",
    "class DynamicTverskyLoss(TverskyLoss):\n",
    "    def __init__(self, lamda=0.5, **kwargs):\n",
    "        super().__init__(alpha=1 - lamda, beta=lamda, **kwargs)\n",
    "        self.lamda = lamda\n",
    "\n",
    "    def set_lamda(self, lamda):\n",
    "        self.lamda = lamda\n",
    "        self.alpha = 1 - lamda\n",
    "        self.beta = lamda\n",
    "        \n",
    "# criterion = DynamicTverskyLoss(\n",
    "#     lamda=0.5,\n",
    "#     include_background=False,\n",
    "#     reduction=\"mean\",\n",
    "#     softmax=True\n",
    "# )\n",
    "\n",
    "class CombinedCETverskyLoss(nn.Module):\n",
    "    def __init__(self, lamda=0.5, ce_weight=0.5, **kwargs):\n",
    "        super().__init__()\n",
    "        self._lamda = lamda  # lamda 값 저장\n",
    "        self.tversky = DynamicTverskyLoss(lamda=lamda, **kwargs)\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.ce_weight = ce_weight\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        tversky_loss = self.tversky(inputs, targets)\n",
    "        ce_loss = self.ce(inputs, targets)\n",
    "        return self.ce_weight * ce_loss + (1 - self.ce_weight) * tversky_loss\n",
    "    \n",
    "    def set_lamda(self, lamda):\n",
    "        self._lamda = lamda\n",
    "        self.tversky.set_lamda(lamda)\n",
    "    \n",
    "    @property\n",
    "    def lamda(self):\n",
    "        return self._lamda\n",
    "\n",
    "criterion = CombinedCETverskyLoss(\n",
    "    lamda=lamda,\n",
    "    ce_weight=ce_weight,  # CE Loss와 Tversky Loss의 비중을 0.5:0.5로 설정\n",
    "    include_background=False,\n",
    "    reduction=\"mean\",\n",
    "    softmax=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\torch\\nn\\init.py:453: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = UNet_CBAM(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=n_classes,\n",
    "    channels=(32, 64, 128, 256),\n",
    "    strides=(2, 2, 2),\n",
    "    dropout = drop_rate,\n",
    ").to(device)\n",
    "\n",
    "# model = SwinCSPUNETR3plus(\n",
    "#     img_size=(img_depth, img_size, img_size),\n",
    "#     in_channels=1,\n",
    "#     out_channels=n_classes,\n",
    "#     feature_size=feature_size,\n",
    "#     use_checkpoint=True,\n",
    "#     drop_rate = drop_rate,\n",
    "#     attn_drop_rate = attn_drop_rate,\n",
    "#     use_v2 = use_v2,\n",
    "#     n = num_bottleneck,\n",
    "# ).to(device)\n",
    "# Pretrained weights 불러오기\n",
    "# if use_checkpoint:\n",
    "#     pretrain_path = \"./swin_unetr_btcv_segmentation/models/model.pt\"\n",
    "#     weight = torch.load(pretrain_path, map_location=device)\n",
    "\n",
    "#     # 출력 레이어의 키를 제외한 나머지 가중치만 로드\n",
    "#     filtered_weights = {k: v for k, v in weight.items() if \"out.conv.conv\" not in k}\n",
    "\n",
    "#     # strict=False로 로드하여 불일치하는 부분 무시\n",
    "#     model.load_state_dict(filtered_weights, strict=False)\n",
    "#     print(\"Filtered weights loaded successfully. Output layer will be trained from scratch.\")\n",
    "\n",
    "# Load pretrained weights\n",
    "# model.load_from(weights=np.load(config_vit.real_pretrained_path, allow_pickle=True))\n",
    "# TverskyLoss 설정\n",
    "# 사용 예시\n",
    "\n",
    "pretrain_str = \"yes\" if use_checkpoint else \"no\"\n",
    "weight_str = \"weighted\" if class_weights is not None else \"\"\n",
    "\n",
    "# 체크포인트 디렉토리 및 파일 설정\n",
    "checkpoint_base_dir = Path(\"./model_checkpoints\")\n",
    "folder_name = f\"UNET_CBAM_dewbp_{weight_str}_f{feature_size}_d{img_depth}s{img_size}_numb{num_bottleneck}_lr{lr:.0e}_a{lamda:.2f}_b{1-lamda:.2f}_b{batch_size}_r{num_repeat}_ce{ce_weight}_ac{accumulation_steps}\"\n",
    "checkpoint_dir = checkpoint_base_dir / folder_name\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "# 체크포인트 디렉토리 생성\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if checkpoint_dir.exists():\n",
    "    best_model_path = checkpoint_dir / 'best_model.pt'\n",
    "    if best_model_path.exists():\n",
    "        print(f\"기존 best model 발견: {best_model_path}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(best_model_path, map_location=device)\n",
    "            # 체크포인트 내부 키 검증\n",
    "            required_keys = ['model_state_dict', 'optimizer_state_dict', 'epoch', 'best_val_loss']\n",
    "            if all(k in checkpoint for k in required_keys):\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                start_epoch = checkpoint['epoch']\n",
    "                best_val_loss = checkpoint['best_val_loss']\n",
    "                print(\"기존 학습된 가중치를 성공적으로 로드했습니다.\")\n",
    "                checkpoint= None\n",
    "            else:\n",
    "                raise ValueError(\"체크포인트 파일에 필요한 key가 없습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"체크포인트 파일을 로드하는 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 96, 96, 96]) torch.Size([16, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_loader))\n",
    "images, labels = batch[\"image\"], batch[\"label\"]\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpook0612\u001b[0m (\u001b[33mlimbw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Workspace\\czll\\wandb\\run-20250114_161219-qe2z7h28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/limbw/czii_SwinUnetR/runs/qe2z7h28' target=\"_blank\">UNET_CBAM_gauss_noclsweight_weighted_f48_d96s96_numb2_lr1e-03_a0.50_b0.50_b16_r4_ce0.4_ac1</a></strong> to <a href='https://wandb.ai/limbw/czii_SwinUnetR' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/limbw/czii_SwinUnetR' target=\"_blank\">https://wandb.ai/limbw/czii_SwinUnetR</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/limbw/czii_SwinUnetR/runs/qe2z7h28' target=\"_blank\">https://wandb.ai/limbw/czii_SwinUnetR/runs/qe2z7h28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "run_name = folder_name\n",
    "\n",
    "# wandb 초기화\n",
    "wandb.init(\n",
    "    project='czii_UNet',  # 프로젝트 이름 설정\n",
    "    name=run_name,         # 실행(run) 이름 설정\n",
    "    config={\n",
    "        'num_epochs': num_epochs,\n",
    "        'learning_rate': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'lambda': lamda,\n",
    "        \"cross_entropy_weight\": ce_weight,\n",
    "        'feature_size': feature_size,\n",
    "        'img_size': img_size,\n",
    "        'sampling_ratio': ratios_list,\n",
    "        'device': device.type,\n",
    "        \"checkpoint_dir\": str(checkpoint_dir),\n",
    "        \"class_weights\": class_weights.tolist() if class_weights is not None else None,\n",
    "        \"use_checkpoint\": use_checkpoint,\n",
    "        \"drop_rate\": drop_rate,\n",
    "        \"attn_drop_rate\": attn_drop_rate,\n",
    "        \"use_v2\": use_v2,\n",
    "        \"accumulation_steps\": accumulation_steps,\n",
    "        \"num_repeat\": num_repeat,\n",
    "        \"num_bottleneck\": num_bottleneck,\n",
    "        \n",
    "        # 필요한 하이퍼파라미터 추가\n",
    "    }\n",
    ")\n",
    "# 모델을 wandb에 연결\n",
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "    \n",
    "def processing(batch_data, model, criterion, device):\n",
    "    images = batch_data['image'].to(device)  # Input 이미지 (B, 1, 96, 96, 96)\n",
    "    labels = batch_data['label'].to(device)  # 라벨 (B, 96, 96, 96)\n",
    "\n",
    "    labels = labels.squeeze(1)  # (B, 1, 96, 96, 96) → (B, 96, 96, 96)\n",
    "    labels = labels.long()  # 라벨을 정수형으로 변환\n",
    "\n",
    "    # 원핫 인코딩 (B, H, W, D) → (B, num_classes, H, W, D)\n",
    "    \n",
    "    labels_onehot = torch.nn.functional.one_hot(labels, num_classes=n_classes)\n",
    "    labels_onehot = labels_onehot.permute(0, 4, 1, 2, 3).float()  # (B, num_classes, H, W, D)\n",
    "\n",
    "    # 모델 예측\n",
    "    outputs = model(images)  # outputs: (B, num_classes, H, W, D)\n",
    "\n",
    "    # Loss 계산\n",
    "    loss = criterion(outputs, labels_onehot)\n",
    "    # loss = loss_fn(criterion(outputs, labels_onehot),class_weights=class_weights, device=device)\n",
    "    return loss, outputs, labels, outputs.argmax(dim=1)\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, accumulation_steps=4):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    optimizer.zero_grad()  # 그래디언트 초기화\n",
    "    with tqdm(train_loader, desc='Training') as pbar:\n",
    "        for i, batch_data in enumerate(pbar):\n",
    "            # 손실 계산\n",
    "            loss, _, _, _ = processing(batch_data, model, criterion, device)\n",
    "\n",
    "            # 그래디언트를 계산하고 누적\n",
    "            loss = loss / accumulation_steps  # 그래디언트 누적을 위한 스케일링\n",
    "            loss.backward()  # 그래디언트 계산 및 누적\n",
    "            \n",
    "            # 그래디언트 업데이트 (accumulation_steps마다 한 번)\n",
    "            if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
    "                optimizer.step()  # 파라미터 업데이트\n",
    "                optimizer.zero_grad()  # 누적된 그래디언트 초기화\n",
    "            \n",
    "            # 손실값 누적 (스케일링 복구)\n",
    "            epoch_loss += loss.item() * accumulation_steps  # 실제 손실값 반영\n",
    "            pbar.set_postfix(loss=loss.item() * accumulation_steps)  # 실제 손실값 출력\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    wandb.log({'train_epoch_loss': avg_loss, 'epoch': epoch + 1})\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion, device, epoch, calculate_dice_interval):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    class_dice_scores = {i: [] for i in range(n_classes)}\n",
    "    class_f_beta_scores = {i: [] for i in range(n_classes)}\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, desc='Validation') as pbar:\n",
    "            for batch_data in pbar:\n",
    "                loss, _, labels, preds = processing(batch_data, model, criterion, device)\n",
    "                val_loss += loss.item()\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "                # 각 클래스별 Dice 점수 계산\n",
    "                if epoch % calculate_dice_interval == 0:\n",
    "                    for i in range(n_classes):\n",
    "                        pred_i = (preds == i)\n",
    "                        label_i = (labels == i)\n",
    "                        dice_score = (2.0 * torch.sum(pred_i & label_i)) / (torch.sum(pred_i) + torch.sum(label_i) + 1e-8)\n",
    "                        class_dice_scores[i].append(dice_score.item())\n",
    "                        precision = (torch.sum(pred_i & label_i) + 1e-8) / (torch.sum(pred_i) + 1e-8)\n",
    "                        recall = (torch.sum(pred_i & label_i) + 1e-8) / (torch.sum(label_i) + 1e-8)\n",
    "                        f_beta_score = (1 + 4**2) * (precision * recall) / (4**2 * precision + recall + 1e-8)\n",
    "                        class_f_beta_scores[i].append(f_beta_score.item())\n",
    "\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    # 에포크별 평균 손실 로깅\n",
    "    wandb.log({'val_epoch_loss': avg_loss, 'epoch': epoch + 1})\n",
    "    \n",
    "    # 각 클래스별 평균 Dice 점수 출력\n",
    "    if epoch % calculate_dice_interval == 0:\n",
    "        print(\"Validation Dice Score\")\n",
    "        all_classes_dice_scores = []\n",
    "        for i in range(n_classes):\n",
    "            mean_dice = np.mean(class_dice_scores[i])\n",
    "            wandb.log({f'class_{i}_dice_score': mean_dice, 'epoch': epoch + 1})\n",
    "            print(f\"Class {i}: {mean_dice:.4f}\", end=\", \")\n",
    "            if i not in [0, 2]:  # 평균에 포함할 클래스만 추가\n",
    "                all_classes_dice_scores.append(mean_dice)\n",
    "            \n",
    "        print()\n",
    "    if epoch % calculate_dice_interval == 0:\n",
    "        print(\"Validation F-beta Score\")\n",
    "        all_classes_fbeta_scores = []\n",
    "        for i in range(n_classes):\n",
    "            mean_fbeta = np.mean(class_f_beta_scores[i])\n",
    "            wandb.log({f'class_{i}_f_beta_score': mean_fbeta, 'epoch': epoch + 1})\n",
    "            print(f\"Class {i}: {mean_fbeta:.4f}\", end=\", \")\n",
    "            if i not in [0, 2]:  # 평균에 포함할 클래스만 추가\n",
    "                all_classes_fbeta_scores.append(mean_fbeta)\n",
    "                \n",
    "        print()\n",
    "        overall_mean_dice = np.mean(all_classes_dice_scores)\n",
    "        overall_mean_fbeta = np.mean(all_classes_fbeta_scores)\n",
    "        wandb.log({'overall_mean_f_beta_score': overall_mean_fbeta, 'overall_mean_dice_score': overall_mean_dice, 'epoch': epoch + 1})\n",
    "        print(f\"\\nOverall Mean Dice Score: {overall_mean_dice:.4f}\\nOverall Mean F-beta Score: {overall_mean_fbeta:.4f}\\n\")\n",
    "\n",
    "    if overall_mean_fbeta is None:\n",
    "        overall_mean_fbeta = 0\n",
    "\n",
    "    return val_loss / len(val_loader), overall_mean_fbeta\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, \n",
    "    device, start_epoch, best_val_loss, best_val_fbeta_score, calculate_dice_interval=1,\n",
    "    accumulation_steps=4\n",
    "):\n",
    "    \"\"\"\n",
    "    모델을 학습하고 검증하는 함수\n",
    "    Args:\n",
    "        model: 학습할 모델\n",
    "        train_loader: 학습 데이터 로더\n",
    "        val_loader: 검증 데이터 로더\n",
    "        criterion: 손실 함수\n",
    "        optimizer: 최적화 알고리즘\n",
    "        num_epochs: 총 학습 epoch 수\n",
    "        patience: early stopping 기준\n",
    "        device: GPU/CPU 장치\n",
    "        start_epoch: 시작 epoch\n",
    "        best_val_loss: 이전 최적 validation loss\n",
    "        best_val_fbeta_score: 이전 최적 validation f-beta score\n",
    "        calculate_dice_interval: Dice 점수 계산 주기\n",
    "    \"\"\"\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Train One Epoch\n",
    "        train_loss = train_one_epoch(\n",
    "            model=model, \n",
    "            train_loader=train_loader, \n",
    "            criterion=criterion, \n",
    "            optimizer=optimizer, \n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "            accumulation_steps= accumulation_steps\n",
    "        )\n",
    "        \n",
    "        scheduler.step(train_loss)\n",
    "        # Validate One Epoch\n",
    "        val_loss, overall_mean_fbeta_score = validate_one_epoch(\n",
    "            model=model, \n",
    "            val_loader=val_loader, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            epoch=epoch, \n",
    "            calculate_dice_interval=calculate_dice_interval\n",
    "        )\n",
    "\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F-beta: {overall_mean_fbeta_score:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss and overall_mean_fbeta_score > best_val_fbeta_score:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_fbeta_score = overall_mean_fbeta_score\n",
    "            epochs_no_improve = 0\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_fbeta_score': best_val_fbeta_score\n",
    "            }, checkpoint_path)\n",
    "            print(f\"========================================================\")\n",
    "            print(f\"SUPER Best model saved. Loss:{best_val_loss:.4f}, Score:{best_val_fbeta_score:.4f}\")\n",
    "            print(f\"========================================================\")\n",
    "\n",
    "        # Early stopping 조건 체크\n",
    "        if val_loss >= best_val_loss and overall_mean_fbeta_score <= best_val_fbeta_score:\n",
    "            epochs_no_improve += 1\n",
    "        else:\n",
    "            epochs_no_improve = 0\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'last.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_fbeta_score': best_val_fbeta_score\n",
    "            }, checkpoint_path)\n",
    "            break\n",
    "        # if epochs_no_improve % 6 == 0 & epochs_no_improve != 0:\n",
    "        #     # 손실이 개선되지 않았으므로 lambda 감소\n",
    "        #     new_lamda = max(criterion.lamda - 0.01, 0.35)  # 최소값은 0.1로 설정\n",
    "        #     criterion.set_lamda(new_lamda)\n",
    "        #     print(f\"Validation loss did not improve. Reducing lambda to {new_lamda:.4f}\")\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:44<00:00,  1.52s/it, loss=0.62] \n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.27it/s, loss=0.639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9889, Class 1: 0.0006, Class 2: 0.0000, Class 3: 0.0001, Class 4: 0.3049, Class 5: 0.0001, Class 6: 0.0051, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9915, Class 1: 0.0003, Class 2: 0.0000, Class 3: 0.0000, Class 4: 0.3989, Class 5: 0.0001, Class 6: 0.0027, \n",
      "\n",
      "Overall Mean Dice Score: 0.0622\n",
      "Overall Mean F-beta Score: 0.0804\n",
      "\n",
      "Training Loss: 0.8087, Validation Loss: 0.6428, Validation F-beta: 0.0804\n",
      "========================================================\n",
      "SUPER Best model saved. Loss:0.6428, Score:0.0804\n",
      "========================================================\n",
      "Epoch 2/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.13s/it, loss=0.574]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.29it/s, loss=0.611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9862, Class 1: 0.0003, Class 2: 0.0000, Class 3: 0.0404, Class 4: 0.3828, Class 5: 0.0232, Class 6: 0.1384, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9837, Class 1: 0.0002, Class 2: 0.0000, Class 3: 0.0291, Class 4: 0.5844, Class 5: 0.0134, Class 6: 0.1703, \n",
      "\n",
      "Overall Mean Dice Score: 0.1170\n",
      "Overall Mean F-beta Score: 0.1595\n",
      "\n",
      "Training Loss: 0.5965, Validation Loss: 0.6145, Validation F-beta: 0.1595\n",
      "========================================================\n",
      "SUPER Best model saved. Loss:0.6145, Score:0.1595\n",
      "========================================================\n",
      "Epoch 3/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:03<00:00,  1.14s/it, loss=0.53] \n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.28it/s, loss=0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9871, Class 1: 0.0017, Class 2: 0.0000, Class 3: 0.0818, Class 4: 0.4268, Class 5: 0.1211, Class 6: 0.1699, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9840, Class 1: 0.0010, Class 2: 0.0000, Class 3: 0.1203, Class 4: 0.6391, Class 5: 0.0962, Class 6: 0.1549, \n",
      "\n",
      "Overall Mean Dice Score: 0.1603\n",
      "Overall Mean F-beta Score: 0.2023\n",
      "\n",
      "Training Loss: 0.5511, Validation Loss: 0.5979, Validation F-beta: 0.2023\n",
      "========================================================\n",
      "SUPER Best model saved. Loss:0.5979, Score:0.2023\n",
      "========================================================\n",
      "Epoch 4/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:02<00:00,  1.13s/it, loss=0.5]  \n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.29it/s, loss=0.595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9882, Class 1: 0.0101, Class 2: 0.0007, Class 3: 0.1053, Class 4: 0.4368, Class 5: 0.1556, Class 6: 0.1998, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9871, Class 1: 0.0068, Class 2: 0.0004, Class 3: 0.2100, Class 4: 0.5006, Class 5: 0.1608, Class 6: 0.1683, \n",
      "\n",
      "Overall Mean Dice Score: 0.1815\n",
      "Overall Mean F-beta Score: 0.2093\n",
      "\n",
      "Training Loss: 0.5210, Validation Loss: 0.5917, Validation F-beta: 0.2093\n",
      "========================================================\n",
      "SUPER Best model saved. Loss:0.5917, Score:0.2093\n",
      "========================================================\n",
      "Epoch 5/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.12s/it, loss=0.469]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.31it/s, loss=0.587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9888, Class 1: 0.1998, Class 2: 0.0205, Class 3: 0.1377, Class 4: 0.4037, Class 5: 0.1397, Class 6: 0.1387, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9889, Class 1: 0.3334, Class 2: 0.0175, Class 3: 0.1816, Class 4: 0.4869, Class 5: 0.1036, Class 6: 0.1066, \n",
      "\n",
      "Overall Mean Dice Score: 0.2039\n",
      "Overall Mean F-beta Score: 0.2424\n",
      "\n",
      "Training Loss: 0.4983, Validation Loss: 0.5834, Validation F-beta: 0.2424\n",
      "========================================================\n",
      "SUPER Best model saved. Loss:0.5834, Score:0.2424\n",
      "========================================================\n",
      "Epoch 6/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:03<00:00,  1.14s/it, loss=0.452]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.28it/s, loss=0.59] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9887, Class 1: 0.2505, Class 2: 0.0394, Class 3: 0.1203, Class 4: 0.4210, Class 5: 0.1091, Class 6: 0.1260, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9877, Class 1: 0.4441, Class 2: 0.0603, Class 3: 0.1718, Class 4: 0.5333, Class 5: 0.0726, Class 6: 0.0904, \n",
      "\n",
      "Overall Mean Dice Score: 0.2054\n",
      "Overall Mean F-beta Score: 0.2624\n",
      "\n",
      "Training Loss: 0.4748, Validation Loss: 0.5841, Validation F-beta: 0.2624\n",
      "Epoch 7/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.13s/it, loss=0.445]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.31it/s, loss=0.575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9884, Class 1: 0.2618, Class 2: 0.0542, Class 3: 0.1231, Class 4: 0.4427, Class 5: 0.0893, Class 6: 0.1869, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9880, Class 1: 0.4496, Class 2: 0.1022, Class 3: 0.1877, Class 4: 0.5147, Class 5: 0.0551, Class 6: 0.1437, \n",
      "\n",
      "Overall Mean Dice Score: 0.2208\n",
      "Overall Mean F-beta Score: 0.2701\n",
      "\n",
      "Training Loss: 0.4571, Validation Loss: 0.5782, Validation F-beta: 0.2701\n",
      "========================================================\n",
      "SUPER Best model saved. Loss:0.5782, Score:0.2701\n",
      "========================================================\n",
      "Epoch 8/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.12s/it, loss=0.395]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.29it/s, loss=0.583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9885, Class 1: 0.2435, Class 2: 0.0739, Class 3: 0.1210, Class 4: 0.4267, Class 5: 0.1054, Class 6: 0.2568, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9875, Class 1: 0.4843, Class 2: 0.1429, Class 3: 0.2588, Class 4: 0.4608, Class 5: 0.0691, Class 6: 0.2291, \n",
      "\n",
      "Overall Mean Dice Score: 0.2307\n",
      "Overall Mean F-beta Score: 0.3004\n",
      "\n",
      "Training Loss: 0.4443, Validation Loss: 0.5737, Validation F-beta: 0.3004\n",
      "========================================================\n",
      "SUPER Best model saved. Loss:0.5737, Score:0.3004\n",
      "========================================================\n",
      "Epoch 9/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.13s/it, loss=0.426]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.29it/s, loss=0.575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9882, Class 1: 0.2711, Class 2: 0.0630, Class 3: 0.1422, Class 4: 0.3766, Class 5: 0.2470, Class 6: 0.1471, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9871, Class 1: 0.5468, Class 2: 0.1030, Class 3: 0.2076, Class 4: 0.4536, Class 5: 0.1860, Class 6: 0.1067, \n",
      "\n",
      "Overall Mean Dice Score: 0.2368\n",
      "Overall Mean F-beta Score: 0.3001\n",
      "\n",
      "Training Loss: 0.4349, Validation Loss: 0.5747, Validation F-beta: 0.3001\n",
      "Epoch 10/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:04<00:00,  1.15s/it, loss=0.403]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.29it/s, loss=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9893, Class 1: 0.2557, Class 2: 0.0719, Class 3: 0.1075, Class 4: 0.4226, Class 5: 0.0746, Class 6: 0.1924, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9894, Class 1: 0.5150, Class 2: 0.1428, Class 3: 0.1792, Class 4: 0.4727, Class 5: 0.0451, Class 6: 0.1642, \n",
      "\n",
      "Overall Mean Dice Score: 0.2106\n",
      "Overall Mean F-beta Score: 0.2752\n",
      "\n",
      "Training Loss: 0.4265, Validation Loss: 0.5830, Validation F-beta: 0.2752\n",
      "Epoch 11/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:02<00:00,  1.14s/it, loss=0.395]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.30it/s, loss=0.555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9894, Class 1: 0.2813, Class 2: 0.0839, Class 3: 0.1402, Class 4: 0.3728, Class 5: 0.1613, Class 6: 0.2588, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9910, Class 1: 0.5284, Class 2: 0.1767, Class 3: 0.2278, Class 4: 0.3339, Class 5: 0.1055, Class 6: 0.1989, \n",
      "\n",
      "Overall Mean Dice Score: 0.2429\n",
      "Overall Mean F-beta Score: 0.2789\n",
      "\n",
      "Training Loss: 0.4236, Validation Loss: 0.5733, Validation F-beta: 0.2789\n",
      "Epoch 12/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.12s/it, loss=0.39] \n",
      "Validation: 100%|██████████| 21/21 [00:15<00:00,  1.32it/s, loss=0.595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9891, Class 1: 0.2921, Class 2: 0.0778, Class 3: 0.1286, Class 4: 0.3965, Class 5: 0.1153, Class 6: 0.1848, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9893, Class 1: 0.5239, Class 2: 0.1616, Class 3: 0.2294, Class 4: 0.4006, Class 5: 0.0747, Class 6: 0.1448, \n",
      "\n",
      "Overall Mean Dice Score: 0.2235\n",
      "Overall Mean F-beta Score: 0.2747\n",
      "\n",
      "Training Loss: 0.4148, Validation Loss: 0.5790, Validation F-beta: 0.2747\n",
      "Epoch 13/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.13s/it, loss=0.37] \n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.28it/s, loss=0.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9878, Class 1: 0.2834, Class 2: 0.0800, Class 3: 0.1517, Class 4: 0.4512, Class 5: 0.2270, Class 6: 0.1793, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9859, Class 1: 0.5504, Class 2: 0.1648, Class 3: 0.3155, Class 4: 0.5022, Class 5: 0.1767, Class 6: 0.1443, \n",
      "\n",
      "Overall Mean Dice Score: 0.2585\n",
      "Overall Mean F-beta Score: 0.3378\n",
      "\n",
      "Training Loss: 0.4141, Validation Loss: 0.5714, Validation F-beta: 0.3378\n",
      "========================================================\n",
      "SUPER Best model saved. Loss:0.5714, Score:0.3378\n",
      "========================================================\n",
      "Epoch 14/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.13s/it, loss=0.391]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.25it/s, loss=0.603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9892, Class 1: 0.2943, Class 2: 0.0855, Class 3: 0.1323, Class 4: 0.3747, Class 5: 0.1470, Class 6: 0.2275, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9892, Class 1: 0.5362, Class 2: 0.1698, Class 3: 0.2771, Class 4: 0.4006, Class 5: 0.0978, Class 6: 0.1728, \n",
      "\n",
      "Overall Mean Dice Score: 0.2352\n",
      "Overall Mean F-beta Score: 0.2969\n",
      "\n",
      "Training Loss: 0.4085, Validation Loss: 0.5758, Validation F-beta: 0.2969\n",
      "Epoch 15/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.12s/it, loss=0.37] \n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.29it/s, loss=0.547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9894, Class 1: 0.3564, Class 2: 0.0814, Class 3: 0.1269, Class 4: 0.4442, Class 5: 0.1016, Class 6: 0.2086, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9898, Class 1: 0.5691, Class 2: 0.1625, Class 3: 0.2342, Class 4: 0.4791, Class 5: 0.0652, Class 6: 0.1493, \n",
      "\n",
      "Overall Mean Dice Score: 0.2475\n",
      "Overall Mean F-beta Score: 0.2994\n",
      "\n",
      "Training Loss: 0.4111, Validation Loss: 0.5734, Validation F-beta: 0.2994\n",
      "Epoch 16/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [01:59<00:00,  1.11s/it, loss=0.373]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.28it/s, loss=0.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9888, Class 1: 0.2034, Class 2: 0.0691, Class 3: 0.1256, Class 4: 0.3806, Class 5: 0.0790, Class 6: 0.2467, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9888, Class 1: 0.5011, Class 2: 0.1597, Class 3: 0.2740, Class 4: 0.3513, Class 5: 0.0502, Class 6: 0.1800, \n",
      "\n",
      "Overall Mean Dice Score: 0.2071\n",
      "Overall Mean F-beta Score: 0.2713\n",
      "\n",
      "Training Loss: 0.4081, Validation Loss: 0.5885, Validation F-beta: 0.2713\n",
      "Epoch 17/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:02<00:00,  1.13s/it, loss=0.395]\n",
      "Validation: 100%|██████████| 21/21 [00:15<00:00,  1.32it/s, loss=0.618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9892, Class 1: 0.2655, Class 2: 0.0671, Class 3: 0.0812, Class 4: 0.3059, Class 5: 0.0516, Class 6: 0.2724, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9918, Class 1: 0.4887, Class 2: 0.1548, Class 3: 0.1694, Class 4: 0.2612, Class 5: 0.0304, Class 6: 0.2051, \n",
      "\n",
      "Overall Mean Dice Score: 0.1953\n",
      "Overall Mean F-beta Score: 0.2310\n",
      "\n",
      "Training Loss: 0.4061, Validation Loss: 0.5961, Validation F-beta: 0.2310\n",
      "Epoch 18/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [01:59<00:00,  1.11s/it, loss=0.378]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.29it/s, loss=0.599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9889, Class 1: 0.2762, Class 2: 0.0837, Class 3: 0.1578, Class 4: 0.4123, Class 5: 0.1596, Class 6: 0.2635, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9897, Class 1: 0.5109, Class 2: 0.1604, Class 3: 0.3237, Class 4: 0.4082, Class 5: 0.1100, Class 6: 0.2048, \n",
      "\n",
      "Overall Mean Dice Score: 0.2539\n",
      "Overall Mean F-beta Score: 0.3115\n",
      "\n",
      "Training Loss: 0.4068, Validation Loss: 0.5693, Validation F-beta: 0.3115\n",
      "Epoch 19/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [01:59<00:00,  1.11s/it, loss=0.359]\n",
      "Validation: 100%|██████████| 21/21 [00:15<00:00,  1.32it/s, loss=0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9893, Class 1: 0.2957, Class 2: 0.0563, Class 3: 0.1222, Class 4: 0.4648, Class 5: 0.1007, Class 6: 0.2750, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9899, Class 1: 0.5294, Class 2: 0.1311, Class 3: 0.2088, Class 4: 0.4802, Class 5: 0.0628, Class 6: 0.2320, \n",
      "\n",
      "Overall Mean Dice Score: 0.2517\n",
      "Overall Mean F-beta Score: 0.3026\n",
      "\n",
      "Training Loss: 0.4023, Validation Loss: 0.5728, Validation F-beta: 0.3026\n",
      "Epoch 20/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.11s/it, loss=0.394]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.28it/s, loss=0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9894, Class 1: 0.2699, Class 2: 0.0741, Class 3: 0.1356, Class 4: 0.3970, Class 5: 0.0957, Class 6: 0.1977, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9897, Class 1: 0.5535, Class 2: 0.1793, Class 3: 0.2897, Class 4: 0.4038, Class 5: 0.0594, Class 6: 0.1380, \n",
      "\n",
      "Overall Mean Dice Score: 0.2192\n",
      "Overall Mean F-beta Score: 0.2889\n",
      "\n",
      "Training Loss: 0.4048, Validation Loss: 0.5844, Validation F-beta: 0.2889\n",
      "Epoch 21/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.12s/it, loss=0.392]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.31it/s, loss=0.577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9895, Class 1: 0.2958, Class 2: 0.0668, Class 3: 0.0974, Class 4: 0.3741, Class 5: 0.0568, Class 6: 0.2439, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9902, Class 1: 0.5482, Class 2: 0.1537, Class 3: 0.2131, Class 4: 0.3649, Class 5: 0.0336, Class 6: 0.1785, \n",
      "\n",
      "Overall Mean Dice Score: 0.2136\n",
      "Overall Mean F-beta Score: 0.2677\n",
      "\n",
      "Training Loss: 0.3997, Validation Loss: 0.5878, Validation F-beta: 0.2677\n",
      "Epoch 22/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.11s/it, loss=0.327]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.29it/s, loss=0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9895, Class 1: 0.2895, Class 2: 0.0818, Class 3: 0.1547, Class 4: 0.3959, Class 5: 0.1464, Class 6: 0.2780, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9897, Class 1: 0.5120, Class 2: 0.1529, Class 3: 0.3249, Class 4: 0.3906, Class 5: 0.0984, Class 6: 0.2103, \n",
      "\n",
      "Overall Mean Dice Score: 0.2529\n",
      "Overall Mean F-beta Score: 0.3072\n",
      "\n",
      "Training Loss: 0.3999, Validation Loss: 0.5714, Validation F-beta: 0.3072\n",
      "Epoch 23/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.11s/it, loss=0.365]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.30it/s, loss=0.585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9893, Class 1: 0.2226, Class 2: 0.0762, Class 3: 0.1349, Class 4: 0.2930, Class 5: 0.0767, Class 6: 0.2456, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9917, Class 1: 0.5111, Class 2: 0.1340, Class 3: 0.2361, Class 4: 0.2387, Class 5: 0.0460, Class 6: 0.1786, \n",
      "\n",
      "Overall Mean Dice Score: 0.1946\n",
      "Overall Mean F-beta Score: 0.2421\n",
      "\n",
      "Training Loss: 0.3977, Validation Loss: 0.5907, Validation F-beta: 0.2421\n",
      "Epoch 24/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:02<00:00,  1.13s/it, loss=0.357]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.31it/s, loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9890, Class 1: 0.2743, Class 2: 0.0699, Class 3: 0.1285, Class 4: 0.3613, Class 5: 0.0989, Class 6: 0.2959, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9904, Class 1: 0.5377, Class 2: 0.1593, Class 3: 0.2502, Class 4: 0.3336, Class 5: 0.0654, Class 6: 0.2372, \n",
      "\n",
      "Overall Mean Dice Score: 0.2318\n",
      "Overall Mean F-beta Score: 0.2848\n",
      "\n",
      "Training Loss: 0.3968, Validation Loss: 0.5832, Validation F-beta: 0.2848\n",
      "Epoch 25/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.11s/it, loss=0.375]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.28it/s, loss=0.578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9900, Class 1: 0.2498, Class 2: 0.0706, Class 3: 0.1383, Class 4: 0.3029, Class 5: 0.0838, Class 6: 0.2767, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9929, Class 1: 0.4978, Class 2: 0.1385, Class 3: 0.2267, Class 4: 0.2440, Class 5: 0.0506, Class 6: 0.1912, \n",
      "\n",
      "Overall Mean Dice Score: 0.2103\n",
      "Overall Mean F-beta Score: 0.2421\n",
      "\n",
      "Training Loss: 0.3947, Validation Loss: 0.5872, Validation F-beta: 0.2421\n",
      "Epoch 26/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [01:59<00:00,  1.11s/it, loss=0.346]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.31it/s, loss=0.6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9893, Class 1: 0.2479, Class 2: 0.0684, Class 3: 0.1374, Class 4: 0.3335, Class 5: 0.1182, Class 6: 0.3133, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9909, Class 1: 0.5301, Class 2: 0.1542, Class 3: 0.3047, Class 4: 0.2740, Class 5: 0.0761, Class 6: 0.2304, \n",
      "\n",
      "Overall Mean Dice Score: 0.2301\n",
      "Overall Mean F-beta Score: 0.2831\n",
      "\n",
      "Training Loss: 0.3960, Validation Loss: 0.5811, Validation F-beta: 0.2831\n",
      "Epoch 27/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:02<00:00,  1.13s/it, loss=0.375]\n",
      "Validation: 100%|██████████| 21/21 [00:15<00:00,  1.32it/s, loss=0.567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9885, Class 1: 0.2800, Class 2: 0.0757, Class 3: 0.1222, Class 4: 0.3838, Class 5: 0.0759, Class 6: 0.2764, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9885, Class 1: 0.5649, Class 2: 0.1633, Class 3: 0.2772, Class 4: 0.3647, Class 5: 0.0462, Class 6: 0.2422, \n",
      "\n",
      "Overall Mean Dice Score: 0.2277\n",
      "Overall Mean F-beta Score: 0.2990\n",
      "\n",
      "Training Loss: 0.3948, Validation Loss: 0.5802, Validation F-beta: 0.2990\n",
      "Epoch 28/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.12s/it, loss=0.352]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.28it/s, loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9897, Class 1: 0.2735, Class 2: 0.0715, Class 3: 0.1199, Class 4: 0.2043, Class 5: 0.0627, Class 6: 0.3998, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9930, Class 1: 0.5391, Class 2: 0.1521, Class 3: 0.2346, Class 4: 0.1432, Class 5: 0.0387, Class 6: 0.3029, \n",
      "\n",
      "Overall Mean Dice Score: 0.2120\n",
      "Overall Mean F-beta Score: 0.2517\n",
      "\n",
      "Training Loss: 0.3954, Validation Loss: 0.5933, Validation F-beta: 0.2517\n",
      "Epoch 29/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.11s/it, loss=0.384]\n",
      "Validation: 100%|██████████| 21/21 [00:17<00:00,  1.23it/s, loss=0.582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9893, Class 1: 0.2577, Class 2: 0.0824, Class 3: 0.1390, Class 4: 0.2807, Class 5: 0.0680, Class 6: 0.3034, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9923, Class 1: 0.4856, Class 2: 0.1532, Class 3: 0.2536, Class 4: 0.2081, Class 5: 0.0420, Class 6: 0.2395, \n",
      "\n",
      "Overall Mean Dice Score: 0.2098\n",
      "Overall Mean F-beta Score: 0.2457\n",
      "\n",
      "Training Loss: 0.3944, Validation Loss: 0.5877, Validation F-beta: 0.2457\n",
      "Epoch 30/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.11s/it, loss=0.374]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.26it/s, loss=0.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9889, Class 1: 0.2302, Class 2: 0.0786, Class 3: 0.1526, Class 4: 0.2656, Class 5: 0.0844, Class 6: 0.3067, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9910, Class 1: 0.4902, Class 2: 0.1739, Class 3: 0.3247, Class 4: 0.2048, Class 5: 0.0524, Class 6: 0.2303, \n",
      "\n",
      "Overall Mean Dice Score: 0.2079\n",
      "Overall Mean F-beta Score: 0.2605\n",
      "\n",
      "Training Loss: 0.3925, Validation Loss: 0.5888, Validation F-beta: 0.2605\n",
      "Epoch 31/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:00<00:00,  1.11s/it, loss=0.351]\n",
      "Validation: 100%|██████████| 21/21 [00:17<00:00,  1.23it/s, loss=0.584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9890, Class 1: 0.2803, Class 2: 0.0628, Class 3: 0.1221, Class 4: 0.3616, Class 5: 0.0521, Class 6: 0.3250, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9912, Class 1: 0.5467, Class 2: 0.1537, Class 3: 0.2515, Class 4: 0.3202, Class 5: 0.0310, Class 6: 0.2797, \n",
      "\n",
      "Overall Mean Dice Score: 0.2282\n",
      "Overall Mean F-beta Score: 0.2858\n",
      "\n",
      "Training Loss: 0.3902, Validation Loss: 0.5810, Validation F-beta: 0.2858\n",
      "Epoch 32/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 108/108 [02:01<00:00,  1.13s/it, loss=0.378]\n",
      "Validation: 100%|██████████| 21/21 [00:16<00:00,  1.28it/s, loss=0.59] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.9888, Class 1: 0.2642, Class 2: 0.0678, Class 3: 0.1690, Class 4: 0.4108, Class 5: 0.0697, Class 6: 0.3548, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.9901, Class 1: 0.5495, Class 2: 0.1754, Class 3: 0.3306, Class 4: 0.3731, Class 5: 0.0408, Class 6: 0.2993, \n",
      "\n",
      "Overall Mean Dice Score: 0.2537\n",
      "Overall Mean F-beta Score: 0.3187\n",
      "\n",
      "Training Loss: 0.3938, Validation Loss: 0.5753, Validation F-beta: 0.3187\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>class_0_dice_score</td><td>▆▁▃▅▆▅▅▅▅▇▇▆▄▆▇▆▇▆▇▇▇▇▇▆█▇▅▇▇▆▆▆</td></tr><tr><td>class_0_f_beta_score</td><td>▇▁▁▄▅▄▄▄▄▅▇▅▃▅▆▅▇▆▆▅▆▆▇▆█▆▅█▇▆▇▆</td></tr><tr><td>class_1_dice_score</td><td>▁▁▁▁▅▆▆▆▆▆▇▇▇▇█▅▆▆▇▆▇▇▅▆▆▆▆▆▆▆▇▆</td></tr><tr><td>class_1_f_beta_score</td><td>▁▁▁▁▅▆▇▇█▇▇▇███▇▇▇███▇▇█▇███▇▇██</td></tr><tr><td>class_2_dice_score</td><td>▁▁▁▁▃▄▅▇▆▇█▇███▇▆█▆▇▆█▇▇▇▇▇▇█▇▆▇</td></tr><tr><td>class_2_f_beta_score</td><td>▁▁▁▁▂▃▅▇▅▇█▇▇█▇▇▇▇▆█▇▇▆▇▆▇▇▇▇█▇█</td></tr><tr><td>class_3_dice_score</td><td>▁▃▄▅▇▆▆▆▇▅▇▆▇▆▆▆▄█▆▇▅▇▇▆▇▇▆▆▇▇▆█</td></tr><tr><td>class_3_f_beta_score</td><td>▁▂▄▅▅▅▅▆▅▅▆▆█▇▆▇▅█▅▇▆█▆▆▆▇▇▆▆█▆█</td></tr><tr><td>class_4_dice_score</td><td>▄▆▇▇▆▇▇▇▆▇▆▆█▆▇▆▄▇█▆▆▆▃▅▄▄▆▁▃▃▅▇</td></tr><tr><td>class_4_f_beta_score</td><td>▅▇█▆▆▇▆▅▅▆▄▅▆▅▆▄▃▅▆▅▄▄▂▄▂▃▄▁▂▂▃▄</td></tr><tr><td>class_5_dice_score</td><td>▁▂▄▅▅▄▄▄█▃▆▄▇▅▄▃▂▆▄▄▃▅▃▄▃▄▃▃▃▃▂▃</td></tr><tr><td>class_5_f_beta_score</td><td>▁▂▅▇▅▄▃▄█▃▅▄█▅▃▃▂▅▃▃▂▅▃▃▃▄▃▂▃▃▂▃</td></tr><tr><td>class_6_dice_score</td><td>▁▃▄▄▃▃▄▅▄▄▅▄▄▅▅▅▆▆▆▄▅▆▅▆▆▆▆█▆▆▇▇</td></tr><tr><td>class_6_f_beta_score</td><td>▁▅▅▅▃▃▄▆▃▅▆▄▄▅▄▅▆▆▆▄▅▆▅▆▅▆▇█▇▆▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>overall_mean_dice_score</td><td>▁▃▄▅▆▆▇▇▇▆▇▇█▇█▆▆██▇▆█▆▇▆▇▇▆▆▆▇█</td></tr><tr><td>overall_mean_f_beta_score</td><td>▁▃▄▅▅▆▆▇▇▆▆▆█▇▇▆▅▇▇▇▆▇▅▇▅▇▇▆▅▆▇▇</td></tr><tr><td>train_epoch_loss</td><td>█▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_epoch_loss</td><td>█▅▄▃▂▂▂▁▂▂▁▂▁▂▁▃▄▁▁▂▃▁▃▂▃▂▂▃▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>class_0_dice_score</td><td>0.98878</td></tr><tr><td>class_0_f_beta_score</td><td>0.99008</td></tr><tr><td>class_1_dice_score</td><td>0.26419</td></tr><tr><td>class_1_f_beta_score</td><td>0.54955</td></tr><tr><td>class_2_dice_score</td><td>0.06779</td></tr><tr><td>class_2_f_beta_score</td><td>0.1754</td></tr><tr><td>class_3_dice_score</td><td>0.16899</td></tr><tr><td>class_3_f_beta_score</td><td>0.33059</td></tr><tr><td>class_4_dice_score</td><td>0.41082</td></tr><tr><td>class_4_f_beta_score</td><td>0.37311</td></tr><tr><td>class_5_dice_score</td><td>0.06974</td></tr><tr><td>class_5_f_beta_score</td><td>0.04076</td></tr><tr><td>class_6_dice_score</td><td>0.35476</td></tr><tr><td>class_6_f_beta_score</td><td>0.29928</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>overall_mean_dice_score</td><td>0.2537</td></tr><tr><td>overall_mean_f_beta_score</td><td>0.31866</td></tr><tr><td>train_epoch_loss</td><td>0.39382</td></tr><tr><td>val_epoch_loss</td><td>0.57533</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">UNET_CBAM_gauss_noclsweight_weighted_f48_d96s96_numb2_lr1e-03_a0.50_b0.50_b16_r4_ce0.4_ac1</strong> at: <a href='https://wandb.ai/limbw/czii_SwinUnetR/runs/qe2z7h28' target=\"_blank\">https://wandb.ai/limbw/czii_SwinUnetR/runs/qe2z7h28</a><br> View project at: <a href='https://wandb.ai/limbw/czii_SwinUnetR' target=\"_blank\">https://wandb.ai/limbw/czii_SwinUnetR</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250114_161219-qe2z7h28\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    patience=10,\n",
    "    device=device,\n",
    "    start_epoch=start_epoch,\n",
    "    best_val_loss=best_val_loss,\n",
    "    best_val_fbeta_score=best_val_fbeta_score,\n",
    "    calculate_dice_interval=1,\n",
    "    accumulation_steps = accumulation_steps\n",
    "     ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (879943805.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    if:\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:fs6utwyo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cc3ae761af43baae5aca60b5d2e7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>class_0_dice_score</td><td>▁</td></tr><tr><td>class_0_f_beta_score</td><td>▁</td></tr><tr><td>class_1_dice_score</td><td>▁</td></tr><tr><td>class_1_f_beta_score</td><td>▁</td></tr><tr><td>class_2_dice_score</td><td>▁</td></tr><tr><td>class_2_f_beta_score</td><td>▁</td></tr><tr><td>class_3_dice_score</td><td>▁</td></tr><tr><td>class_3_f_beta_score</td><td>▁</td></tr><tr><td>class_4_dice_score</td><td>▁</td></tr><tr><td>class_4_f_beta_score</td><td>▁</td></tr><tr><td>class_5_dice_score</td><td>▁</td></tr><tr><td>class_5_f_beta_score</td><td>▁</td></tr><tr><td>class_6_dice_score</td><td>▁</td></tr><tr><td>class_6_f_beta_score</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>overall_mean_dice_score</td><td>▁</td></tr><tr><td>overall_mean_f_beta_score</td><td>▁</td></tr><tr><td>val_epoch_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>class_0_dice_score</td><td>0.65703</td></tr><tr><td>class_0_f_beta_score</td><td>0.50748</td></tr><tr><td>class_1_dice_score</td><td>0.53332</td></tr><tr><td>class_1_f_beta_score</td><td>0.64703</td></tr><tr><td>class_2_dice_score</td><td>0.00286</td></tr><tr><td>class_2_f_beta_score</td><td>0.02334</td></tr><tr><td>class_3_dice_score</td><td>0.23703</td></tr><tr><td>class_3_f_beta_score</td><td>0.23033</td></tr><tr><td>class_4_dice_score</td><td>0.65487</td></tr><tr><td>class_4_f_beta_score</td><td>0.62525</td></tr><tr><td>class_5_dice_score</td><td>0.47899</td></tr><tr><td>class_5_f_beta_score</td><td>0.51448</td></tr><tr><td>class_6_dice_score</td><td>0.42545</td></tr><tr><td>class_6_f_beta_score</td><td>0.47197</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>overall_mean_dice_score</td><td>0.42708</td></tr><tr><td>overall_mean_f_beta_score</td><td>0.43141</td></tr><tr><td>val_epoch_loss</td><td>0.7152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SwinUNETR96_96_lr0.001_lambda0.52_batch2</strong> at: <a href='https://wandb.ai/waooang/czii_SwinUnetR_val/runs/fs6utwyo' target=\"_blank\">https://wandb.ai/waooang/czii_SwinUnetR_val/runs/fs6utwyo</a><br/> View project at: <a href='https://wandb.ai/waooang/czii_SwinUnetR_val' target=\"_blank\">https://wandb.ai/waooang/czii_SwinUnetR_val</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241219_200219-fs6utwyo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:fs6utwyo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Workspace\\czll\\wandb\\run-20241219_200454-121l7bn3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/waooang/czii_SwinUnetR_val/runs/121l7bn3' target=\"_blank\">SwinUNETR96_96_lr0.001_lambda0.52_batch2</a></strong> to <a href='https://wandb.ai/waooang/czii_SwinUnetR_val' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/waooang/czii_SwinUnetR_val' target=\"_blank\">https://wandb.ai/waooang/czii_SwinUnetR_val</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/waooang/czii_SwinUnetR_val/runs/121l7bn3' target=\"_blank\">https://wandb.ai/waooang/czii_SwinUnetR_val/runs/121l7bn3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n",
      "C:\\Users\\Seungwoo\\AppData\\Local\\Temp\\ipykernel_21000\\1177025787.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrain_path, map_location=device)\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.38it/s, loss=0.865]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.6570, Class 1: 0.5333, Class 2: 0.0029, Class 3: 0.2370, \n",
      "Class 4: 0.6549, Class 5: 0.4790, Class 6: 0.4255, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.5075, Class 1: 0.6470, Class 2: 0.0233, Class 3: 0.2303, \n",
      "Class 4: 0.6252, Class 5: 0.5145, Class 6: 0.4720, \n",
      "Overall Mean Dice Score: 0.4659\n",
      "Overall Mean F-beta Score: 0.4978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, NormalizeIntensityd,\n",
    "    Orientationd, CropForegroundd, GaussianSmoothd, ScaleIntensityd,\n",
    "    RandSpatialCropd, RandRotate90d, RandFlipd, RandGaussianNoised,\n",
    "    ToTensord, RandCropByLabelClassesd\n",
    ")\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR, SwinUNETR\n",
    "from monai.losses import TverskyLoss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from src.dataset.dataset import make_val_dataloader\n",
    "\n",
    "val_img_dir = \"./datasets/val/images\"\n",
    "val_label_dir = \"./datasets/val/labels\"\n",
    "img_depth = 96\n",
    "img_size = 96  # Match your patch size\n",
    "n_classes = 7\n",
    "batch_size = 2 # 13.8GB GPU memory required for 128x128 img size\n",
    "num_samples = batch_size # 한 이미지에서 뽑을 샘플 수\n",
    "loader_batch = 1\n",
    "lamda = 0.52\n",
    "\n",
    "wandb.init(\n",
    "    project='czii_SwinUnetR_val',  # 프로젝트 이름 설정\n",
    "    name='SwinUNETR96_96_lr0.001_lambda0.52_batch2',         # 실행(run) 이름 설정\n",
    "    config={\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': batch_size,\n",
    "        'lambda': lamda,\n",
    "        'img_size': img_size,\n",
    "        'device': 'cuda',\n",
    "        \"checkpoint_dir\": \"./model_checkpoints/SwinUNETR96_96_lr0.001_lambda0.52_batch2\",\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    GaussianSmoothd(\n",
    "        keys=[\"image\"],      # 변환을 적용할 키\n",
    "        sigma=[1.0, 1.0, 1.0]  # 각 축(x, y, z)의 시그마 값\n",
    "        ),\n",
    "])\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[img_depth, img_size, img_size],\n",
    "        num_classes=n_classes,\n",
    "        num_samples=num_samples, \n",
    "        ratios=ratios_list,\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[1, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "])\n",
    "\n",
    "val_loader = make_val_dataloader(\n",
    "    val_img_dir, \n",
    "    val_label_dir, \n",
    "    non_random_transforms = non_random_transforms, \n",
    "    random_transforms = random_transforms, \n",
    "    batch_size = loader_batch,\n",
    "    num_workers=0\n",
    ")\n",
    "criterion = TverskyLoss(\n",
    "    alpha= 1 - lamda,  # FP에 대한 가중치\n",
    "    beta=lamda,       # FN에 대한 가중치\n",
    "    include_background=False,  # 배경 클래스 제외\n",
    "    softmax=True\n",
    ")\n",
    "    \n",
    "    \n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "img_size = 96\n",
    "img_depth = img_size\n",
    "n_classes = 7 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrain_path = \"./model_checkpoints/SwinUNETR96_96_lr0.001_lambda0.52_batch2/best_model.pt\"\n",
    "model = SwinUNETR(\n",
    "    img_size=(img_depth, img_size, img_size),\n",
    "    in_channels=1,\n",
    "    out_channels=n_classes,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n",
    "# Pretrained weights 불러오기\n",
    "checkpoint = torch.load(pretrain_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "val_loss, overall_mean_fbeta_score = validate_one_epoch(\n",
    "    model=model, \n",
    "    val_loader=val_loader, \n",
    "    criterion=criterion, \n",
    "    device=device, \n",
    "    epoch=0, \n",
    "    calculate_dice_interval=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from src.dataset.preprocessing import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import Compose, EnsureChannelFirstd, NormalizeIntensityd, Orientationd, GaussianSmoothd\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import copick\n",
    "\n",
    "import torch\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file written to ./kaggle/working/copick.config\n",
      "file length: 7\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "config_blob = \"\"\"{\n",
    "    \"name\": \"czii_cryoet_mlchallenge_2024\",\n",
    "    \"description\": \"2024 CZII CryoET ML Challenge training data.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "\n",
    "    \"pickable_objects\": [\n",
    "        {\n",
    "            \"name\": \"apo-ferritin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"4V1W\",\n",
    "            \"label\": 1,\n",
    "            \"color\": [  0, 117, 220, 128],\n",
    "            \"radius\": 60,\n",
    "            \"map_threshold\": 0.0418\n",
    "        },\n",
    "        {\n",
    "          \"name\" : \"beta-amylase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"8ZRZ\",\n",
    "            \"label\": 2,\n",
    "            \"color\": [255, 255, 255, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578  \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"beta-galactosidase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6X1Q\",\n",
    "            \"label\": 3,\n",
    "            \"color\": [ 76,   0,  92, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ribosome\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6EK0\",\n",
    "            \"label\": 4,\n",
    "            \"color\": [  0,  92,  49, 128],\n",
    "            \"radius\": 150,\n",
    "            \"map_threshold\": 0.0374\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"thyroglobulin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6SCJ\",\n",
    "            \"label\": 5,\n",
    "            \"color\": [ 43, 206,  72, 128],\n",
    "            \"radius\": 130,\n",
    "            \"map_threshold\": 0.0278\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"virus-like-particle\",\n",
    "            \"is_particle\": true,\n",
    "            \"label\": 6,\n",
    "            \"color\": [255, 204, 153, 128],\n",
    "            \"radius\": 135,\n",
    "            \"map_threshold\": 0.201\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"membrane\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 8,\n",
    "            \"color\": [100, 100, 100, 128]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"background\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 9,\n",
    "            \"color\": [10, 150, 200, 128]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"overlay_root\": \"./kaggle/working/overlay\",\n",
    "\n",
    "    \"overlay_fs_args\": {\n",
    "        \"auto_mkdir\": true\n",
    "    },\n",
    "\n",
    "    \"static_root\": \"./kaggle/input/czii-cryo-et-object-identification/test/static\"\n",
    "}\"\"\"\n",
    "\n",
    "copick_config_path = \"./kaggle/working/copick.config\"\n",
    "preprocessor = Preprocessor(config_blob,copick_config_path=copick_config_path)\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "    GaussianSmoothd(\n",
    "        keys=[\"image\"],      # 변환을 적용할 키\n",
    "        sigma=[1.0, 1.0, 1.0]  # 각 축(x, y, z)의 시그마 값\n",
    "        ),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ship\\Lib\\site-packages\\monai\\utils\\deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "C:\\Users\\Seungwoo\\AppData\\Local\\Temp\\ipykernel_6248\\2937359115.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrain_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "img_size = 96\n",
    "img_depth = img_size\n",
    "n_classes = 7 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrain_path = \"./model_checkpoints/SwinUNETR96_96_lr0.001_lambda0.52_batch2/best_model.pt\"\n",
    "model = SwinUNETR(\n",
    "    img_size=(img_depth, img_size, img_size),\n",
    "    in_channels=1,\n",
    "    out_channels=n_classes,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n",
    "# Pretrained weights 불러오기\n",
    "checkpoint = torch.load(pretrain_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/4 [00:03<?, ?it/s, loss=0.764]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcalculate_dice_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 64\u001b[0m, in \u001b[0;36mvalidate_one_epoch\u001b[1;34m(model, val_loader, criterion, device, epoch, calculate_dice_interval)\u001b[0m\n\u001b[0;32m     61\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# 각 클래스별 Dice 점수 계산\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalculate_dice_interval\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes):\n\u001b[0;32m     66\u001b[0m         pred_i \u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m i)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer modulo by zero"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "val_loss = validate_one_epoch(\n",
    "            model=model, \n",
    "            val_loader=val_loader, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            epoch=1, \n",
    "            calculate_dice_interval=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing volume 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing volume 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing volume 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: submission.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import Compose, NormalizeIntensity\n",
    "import cc3d\n",
    "\n",
    "def dict_to_df(coord_dict, experiment_name):\n",
    "    all_coords = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for label, coords in coord_dict.items():\n",
    "        all_coords.append(coords)\n",
    "        all_labels.extend([label] * len(coords))\n",
    "    \n",
    "    all_coords = np.vstack(all_coords)\n",
    "    df = pd.DataFrame({\n",
    "        'experiment': experiment_name,\n",
    "        'particle_type': all_labels,\n",
    "        'x': all_coords[:, 0],\n",
    "        'y': all_coords[:, 1],\n",
    "        'z': all_coords[:, 2]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "id_to_name = {1: \"apo-ferritin\", \n",
    "              2: \"beta-amylase\",\n",
    "              3: \"beta-galactosidase\", \n",
    "              4: \"ribosome\", \n",
    "              5: \"thyroglobulin\", \n",
    "              6: \"virus-like-particle\"}\n",
    "BLOB_THRESHOLD = 200\n",
    "CERTAINTY_THRESHOLD = 0.05\n",
    "\n",
    "classes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    location_dfs = []  # DataFrame 리스트로 초기화\n",
    "    \n",
    "    for vol_idx, run in enumerate(preprocessor.root.runs):\n",
    "        print(f\"Processing volume {vol_idx + 1}/{len(preprocessor.root.runs)}\")\n",
    "        tomogram = preprocessor.processing(run=run, task=\"task\")\n",
    "        task_files = [{\"image\": tomogram}]\n",
    "        task_ds = CacheDataset(data=task_files, transform=non_random_transforms)\n",
    "        task_loader = DataLoader(task_ds, batch_size=1, num_workers=0)\n",
    "        \n",
    "        for task_data in task_loader:\n",
    "            images = task_data['image'].to(\"cuda\")\n",
    "            outputs = sliding_window_inference(\n",
    "                inputs=images,\n",
    "                roi_size=(96, 96, 96),  # ROI 크기\n",
    "                sw_batch_size=4,\n",
    "                predictor=model.forward,\n",
    "                overlap=0.1,\n",
    "                sw_device=\"cuda\",\n",
    "                device=\"cpu\",\n",
    "                buffer_steps=1,\n",
    "                buffer_dim=-1\n",
    "            )\n",
    "            outputs = outputs.argmax(dim=1).squeeze(0).cpu().numpy()  # 클래스 채널 예측\n",
    "            location = {}  # 좌표 저장용 딕셔너리\n",
    "            for c in classes:\n",
    "                cc = cc3d.connected_components(outputs == c)  # cc3d 라벨링\n",
    "                stats = cc3d.statistics(cc)\n",
    "                zyx = stats['centroids'][1:] * 10.012444  # 스케일 변환\n",
    "                zyx_large = zyx[stats['voxel_counts'][1:] > BLOB_THRESHOLD]  # 크기 필터링\n",
    "                xyz = np.ascontiguousarray(zyx_large[:, ::-1])  # 좌표 스왑 (z, y, x -> x, y, z)\n",
    "\n",
    "                location[id_to_name[c]] = xyz  # ID 이름 매칭 저장\n",
    "\n",
    "            # 데이터프레임 변환\n",
    "            df = dict_to_df(location, run.name)\n",
    "            location_dfs.append(df)  # 리스트에 추가\n",
    "        \n",
    "        # if vol_idx == 2:\n",
    "        #     break\n",
    "    \n",
    "    # DataFrame 병합\n",
    "    final_df = pd.concat(location_dfs, ignore_index=True)\n",
    "    \n",
    "    # ID 추가 및 CSV 저장\n",
    "    final_df.insert(loc=0, column='id', value=np.arange(len(final_df)))\n",
    "    final_df.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Submission saved to: submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
