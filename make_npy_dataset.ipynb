{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_5_4\\Picks\\apo-ferritin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_5_4\\Picks\\curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_5_4\\Picks\\beta-amylase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_5_4\\Picks\\curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_5_4\\Picks\\beta-galactosidase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_5_4\\Picks\\curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_5_4\\Picks\\ribosome.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_5_4\\Picks\\curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_5_4\\Picks\\thyroglobulin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_5_4\\Picks\\curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_5_4\\Picks\\virus-like-particle.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_5_4\\Picks\\curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_69_2\\Picks\\apo-ferritin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_69_2\\Picks\\curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_69_2\\Picks\\beta-amylase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_69_2\\Picks\\curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_69_2\\Picks\\beta-galactosidase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_69_2\\Picks\\curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_69_2\\Picks\\ribosome.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_69_2\\Picks\\curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_69_2\\Picks\\thyroglobulin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_69_2\\Picks\\curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_69_2\\Picks\\virus-like-particle.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_69_2\\Picks\\curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_4\\Picks\\apo-ferritin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_4\\Picks\\curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_4\\Picks\\beta-amylase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_4\\Picks\\curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_4\\Picks\\beta-galactosidase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_4\\Picks\\curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_4\\Picks\\ribosome.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_4\\Picks\\curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_4\\Picks\\thyroglobulin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_4\\Picks\\curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_4\\Picks\\virus-like-particle.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_4\\Picks\\curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_6\\Picks\\apo-ferritin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_6\\Picks\\curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_6\\Picks\\beta-amylase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_6\\Picks\\curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_6\\Picks\\beta-galactosidase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_6\\Picks\\curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_6\\Picks\\ribosome.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_6\\Picks\\curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_6\\Picks\\thyroglobulin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_6\\Picks\\curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_6_6\\Picks\\virus-like-particle.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_6_6\\Picks\\curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_73_6\\Picks\\apo-ferritin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_73_6\\Picks\\curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_73_6\\Picks\\beta-amylase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_73_6\\Picks\\curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_73_6\\Picks\\beta-galactosidase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_73_6\\Picks\\curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_73_6\\Picks\\ribosome.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_73_6\\Picks\\curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_73_6\\Picks\\thyroglobulin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_73_6\\Picks\\curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_73_6\\Picks\\virus-like-particle.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_73_6\\Picks\\curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_86_3\\Picks\\apo-ferritin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_86_3\\Picks\\curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_86_3\\Picks\\beta-amylase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_86_3\\Picks\\curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_86_3\\Picks\\beta-galactosidase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_86_3\\Picks\\curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_86_3\\Picks\\ribosome.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_86_3\\Picks\\curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_86_3\\Picks\\thyroglobulin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_86_3\\Picks\\curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_86_3\\Picks\\virus-like-particle.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_86_3\\Picks\\curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_99_9\\Picks\\apo-ferritin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_99_9\\Picks\\curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_99_9\\Picks\\beta-amylase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_99_9\\Picks\\curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_99_9\\Picks\\beta-galactosidase.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_99_9\\Picks\\curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_99_9\\Picks\\ribosome.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_99_9\\Picks\\curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_99_9\\Picks\\thyroglobulin.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_99_9\\Picks\\curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay\\ExperimentRuns\\TS_99_9\\Picks\\virus-like-particle.json to ./kaggle/working/overlay\\ExperimentRuns\\TS_99_9\\Picks\\curation_0_virus-like-particle.json\n"
     ]
    }
   ],
   "source": [
    "# Make a copick project\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "config_blob = \"\"\"{\n",
    "    \"name\": \"czii_cryoet_mlchallenge_2024\",\n",
    "    \"description\": \"2024 CZII CryoET ML Challenge training data.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "\n",
    "    \"pickable_objects\": [\n",
    "        {\n",
    "            \"name\": \"apo-ferritin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"4V1W\",\n",
    "            \"label\": 1,\n",
    "            \"color\": [  0, 117, 220, 128],\n",
    "            \"radius\": 60,\n",
    "            \"map_threshold\": 0.0418\n",
    "        },\n",
    "        {\n",
    "          \"name\" : \"beta-amylase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"8ZRZ\",\n",
    "            \"label\": 2,\n",
    "            \"color\": [255, 255, 255, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578  \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"beta-galactosidase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6X1Q\",\n",
    "            \"label\": 3,\n",
    "            \"color\": [ 76,   0,  92, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ribosome\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6EK0\",\n",
    "            \"label\": 4,\n",
    "            \"color\": [  0,  92,  49, 128],\n",
    "            \"radius\": 150,\n",
    "            \"map_threshold\": 0.0374\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"thyroglobulin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6SCJ\",\n",
    "            \"label\": 5,\n",
    "            \"color\": [ 43, 206,  72, 128],\n",
    "            \"radius\": 130,\n",
    "            \"map_threshold\": 0.0278\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"virus-like-particle\",\n",
    "            \"is_particle\": true,\n",
    "            \"label\": 6,\n",
    "            \"color\": [255, 204, 153, 128],\n",
    "            \"radius\": 135,\n",
    "            \"map_threshold\": 0.201\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"membrane\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 8,\n",
    "            \"color\": [100, 100, 100, 128]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"background\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 9,\n",
    "            \"color\": [10, 150, 200, 128]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"overlay_root\": \"./kaggle/working/overlay\",\n",
    "\n",
    "    \"overlay_fs_args\": {\n",
    "        \"auto_mkdir\": true\n",
    "    },\n",
    "\n",
    "    \"static_root\": \"./kaggle/input/czii-cryo-et-object-identification/train/static\"\n",
    "}\"\"\"\n",
    "\n",
    "copick_config_path = \"./kaggle/working/copick.config\"\n",
    "output_overlay = \"./kaggle/working/overlay\"\n",
    "\n",
    "\n",
    "with open(copick_config_path, \"w\") as f:\n",
    "    f.write(config_blob)\n",
    "    \n",
    "# Update the overlay\n",
    "# Define source and destination directories\n",
    "source_dir = './kaggle/input/czii-cryo-et-object-identification/train/overlay'\n",
    "destination_dir = './kaggle/working/overlay'\n",
    "\n",
    "# Walk through the source directory\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    # Create corresponding subdirectories in the destination\n",
    "    relative_path = os.path.relpath(root, source_dir)\n",
    "    target_dir = os.path.join(destination_dir, relative_path)\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy and rename each file\n",
    "    for file in files:\n",
    "        if file.startswith(\"curation_0_\"):\n",
    "            new_filename = file\n",
    "        else:\n",
    "            new_filename = f\"curation_0_{file}\"\n",
    "            \n",
    "        \n",
    "        # Define full paths for the source and destination files\n",
    "        source_file = os.path.join(root, file)\n",
    "        destination_file = os.path.join(target_dir, new_filename)\n",
    "        \n",
    "        # Copy the file with the new name\n",
    "        shutil.copy2(source_file, destination_file)\n",
    "        print(f\"Copied {source_file} to {destination_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copick\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = copick.from_file(copick_config_path)\n",
    "\n",
    "copick_user_name = \"copickUtils\"\n",
    "copick_segmentation_name = \"paintedPicks\"\n",
    "voxel_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root.runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.83it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.10it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.13it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from copick_utils.segmentation import segmentation_from_picks\n",
    "import copick_utils.writers.write as write\n",
    "from collections import defaultdict\n",
    "\n",
    "# Just do this once\n",
    "generate_masks = True\n",
    "tomo_type_list = [\"ctfdeconvolved\", \"denoised\", \"isonetcorrected\", \"wbp\"]\n",
    "for tomo_type in tomo_type_list:\n",
    "\n",
    "    if generate_masks:\n",
    "        target_objects = defaultdict(dict)\n",
    "        for object in root.pickable_objects:\n",
    "            if object.is_particle:\n",
    "                target_objects[object.name]['label'] = object.label\n",
    "                target_objects[object.name]['radius'] = object.radius\n",
    "\n",
    "\n",
    "        for run in tqdm(root.runs):\n",
    "            tomo = run.get_voxel_spacing(10)\n",
    "            tomo = tomo.get_tomogram(tomo_type).numpy()\n",
    "            target = np.zeros(tomo.shape, dtype=np.uint8)\n",
    "            for pickable_object in root.pickable_objects:\n",
    "                pick = run.get_picks(object_name=pickable_object.name, user_id=\"curation\")\n",
    "                if len(pick):  \n",
    "                    target = segmentation_from_picks.from_picks(pick[0], \n",
    "                                                                target, \n",
    "                                                                target_objects[pickable_object.name]['radius'] * 0.8,\n",
    "                                                                target_objects[pickable_object.name]['label']\n",
    "                                                                )\n",
    "            write.segmentation(run, target, copick_user_name, name=copick_segmentation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs: 7\n",
      "Processing \"ctfdeconvolved\" data...\n",
      "Saved image: datasets\\train\\images\\ctfdeconvolved_TS_5_4_image.npy\n",
      "Saved label: datasets\\train\\labels\\ctfdeconvolved_TS_5_4_label.npy\n",
      "Saved image: datasets\\train\\images\\ctfdeconvolved_TS_69_2_image.npy\n",
      "Saved label: datasets\\train\\labels\\ctfdeconvolved_TS_69_2_label.npy\n",
      "Saved image: datasets\\train\\images\\ctfdeconvolved_TS_6_4_image.npy\n",
      "Saved label: datasets\\train\\labels\\ctfdeconvolved_TS_6_4_label.npy\n",
      "Saved image: datasets\\train\\images\\ctfdeconvolved_TS_6_6_image.npy\n",
      "Saved label: datasets\\train\\labels\\ctfdeconvolved_TS_6_6_label.npy\n",
      "Saved image: datasets\\train\\images\\ctfdeconvolved_TS_73_6_image.npy\n",
      "Saved label: datasets\\train\\labels\\ctfdeconvolved_TS_73_6_label.npy\n",
      "Saved image: datasets\\train\\images\\ctfdeconvolved_TS_86_3_image.npy\n",
      "Saved label: datasets\\train\\labels\\ctfdeconvolved_TS_86_3_label.npy\n",
      "Saved image: datasets\\val\\images\\ctfdeconvolved_TS_99_9_image.npy\n",
      "Saved label: datasets\\val\\labels\\ctfdeconvolved_TS_99_9_label.npy\n",
      "Processing \"denoised\" data...\n",
      "Saved image: datasets\\train\\images\\denoised_TS_5_4_image.npy\n",
      "Saved label: datasets\\train\\labels\\denoised_TS_5_4_label.npy\n",
      "Saved image: datasets\\train\\images\\denoised_TS_69_2_image.npy\n",
      "Saved label: datasets\\train\\labels\\denoised_TS_69_2_label.npy\n",
      "Saved image: datasets\\train\\images\\denoised_TS_6_4_image.npy\n",
      "Saved label: datasets\\train\\labels\\denoised_TS_6_4_label.npy\n",
      "Saved image: datasets\\train\\images\\denoised_TS_6_6_image.npy\n",
      "Saved label: datasets\\train\\labels\\denoised_TS_6_6_label.npy\n",
      "Saved image: datasets\\train\\images\\denoised_TS_73_6_image.npy\n",
      "Saved label: datasets\\train\\labels\\denoised_TS_73_6_label.npy\n",
      "Saved image: datasets\\train\\images\\denoised_TS_86_3_image.npy\n",
      "Saved label: datasets\\train\\labels\\denoised_TS_86_3_label.npy\n",
      "Saved image: datasets\\val\\images\\denoised_TS_99_9_image.npy\n",
      "Saved label: datasets\\val\\labels\\denoised_TS_99_9_label.npy\n",
      "Processing \"isonetcorrected\" data...\n",
      "Saved image: datasets\\train\\images\\isonetcorrected_TS_5_4_image.npy\n",
      "Saved label: datasets\\train\\labels\\isonetcorrected_TS_5_4_label.npy\n",
      "Saved image: datasets\\train\\images\\isonetcorrected_TS_69_2_image.npy\n",
      "Saved label: datasets\\train\\labels\\isonetcorrected_TS_69_2_label.npy\n",
      "Saved image: datasets\\train\\images\\isonetcorrected_TS_6_4_image.npy\n",
      "Saved label: datasets\\train\\labels\\isonetcorrected_TS_6_4_label.npy\n",
      "Saved image: datasets\\train\\images\\isonetcorrected_TS_6_6_image.npy\n",
      "Saved label: datasets\\train\\labels\\isonetcorrected_TS_6_6_label.npy\n",
      "Saved image: datasets\\train\\images\\isonetcorrected_TS_73_6_image.npy\n",
      "Saved label: datasets\\train\\labels\\isonetcorrected_TS_73_6_label.npy\n",
      "Saved image: datasets\\train\\images\\isonetcorrected_TS_86_3_image.npy\n",
      "Saved label: datasets\\train\\labels\\isonetcorrected_TS_86_3_label.npy\n",
      "Saved image: datasets\\val\\images\\isonetcorrected_TS_99_9_image.npy\n",
      "Saved label: datasets\\val\\labels\\isonetcorrected_TS_99_9_label.npy\n",
      "Processing \"wbp\" data...\n",
      "Saved image: datasets\\train\\images\\wbp_TS_5_4_image.npy\n",
      "Saved label: datasets\\train\\labels\\wbp_TS_5_4_label.npy\n",
      "Saved image: datasets\\train\\images\\wbp_TS_69_2_image.npy\n",
      "Saved label: datasets\\train\\labels\\wbp_TS_69_2_label.npy\n",
      "Saved image: datasets\\train\\images\\wbp_TS_6_4_image.npy\n",
      "Saved label: datasets\\train\\labels\\wbp_TS_6_4_label.npy\n",
      "Saved image: datasets\\train\\images\\wbp_TS_6_6_image.npy\n",
      "Saved label: datasets\\train\\labels\\wbp_TS_6_6_label.npy\n",
      "Saved image: datasets\\train\\images\\wbp_TS_73_6_image.npy\n",
      "Saved label: datasets\\train\\labels\\wbp_TS_73_6_label.npy\n",
      "Saved image: datasets\\train\\images\\wbp_TS_86_3_image.npy\n",
      "Saved label: datasets\\train\\labels\\wbp_TS_86_3_label.npy\n",
      "Saved image: datasets\\val\\images\\wbp_TS_99_9_image.npy\n",
      "Saved label: datasets\\val\\labels\\wbp_TS_99_9_label.npy\n",
      "Number of files in train images: 24\n",
      "Number of files in train labels: 24\n",
      "Number of files in val images: 4\n",
      "Number of files in val labels: 4\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "tomo_type_list = [\"ctfdeconvolved\", \"denoised\", \"isonetcorrected\", \"wbp\"]\n",
    "# Define directories for saving numpy arrays\n",
    "train_image_dir = Path('./datasets/train/images')\n",
    "train_label_dir = Path('./datasets/train/labels')\n",
    "val_image_dir = Path('./datasets/val/images')\n",
    "val_label_dir = Path('./datasets/val/labels')\n",
    "\n",
    "for dir_path in [train_image_dir, train_label_dir, val_image_dir, val_label_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# root.runs의 개수 출력\n",
    "print(f\"Number of runs: {len(root.runs)}\")\n",
    "\n",
    "for tomo_type in tomo_type_list:\n",
    "    print(f\"Processing \\\"{tomo_type}\\\" data...\")\n",
    "    for vol_idx, run in enumerate(root.runs):\n",
    "        # Load image and label data\n",
    "        tomogram = run.get_voxel_spacing(voxel_size).get_tomogram(tomo_type).numpy()\n",
    "        segmentation = run.get_segmentations(\n",
    "            name=copick_segmentation_name,\n",
    "            user_id=copick_user_name,\n",
    "            voxel_size=voxel_size,\n",
    "            is_multilabel=True\n",
    "        )[0].numpy()\n",
    "\n",
    "        # Format run name\n",
    "        run_name = run.name.replace(\"\\\\\", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "        # Determine if this is the last volume\n",
    "        is_last_volume = (vol_idx == len(root.runs) - 1)\n",
    "\n",
    "        # Set directories based on whether it's the last volume\n",
    "        image_dir = val_image_dir if is_last_volume else train_image_dir\n",
    "        label_dir = val_label_dir if is_last_volume else train_label_dir\n",
    "\n",
    "        # Save tomogram and segmentation as numpy arrays\n",
    "        image_path = image_dir / f\"{tomo_type}_{run_name}_image.npy\"\n",
    "        label_path = label_dir / f\"{tomo_type}_{run_name}_label.npy\"\n",
    "        np.save(image_path, tomogram)\n",
    "        np.save(label_path, segmentation)\n",
    "\n",
    "        # 저장된 파일 경로 출력\n",
    "        print(f\"Saved image: {image_path}\")\n",
    "        print(f\"Saved label: {label_path}\")\n",
    "\n",
    "# 저장된 파일의 개수 출력\n",
    "print(f\"Number of files in train images: {len(list(train_image_dir.glob('*.npy')))}\")\n",
    "print(f\"Number of files in train labels: {len(list(train_label_dir.glob('*.npy')))}\")\n",
    "print(f\"Number of files in val images: {len(list(val_image_dir.glob('*.npy')))}\")\n",
    "print(f\"Number of files in val labels: {len(list(val_label_dir.glob('*.npy')))}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "TS_5_4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(184, 630, 630)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copick project\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "config_blob = \"\"\"{\n",
    "    \"name\": \"czii_cryoet_mlchallenge_2024\",\n",
    "    \"description\": \"2024 CZII CryoET ML Challenge training data.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "\n",
    "    \"pickable_objects\": [\n",
    "        {\n",
    "            \"name\": \"apo-ferritin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"4V1W\",\n",
    "            \"label\": 1,\n",
    "            \"color\": [  0, 117, 220, 128],\n",
    "            \"radius\": 60,\n",
    "            \"map_threshold\": 0.0418\n",
    "        },\n",
    "        {\n",
    "          \"name\" : \"beta-amylase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"8ZRZ\",\n",
    "            \"label\": 2,\n",
    "            \"color\": [255, 255, 255, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578  \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"beta-galactosidase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6X1Q\",\n",
    "            \"label\": 3,\n",
    "            \"color\": [ 76,   0,  92, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ribosome\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6EK0\",\n",
    "            \"label\": 4,\n",
    "            \"color\": [  0,  92,  49, 128],\n",
    "            \"radius\": 150,\n",
    "            \"map_threshold\": 0.0374\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"thyroglobulin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6SCJ\",\n",
    "            \"label\": 5,\n",
    "            \"color\": [ 43, 206,  72, 128],\n",
    "            \"radius\": 130,\n",
    "            \"map_threshold\": 0.0278\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"virus-like-particle\",\n",
    "            \"is_particle\": true,\n",
    "            \"label\": 6,\n",
    "            \"color\": [255, 204, 153, 128],\n",
    "            \"radius\": 135,\n",
    "            \"map_threshold\": 0.201\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"membrane\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 8,\n",
    "            \"color\": [100, 100, 100, 128]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"background\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 9,\n",
    "            \"color\": [10, 150, 200, 128]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"overlay_root\": \"./kaggle/working/overlay\",\n",
    "\n",
    "    \"overlay_fs_args\": {\n",
    "        \"auto_mkdir\": true\n",
    "    },\n",
    "\n",
    "    \"static_root\": \"./kaggle/input/czii-cryo-et-object-identification/test/static\"\n",
    "}\"\"\"\n",
    "\n",
    "copick_config_path = \"./kaggle/working/copick.config\"\n",
    "output_overlay = \"./kaggle/working/overlay\"\n",
    "\n",
    "\n",
    "with open(copick_config_path, \"w\") as f:\n",
    "    f.write(config_blob)\n",
    "    \n",
    "import copick\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = copick.from_file(copick_config_path)\n",
    "print(len(root.runs))\n",
    "\n",
    "run = root.runs[0]\n",
    "print(run.name)\n",
    "tomo = run.get_voxel_spacing(10).get_tomogram(\"denoised\").numpy()\n",
    "tomo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"denoised\" data...\n",
      "Saved image: datasets\\task\\images\\denoised_TS_5_4_image.npy\n",
      "Saved image: datasets\\task\\images\\denoised_TS_69_2_image.npy\n",
      "Saved image: datasets\\task\\images\\denoised_TS_6_4_image.npy\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_tomogram'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtomo_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m root\u001b[38;5;241m.\u001b[39mruns:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Load image and label data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     tomogram \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_voxel_spacing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoxel_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tomogram\u001b[49m(tomo_type)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Format run name\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     run_name \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_tomogram'"
     ]
    }
   ],
   "source": [
    "\n",
    "copick_user_name = \"copickUtils\"\n",
    "copick_segmentation_name = \"paintedPicks\"\n",
    "voxel_size = 10\n",
    "tomo_type_list = [\"denoised\"]\n",
    "task_dir = Path('./datasets/task/images')\n",
    "for dir_path in [task_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for tomo_type in tomo_type_list:\n",
    "    print(f\"Processing \\\"{tomo_type}\\\" data...\")\n",
    "    for run in root.runs:\n",
    "        # Load image and label data\n",
    "        tomogram = run.get_voxel_spacing(voxel_size).get_tomogram(tomo_type).numpy()\n",
    "\n",
    "        # Format run name\n",
    "        run_name = run.name.replace(\"\\\\\", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "        # Save tomogram as numpy array\n",
    "        image_path = task_dir / f\"{tomo_type}_{run_name}_image.npy\"\n",
    "        np.save(image_path, tomogram)\n",
    "\n",
    "        # 저장된 파일 경로 출력\n",
    "        print(f\"Saved image: {image_path}\")\n",
    "print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
