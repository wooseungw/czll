{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_thyroglobulin.json\n"
     ]
    }
   ],
   "source": [
    "# Make a copick project\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "config_blob = \"\"\"{\n",
    "    \"name\": \"czii_cryoet_mlchallenge_2024\",\n",
    "    \"description\": \"2024 CZII CryoET ML Challenge training data.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "\n",
    "    \"pickable_objects\": [\n",
    "        {\n",
    "            \"name\": \"apo-ferritin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"4V1W\",\n",
    "            \"label\": 1,\n",
    "            \"color\": [  0, 117, 220, 128],\n",
    "            \"radius\": 60,\n",
    "            \"map_threshold\": 0.0418\n",
    "        },\n",
    "        {\n",
    "          \"name\" : \"beta-amylase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"8ZRZ\",\n",
    "            \"label\": 2,\n",
    "            \"color\": [255, 255, 255, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578  \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"beta-galactosidase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6X1Q\",\n",
    "            \"label\": 3,\n",
    "            \"color\": [ 76,   0,  92, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ribosome\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6EK0\",\n",
    "            \"label\": 4,\n",
    "            \"color\": [  0,  92,  49, 128],\n",
    "            \"radius\": 150,\n",
    "            \"map_threshold\": 0.0374\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"thyroglobulin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6SCJ\",\n",
    "            \"label\": 5,\n",
    "            \"color\": [ 43, 206,  72, 128],\n",
    "            \"radius\": 130,\n",
    "            \"map_threshold\": 0.0278\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"virus-like-particle\",\n",
    "            \"is_particle\": true,\n",
    "            \"label\": 6,\n",
    "            \"color\": [255, 204, 153, 128],\n",
    "            \"radius\": 135,\n",
    "            \"map_threshold\": 0.201\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"membrane\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 8,\n",
    "            \"color\": [100, 100, 100, 128]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"background\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 9,\n",
    "            \"color\": [10, 150, 200, 128]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"overlay_root\": \"./kaggle/working/overlay\",\n",
    "\n",
    "    \"overlay_fs_args\": {\n",
    "        \"auto_mkdir\": true\n",
    "    },\n",
    "\n",
    "    \"static_root\": \"./kaggle/input/czii-cryo-et-object-identification/train/static\"\n",
    "}\"\"\"\n",
    "\n",
    "copick_config_path = \"./kaggle/working/copick.config\"\n",
    "output_overlay = \"./kaggle/working/overlay\"\n",
    "\n",
    "\n",
    "with open(copick_config_path, \"w\") as f:\n",
    "    f.write(config_blob)\n",
    "    \n",
    "# Update the overlay\n",
    "# Define source and destination directories\n",
    "source_dir = './kaggle/input/czii-cryo-et-object-identification/train/overlay'\n",
    "destination_dir = './kaggle/working/overlay'\n",
    "\n",
    "# Walk through the source directory\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    # Create corresponding subdirectories in the destination\n",
    "    relative_path = os.path.relpath(root, source_dir)\n",
    "    target_dir = os.path.join(destination_dir, relative_path)\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy and rename each file\n",
    "    for file in files:\n",
    "        if file.startswith(\"curation_0_\"):\n",
    "            new_filename = file\n",
    "        else:\n",
    "            new_filename = f\"curation_0_{file}\"\n",
    "            \n",
    "        \n",
    "        # Define full paths for the source and destination files\n",
    "        source_file = os.path.join(root, file)\n",
    "        destination_file = os.path.join(target_dir, new_filename)\n",
    "        \n",
    "        # Copy the file with the new name\n",
    "        shutil.copy2(source_file, destination_file)\n",
    "        print(f\"Copied {source_file} to {destination_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/vt4hj2ln3hs6c97_qllsy7lh0000gn/T/ipykernel_17624/1521813977.py:5: DeprecationWarning: config_type not found in config file, defaulting to filesystem\n",
      "  root = copick.from_file(copick_config_path)\n"
     ]
    }
   ],
   "source": [
    "import copick\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = copick.from_file(copick_config_path)\n",
    "\n",
    "copick_user_name = \"copickUtils\"\n",
    "copick_segmentation_name = \"paintedPicks\"\n",
    "voxel_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# from pathlib import Path\n",
    "# from PIL import Image  # For saving PNGs\n",
    "\n",
    "# # Define tomogram types\n",
    "# tomo_tpye_list = [\"ctfdeconvolved\", \"denoised\", \"isonetcorrected\", \"wbp\"]\n",
    "\n",
    "# # Configuration for directories\n",
    "# train_label_dir = Path('./datasets/labels/train')\n",
    "# train_image_dir = Path('./datasets/images/train')\n",
    "# val_label_dir = Path('./datasets/labels/val')\n",
    "# val_image_dir = Path('./datasets/images/val')\n",
    "# metadata_dir = Path('./datasets/metadata')\n",
    "# os.makedirs(metadata_dir, exist_ok=True)\n",
    "\n",
    "# for dir_path in [train_label_dir, train_image_dir, val_label_dir, val_image_dir]:\n",
    "#     dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Parameters\n",
    "# slice_size = (224, 224)  # Patch size\n",
    "# stride = 112             # Stride for slicing\n",
    "\n",
    "# def slice_volume(volume, slice_size, stride):\n",
    "#     \"\"\"\n",
    "#     Slices a 3D volume into 2D patches with the specified size and stride.\n",
    "#     Args:\n",
    "#         volume (np.ndarray): 3D array to slice (D, H, W).\n",
    "#         slice_size (tuple): Size of the 2D slices (height, width).\n",
    "#         stride (int): Stride for slicing.\n",
    "#     Returns:\n",
    "#         slices (list): List of slices with metadata [(z, y, x, patch)].\n",
    "#     \"\"\"\n",
    "#     D, H, W = volume.shape\n",
    "#     patch_h, patch_w = slice_size\n",
    "#     slices = []\n",
    "\n",
    "#     for z in range(D):  # Process each slice independently\n",
    "#         for y in range(0, H - patch_h + 1, stride):\n",
    "#             for x in range(0, W - patch_w + 1, stride):\n",
    "#                 patch = volume[z, y:y + patch_h, x:x + patch_w]\n",
    "#                 slices.append((z, y, x, patch))\n",
    "#     return slices\n",
    "\n",
    "# def save_as_png(volume, save_path):\n",
    "#     \"\"\"\n",
    "#     Save a 2D array as a PNG file.\n",
    "#     Args:\n",
    "#         volume (np.ndarray): 2D array to save.\n",
    "#         save_path (Path): Path to save the PNG file.\n",
    "#     \"\"\"\n",
    "#     volume = ((volume - volume.min()) / (volume.max() - volume.min()) * 255).astype(np.uint8)\n",
    "#     img = Image.fromarray(volume)\n",
    "#     img.save(save_path)\n",
    "    \n",
    "# def save_as_png_without_scaling(volume, save_path):\n",
    "#     \"\"\"\n",
    "#     Save a 2D array as a PNG file without scaling the values.\n",
    "#     Args:\n",
    "#         volume (np.ndarray): 2D array to save.\n",
    "#         save_path (Path): Path to save the PNG file.\n",
    "#     \"\"\"\n",
    "#     # Ensure the volume is in int32 format\n",
    "#     volume = volume.astype(np.int32)\n",
    "    \n",
    "#     # Debug: Check unique values before saving\n",
    "#     print(f\"Unique values before saving: {np.unique(volume)}\")\n",
    "\n",
    "#     # Save as mode=\"I\" to preserve integer values\n",
    "#     img = Image.fromarray(volume, mode=\"I\")\n",
    "#     img.save(save_path)\n",
    "\n",
    "# def process_and_save(data_dict, image_dir, label_dir, metadata_dir, tomo_type, vol_idx):\n",
    "#     \"\"\"\n",
    "#     Processes and saves sliced images and labels as PNGs.\n",
    "#     Args:\n",
    "#         data_dict (dict): Dictionary containing 'image' and 'label'.\n",
    "#         image_dir (Path): Directory to save image slices.\n",
    "#         label_dir (Path): Directory to save label slices.\n",
    "#         metadata_dir (Path): Directory to save metadata.\n",
    "#         tomo_type (str): Tomogram type (for naming).\n",
    "#         vol_idx (int): Volume index (for naming).\n",
    "#     \"\"\"\n",
    "#     image_volume = data_dict[\"image\"]\n",
    "#     label_volume = data_dict[\"label\"]\n",
    "\n",
    "#     # Save original shape metadata\n",
    "#     metadata_file = metadata_dir / f\"{tomo_type}_vol_{vol_idx:03d}_metadata.txt\"\n",
    "#     with open(metadata_file, \"w\") as f:\n",
    "#         f.write(f\"Original shape: {image_volume.shape}\\n\")\n",
    "\n",
    "#     # Slice and save images and labels\n",
    "#     image_slices = slice_volume(image_volume, slice_size, stride)\n",
    "#     label_slices = slice_volume(label_volume, slice_size, stride)\n",
    "    \n",
    "#     for (z_img, y_img, x_img, img_patch), (z_lbl, y_lbl, x_lbl, lbl_patch) in tqdm(\n",
    "#         zip(image_slices, label_slices), desc=f\"Processing {tomo_type} volume {vol_idx}\"\n",
    "#     ):\n",
    "#         # Save image slice\n",
    "#         image_filename = f\"{tomo_type}_vol_{vol_idx:03d}_z{z_img}_y{y_img}_x{x_img}.png\"\n",
    "#         image_save_path = image_dir / image_filename\n",
    "#         save_as_png(img_patch, image_save_path)\n",
    "\n",
    "#         # Save label slice\n",
    "#         label_filename = f\"{tomo_type}_vol_{vol_idx:03d}_z{z_lbl}_y{y_lbl}_x{x_lbl}.png\"\n",
    "#         label_save_path = label_dir / label_filename\n",
    "#         save_as_png_without_scaling(lbl_patch, label_save_path)\n",
    "\n",
    "# # Iterate over all tomogram types\n",
    "# for tomo_type in tomo_tpye_list:\n",
    "#     print(f\"Processing \\\"{tomo_type}\\\" data...\")\n",
    "#     for vol_idx, run in enumerate(root.runs):\n",
    "#         # Load image and label data\n",
    "#         tomogram = run.get_voxel_spacing(voxel_size).get_tomogram(tomo_type).numpy()\n",
    "#         segmentation = run.get_segmentations(\n",
    "#             name=copick_segmentation_name,\n",
    "#             user_id=copick_user_name,\n",
    "#             voxel_size=voxel_size,\n",
    "#             is_multilabel=True\n",
    "#         )[0].numpy()\n",
    "#         print(\"Original segmentation unique values:\", np.unique(segmentation))\n",
    "\n",
    "#         data_dict = {\"image\": tomogram, \"label\": segmentation}\n",
    "\n",
    "#         # Determine dataset type (train/val)\n",
    "#         is_test = (vol_idx == len(root.runs) - 1)\n",
    "#         label_dir = val_label_dir if is_test else train_label_dir\n",
    "#         image_dir = val_image_dir if is_test else train_image_dir\n",
    "\n",
    "#         # Process and save slices\n",
    "#         process_and_save(data_dict, image_dir, label_dir, metadata_dir, tomo_type, vol_idx)\n",
    "\n",
    "# print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dir = Path(image_dir)\n",
    "# label_dir = Path(label_dir) if label_dir else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Collect sorted file paths for images\n",
    "# image_files = sorted(list(image_dir.glob(\"*.png\")))\n",
    "# image_files[:194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"ctfdeconvolved\" data...\n",
      "Processing \"denoised\" data...\n",
      "Processing \"isonetcorrected\" data...\n",
      "Processing \"wbp\" data...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tomo_type_list = [\"ctfdeconvolved\", \"denoised\", \"isonetcorrected\", \"wbp\"]\n",
    "# Define directories for saving numpy arrays\n",
    "train_image_dir = Path('./datasets/train/images')\n",
    "train_label_dir = Path('./datasets/train/labels')\n",
    "val_image_dir = Path('./datasets/val/images')\n",
    "val_label_dir = Path('./datasets/val/labels')\n",
    "\n",
    "for dir_path in [train_image_dir, train_label_dir, val_image_dir, val_label_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for tomo_type in tomo_type_list:\n",
    "    print(f\"Processing \\\"{tomo_type}\\\" data...\")\n",
    "    for vol_idx, run in enumerate(root.runs):\n",
    "        # Load image and label data\n",
    "        tomogram = run.get_voxel_spacing(voxel_size).get_tomogram(tomo_type).numpy()\n",
    "        segmentation = run.get_segmentations(\n",
    "            name=copick_segmentation_name,\n",
    "            user_id=copick_user_name,\n",
    "            voxel_size=voxel_size,\n",
    "            is_multilabel=True\n",
    "        )[0].numpy()\n",
    "\n",
    "        # Format run name\n",
    "        run_name = run.name.replace(\"\\\\\", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "        # Determine if this is the last volume\n",
    "        is_last_volume = (vol_idx == len(root.runs) - 1)\n",
    "\n",
    "        # Set directories based on whether it's the last volume\n",
    "        image_dir = val_image_dir if is_last_volume else train_image_dir\n",
    "        label_dir = val_label_dir if is_last_volume else train_label_dir\n",
    "\n",
    "        # Save tomogram and segmentation as numpy arrays\n",
    "        np.save(image_dir / f\"{tomo_type}_{run_name}_image.npy\", tomogram)\n",
    "        np.save(label_dir / f\"{tomo_type}_{run_name}_label.npy\", segmentation)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from monai.data import DataLoader, Dataset, CacheDataset, decollate_batch\n",
    "import os\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    EnsureChannelFirstd, \n",
    "    Orientationd,  \n",
    "    AsDiscrete,  \n",
    "    RandFlipd, \n",
    "    RandRotate90d, \n",
    "    NormalizeIntensityd,\n",
    "    RandCropByLabelClassesd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"./datasets/train/images\"\n",
    "TRAIN_LABEL_DIR = \"./datasets/train/labels\"\n",
    "VAL_IMG_DIR = \"./datasets/val/images\"\n",
    "VAL_LABEL_DIR = \"./datasets/val/labels\"\n",
    "\n",
    "train_list = os.listdir(TRAIN_IMG_DIR)\n",
    "val_list = os.listdir(VAL_IMG_DIR)\n",
    "train_files = []\n",
    "valid_files = []\n",
    "\n",
    "\n",
    "for name in train_list:\n",
    "    image = np.load(os.path.join(TRAIN_IMG_DIR, f\"{name}\"))    \n",
    "    label = np.load(os.path.join(TRAIN_LABEL_DIR, f\"{name.replace(\"image\", \"label\")}\"))\n",
    "\n",
    "    train_files.append({\"image\": image, \"label\": label})    \n",
    "\n",
    "for name in val_list:\n",
    "    image = np.load(os.path.join(VAL_IMG_DIR, f\"{name}\"))\n",
    "    label = np.load(os.path.join(VAL_LABEL_DIR, f\"{name.replace(\"image\", \"label\")}\"))\n",
    "\n",
    "    valid_files.append({\"image\": image, \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-random transforms to be cached\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"ASR\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "my_num_samples = 1\n",
    "train_batch_size = 1\n",
    "\n",
    "\n",
    "# Random transforms to be applied during training\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[11, 96, 96],\n",
    "        num_classes=7,\n",
    "        num_samples=my_num_samples,\n",
    "        lazy=True,\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = CacheDataset(data=train_files, transform=non_random_transforms, cache_rate=1.0)\n",
    "\n",
    "\n",
    "train_ds = Dataset(data=raw_train_ds, transform=random_transforms)\n",
    "\n",
    "\n",
    "# DataLoader remains the same\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(38708) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(38749) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 배치를 가져옵니다.\n",
    "for batch in train_loader:\n",
    "    # 배치의 입력 데이터와 레이블을 가져옵니다.\n",
    "    x, y = batch['image'], batch['label']\n",
    "    \n",
    "    # 입력 데이터와 레이블의 모양을 출력합니다.\n",
    "    print(f'입력 데이터의 모양: {x.shape}')\n",
    "    print(f'레이블의 모양: {y.shape}')\n",
    "    \n",
    "    # 첫 번째 배치만 확인하면 되므로 break로 루프를 종료합니다.\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 4/4 [00:01<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_valid_ds = CacheDataset(data=valid_files, transform=non_random_transforms, cache_rate=1.0)\n",
    "valid_ds = Dataset(data=raw_valid_ds, transform=random_transforms)\n",
    "valid_batch_size = 1\n",
    "\n",
    "# DataLoader remains the same\n",
    "valid_loader = DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size=valid_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터의 모양: torch.Size([1, 1, 11, 96, 96])\n",
      "레이블의 모양: torch.Size([1, 1, 11, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 배치를 가져옵니다.\n",
    "for batch in valid_loader:\n",
    "    # 배치의 입력 데이터와 레이블을 가져옵니다.\n",
    "    x, y = batch['image'], batch['label']\n",
    "    \n",
    "    # 입력 데이터와 레이블의 모양을 출력합니다.\n",
    "    print(f'입력 데이터의 모양: {x.shape}')\n",
    "    print(f'레이블의 모양: {y.shape}')\n",
    "    \n",
    "    # 첫 번째 배치만 확인하면 되므로 break로 루프를 종료합니다.\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([1, 11, 224, 224])\n",
      "Labels shape: torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from collections import defaultdict\n",
    "\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# class NumpyCryoETDataset(Dataset):\n",
    "#     def __init__(self, data_dir, num_channels=11, slice_size=(224, 224), stride=112, transform=None):\n",
    "#         self.data_dir = Path(data_dir)\n",
    "#         self.num_channels = num_channels\n",
    "#         self.slice_size = slice_size\n",
    "#         self.stride = stride\n",
    "#         self.transform = transform\n",
    "\n",
    "#         # Collect all numpy files\n",
    "#         self.image_files = sorted(list(self.data_dir.glob(\"*_image.npy\")))\n",
    "#         self.label_files = sorted(list(self.data_dir.glob(\"*_label.npy\")))\n",
    "#         assert len(self.image_files) == len(self.label_files), \"Mismatch between image and label files!\"\n",
    "\n",
    "#         # Generate indices for individual patches\n",
    "#         self.data_indices = self._generate_indices()\n",
    "\n",
    "#     def _generate_indices(self):\n",
    "#         \"\"\"Generate indices for individual patches.\"\"\"\n",
    "#         indices = []\n",
    "#         for file_idx, (image_file, label_file) in enumerate(zip(self.image_files, self.label_files)):\n",
    "#             image = np.load(image_file)\n",
    "#             label = np.load(label_file)\n",
    "#             D, H, W = image.shape\n",
    "\n",
    "#             for z in range(self.num_channels // 2, D - self.num_channels // 2):\n",
    "#                 for y in range(0, H - self.slice_size[0] + 1, self.stride):\n",
    "#                     for x in range(0, W - self.slice_size[1] + 1, self.stride):\n",
    "#                         indices.append((file_idx, z, y, x))\n",
    "#         return indices\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data_indices)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         # Retrieve patch index\n",
    "#         file_idx, z, y, x = self.data_indices[idx]\n",
    "\n",
    "#         # Load numpy arrays\n",
    "#         image = np.load(self.image_files[file_idx])\n",
    "#         label = np.load(self.label_files[file_idx])\n",
    "\n",
    "#         # Extract 2.5D patch\n",
    "#         input_patch = image[z - self.num_channels // 2:z + self.num_channels // 2 + 1, y:y + self.slice_size[0], x:x + self.slice_size[1]]\n",
    "#         label_patch = label[z, y:y + self.slice_size[0], x:x + self.slice_size[1]]\n",
    "\n",
    "#         # Apply transformations if provided\n",
    "#         if self.transform:\n",
    "#             input_patch, label_patch = self.transform(input_patch, label_patch)\n",
    "\n",
    "#         # Convert to PyTorch tensors\n",
    "#         input_patch = torch.tensor(input_patch, dtype=torch.float32)\n",
    "#         label_patch = torch.tensor(label_patch, dtype=torch.long)\n",
    "\n",
    "#         return input_patch, label_patch\n",
    "\n",
    "# # Example usage\n",
    "# data_dir = \"./datasets/numpy\"\n",
    "# dataset = NumpyCryoETDataset(data_dir, num_channels=11, slice_size=(224, 224), stride=112)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# for inputs, labels in dataloader:\n",
    "#     print(f\"Inputs shape: {inputs.shape}\")  # (B, num_channels, H, W)\n",
    "#     print(f\"Labels shape: {labels.shape}\")  # (B, H, W)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ship\\Lib\\site-packages\\monai\\networks\\nets\\unet.py:130: UserWarning: `len(strides) > len(channels) - 1`, the last 1 values of strides will not be used.\n",
      "  warnings.warn(f\"`len(strides) > len(channels) - 1`, the last {delta} values of strides will not be used.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 7, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "class UNet2_5D_v2(nn.Module):\n",
    "    def __init__(self, out_channels=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 초기 3D 처리 레이어\n",
    "        self.init_3d = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=(11, 3, 3), padding=(0, 1, 1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 2D UNet\n",
    "        self.unet = UNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=64,  # 3D 컨볼루션 출력 채널\n",
    "            out_channels=out_channels,\n",
    "            channels=(128, 256, 512, 1024),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 1, 11, H, W)\n",
    "        # 3D 처리\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.init_3d(x)  # (batch, 64, 1, H, W)\n",
    "        x = x.squeeze(2)     # (batch, 64, H, W)\n",
    "        \n",
    "        # 2D UNet\n",
    "        return self.unet(x)\n",
    "\n",
    "# 테스트 코드\n",
    "\n",
    "model = UNet2_5D_v2(out_channels=7)\n",
    "x = torch.randn(2, 11, 224, 224)\n",
    "output = model(x)\n",
    "print(f\"Output shape: {output.shape}\")  # Expected: (8, 6, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max label value: 6\n",
      "Num classes (model output): 7\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in dataloader:\n",
    "    print(f\"Max label value: {targets.max().item()}\")\n",
    "    print(f\"Num classes (model output): {output.shape[1]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9693675637245178\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9682437181472778\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9593340754508972\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9628776907920837\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.957891047000885\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9588175415992737\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9568149447441101\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9450807571411133\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9553682208061218\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9506766200065613\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9541364312171936\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9436262249946594\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9527478814125061\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9520754218101501\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9483424425125122\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.951509952545166\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9474872946739197\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.950218141078949\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9328693747520447\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9427644610404968\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.94884192943573\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9487036466598511\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9485341906547546\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9292684197425842\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9464502334594727\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9463152885437012\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9354395270347595\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9466246366500854\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9391736388206482\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9467802047729492\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9352413415908813\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9463583827018738\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9465163350105286\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9306291341781616\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9439311623573303\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9455665946006775\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9459313154220581\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9219071269035339\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9445823431015015\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9450525641441345\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9143122434616089\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.944800078868866\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9453126192092896\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9446495175361633\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9399200081825256\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9435086846351624\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9440208077430725\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9419870376586914\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.943712055683136\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.913151741027832\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9436001181602478\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9436949491500854\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9433645606040955\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.942760169506073\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9397220611572266\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9210411906242371\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9422624707221985\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9427121877670288\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9423731565475464\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9278120398521423\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9419851303100586\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9412870407104492\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9163182377815247\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.900744616985321\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9162211418151855\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.8899073600769043\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9424445033073425\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9412827491760254\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9423909187316895\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9181156754493713\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9425663352012634\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9418400526046753\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9417296648025513\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9421254396438599\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9369994401931763\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9343165755271912\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9391775131225586\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9200354814529419\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9298306703567505\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9407753348350525\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9391264319419861\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9230485558509827\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9115080237388611\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9399765729904175\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.939432680606842\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9397101998329163\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.937552809715271\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9388419389724731\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9368718266487122\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9387164115905762\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.8975980877876282\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.8807440996170044\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9375311136245728\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9365178346633911\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9356737732887268\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.936938464641571\n",
      "Modified Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Outputs shape: torch.Size([1, 7, 224, 224]), Targets shape: torch.Size([1, 1, 224, 224])\n",
      "Loss: 0.9383284449577332\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.losses import DiceLoss\n",
    "from torch import optim\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = DiceLoss(to_onehot_y=True, softmax=True)  # Dice Loss with softmax\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "        # Ensure targets are long integers\n",
    "        targets = targets.long()  # 라벨: (B, H, W)\n",
    "\n",
    "        # Add channel dimension to targets: (B, H, W) -> (B, 1, H, W)\n",
    "        targets = targets.unsqueeze(1)\n",
    "        print(f\"Modified Targets shape: {targets.shape}\")  # (B, 1, H, W)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)  # 모델 출력: (B, 7, H, W)\n",
    "        print(f\"Outputs shape: {outputs.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)  # Dice Loss\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print epoch loss\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the model (U-Net)\n",
    "# class DoubleConv(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(DoubleConv, self).__init__()\n",
    "#         self.double_conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.double_conv(x)\n",
    "\n",
    "\n",
    "# class UNet(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(UNet, self).__init__()\n",
    "#         self.enc1 = DoubleConv(in_channels, 64)\n",
    "#         self.pool1 = nn.MaxPool2d(2)\n",
    "#         self.enc2 = DoubleConv(64, 128)\n",
    "#         self.pool2 = nn.MaxPool2d(2)\n",
    "#         self.enc3 = DoubleConv(128, 256)\n",
    "#         self.pool3 = nn.MaxPool2d(2)\n",
    "#         self.bridge = DoubleConv(256, 512)\n",
    "#         self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "#         self.dec3 = DoubleConv(512, 256)\n",
    "#         self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "#         self.dec2 = DoubleConv(256, 128)\n",
    "#         self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "#         self.dec1 = DoubleConv(128, 64)\n",
    "#         self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         enc1 = self.enc1(x)\n",
    "#         enc2 = self.enc2(self.pool1(enc1))\n",
    "#         enc3 = self.enc3(self.pool2(enc2))\n",
    "#         bridge = self.bridge(self.pool3(enc3))\n",
    "#         dec3 = self.dec3(torch.cat([self.upconv3(bridge), enc3], dim=1))\n",
    "#         dec2 = self.dec2(torch.cat([self.upconv2(dec3), enc2], dim=1))\n",
    "#         dec1 = self.dec1(torch.cat([self.upconv1(dec2), enc1], dim=1))\n",
    "#         return self.out_conv(dec1)\n",
    "\n",
    "\n",
    "# # Instantiate model, loss, and optimizer\n",
    "# model = UNet(in_channels=11, out_channels=2)  # 2 classes for segmentation\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# # Training Loop\n",
    "# for epoch in range(5):  # 5 epochs for demonstration\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, targets in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)  # Forward pass\n",
    "#         loss = criterion(outputs, targets)  # Compute loss\n",
    "#         loss.backward()  # Backpropagation\n",
    "#         optimizer.step()  # Update weights\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(dataloader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
