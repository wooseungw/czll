{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_thyroglobulin.json\n"
     ]
    }
   ],
   "source": [
    "# Make a copick project\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "config_blob = \"\"\"{\n",
    "    \"name\": \"czii_cryoet_mlchallenge_2024\",\n",
    "    \"description\": \"2024 CZII CryoET ML Challenge training data.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "\n",
    "    \"pickable_objects\": [\n",
    "        {\n",
    "            \"name\": \"apo-ferritin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"4V1W\",\n",
    "            \"label\": 1,\n",
    "            \"color\": [  0, 117, 220, 128],\n",
    "            \"radius\": 60,\n",
    "            \"map_threshold\": 0.0418\n",
    "        },\n",
    "        {\n",
    "          \"name\" : \"beta-amylase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"8ZRZ\",\n",
    "            \"label\": 2,\n",
    "            \"color\": [255, 255, 255, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578  \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"beta-galactosidase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6X1Q\",\n",
    "            \"label\": 3,\n",
    "            \"color\": [ 76,   0,  92, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ribosome\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6EK0\",\n",
    "            \"label\": 4,\n",
    "            \"color\": [  0,  92,  49, 128],\n",
    "            \"radius\": 150,\n",
    "            \"map_threshold\": 0.0374\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"thyroglobulin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6SCJ\",\n",
    "            \"label\": 5,\n",
    "            \"color\": [ 43, 206,  72, 128],\n",
    "            \"radius\": 130,\n",
    "            \"map_threshold\": 0.0278\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"virus-like-particle\",\n",
    "            \"is_particle\": true,\n",
    "            \"label\": 6,\n",
    "            \"color\": [255, 204, 153, 128],\n",
    "            \"radius\": 135,\n",
    "            \"map_threshold\": 0.201\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"membrane\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 8,\n",
    "            \"color\": [100, 100, 100, 128]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"background\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 9,\n",
    "            \"color\": [10, 150, 200, 128]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"overlay_root\": \"./kaggle/working/overlay\",\n",
    "\n",
    "    \"overlay_fs_args\": {\n",
    "        \"auto_mkdir\": true\n",
    "    },\n",
    "\n",
    "    \"static_root\": \"./kaggle/input/czii-cryo-et-object-identification/train/static\"\n",
    "}\"\"\"\n",
    "\n",
    "copick_config_path = \"./kaggle/working/copick.config\"\n",
    "output_overlay = \"./kaggle/working/overlay\"\n",
    "\n",
    "\n",
    "with open(copick_config_path, \"w\") as f:\n",
    "    f.write(config_blob)\n",
    "    \n",
    "# Update the overlay\n",
    "# Define source and destination directories\n",
    "source_dir = './kaggle/input/czii-cryo-et-object-identification/train/overlay'\n",
    "destination_dir = './kaggle/working/overlay'\n",
    "\n",
    "# Walk through the source directory\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    # Create corresponding subdirectories in the destination\n",
    "    relative_path = os.path.relpath(root, source_dir)\n",
    "    target_dir = os.path.join(destination_dir, relative_path)\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy and rename each file\n",
    "    for file in files:\n",
    "        if file.startswith(\"curation_0_\"):\n",
    "            new_filename = file\n",
    "        else:\n",
    "            new_filename = f\"curation_0_{file}\"\n",
    "            \n",
    "        \n",
    "        # Define full paths for the source and destination files\n",
    "        source_file = os.path.join(root, file)\n",
    "        destination_file = os.path.join(target_dir, new_filename)\n",
    "        \n",
    "        # Copy the file with the new name\n",
    "        shutil.copy2(source_file, destination_file)\n",
    "        print(f\"Copied {source_file} to {destination_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/vt4hj2ln3hs6c97_qllsy7lh0000gn/T/ipykernel_15094/1521813977.py:5: DeprecationWarning: config_type not found in config file, defaulting to filesystem\n",
      "  root = copick.from_file(copick_config_path)\n"
     ]
    }
   ],
   "source": [
    "import copick\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = copick.from_file(copick_config_path)\n",
    "\n",
    "copick_user_name = \"copickUtils\"\n",
    "copick_segmentation_name = \"paintedPicks\"\n",
    "voxel_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"ctfdeconvolved\" data...\n",
      "Processed volume 0 for \"ctfdeconvolved\" dataset.\n",
      "Processed volume 1 for \"ctfdeconvolved\" dataset.\n",
      "Processed volume 2 for \"ctfdeconvolved\" dataset.\n",
      "Processed volume 3 for \"ctfdeconvolved\" dataset.\n",
      "Processed volume 4 for \"ctfdeconvolved\" dataset.\n",
      "Processed volume 5 for \"ctfdeconvolved\" dataset.\n",
      "Processed volume 6 for \"ctfdeconvolved\" dataset.\n",
      "Processing \"denoised\" data...\n",
      "Processed volume 0 for \"denoised\" dataset.\n",
      "Processed volume 1 for \"denoised\" dataset.\n",
      "Processed volume 2 for \"denoised\" dataset.\n",
      "Processed volume 3 for \"denoised\" dataset.\n",
      "Processed volume 4 for \"denoised\" dataset.\n",
      "Processed volume 5 for \"denoised\" dataset.\n",
      "Processed volume 6 for \"denoised\" dataset.\n",
      "Processing \"isonetcorrected\" data...\n",
      "Processed volume 0 for \"isonetcorrected\" dataset.\n",
      "Processed volume 1 for \"isonetcorrected\" dataset.\n",
      "Processed volume 2 for \"isonetcorrected\" dataset.\n",
      "Processed volume 3 for \"isonetcorrected\" dataset.\n",
      "Processed volume 4 for \"isonetcorrected\" dataset.\n",
      "Processed volume 5 for \"isonetcorrected\" dataset.\n",
      "Processed volume 6 for \"isonetcorrected\" dataset.\n",
      "Processing \"wbp\" data...\n",
      "Processed volume 0 for \"wbp\" dataset.\n",
      "Processed volume 1 for \"wbp\" dataset.\n",
      "Processed volume 2 for \"wbp\" dataset.\n",
      "Processed volume 3 for \"wbp\" dataset.\n",
      "Processed volume 4 for \"wbp\" dataset.\n",
      "Processed volume 5 for \"wbp\" dataset.\n",
      "Processed volume 6 for \"wbp\" dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define tomogram types\n",
    "tomo_tpye_list = [\"ctfdeconvolved\", \"denoised\", \"isonetcorrected\", \"wbp\"]\n",
    "\n",
    "# Configuration for directories\n",
    "train_label_dir = Path('./datasets/labels/train')\n",
    "train_image_dir = Path('./datasets/images/train')\n",
    "val_label_dir = Path('./datasets/labels/val')\n",
    "val_image_dir = Path('./datasets/images/val')\n",
    "\n",
    "for dir_path in [train_label_dir, train_image_dir, val_label_dir, val_image_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Iterate over all tomogram types\n",
    "for tomo_type in tomo_tpye_list:\n",
    "    print(f\"Processing \\\"{tomo_type}\\\" data...\")\n",
    "    for vol_idx, run in enumerate(root.runs):\n",
    "        # Load image and label data\n",
    "        tomogram = run.get_voxel_spacing(voxel_size).get_tomogram(tomo_type).numpy()\n",
    "        segmentation = run.get_segmentations(\n",
    "            name=copick_segmentation_name,\n",
    "            user_id=copick_user_name,\n",
    "            voxel_size=voxel_size,\n",
    "            is_multilabel=True\n",
    "        )[0].numpy()\n",
    "\n",
    "        data_dict = {\"image\": tomogram, \"label\": segmentation}\n",
    "\n",
    "        # Determine dataset type (train/val)\n",
    "        is_test = (vol_idx == len(root.runs) - 1)\n",
    "        label_dir = val_label_dir if is_test else train_label_dir\n",
    "        image_dir = val_image_dir if is_test else train_image_dir\n",
    "\n",
    "        # Save slices for current tomogram type\n",
    "        for slice_idx in range(data_dict[\"image\"].shape[0]):  # Iterate over slices\n",
    "            base_filename = f\"{tomo_type}_vol_{vol_idx:01d}_slice_{slice_idx:03d}\"\n",
    "\n",
    "            # Save label as PNG\n",
    "            label_slice = data_dict[\"label\"][slice_idx]\n",
    "            plt.imsave(label_dir / f\"{base_filename}.png\", label_slice, cmap='gray')\n",
    "\n",
    "            # Normalize and save image\n",
    "            slice_img = data_dict[\"image\"][slice_idx]\n",
    "            norm_img = ((slice_img - slice_img.min()) / (slice_img.max() - slice_img.min()) * 255).astype(np.uint8)\n",
    "            plt.imsave(image_dir / f\"{base_filename}.png\", norm_img, cmap='gray')\n",
    "\n",
    "        print(f\"Processed volume {vol_idx} for \\\"{tomo_type}\\\" dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(image_dir)\n\u001b[1;32m      2\u001b[0m label_dir \u001b[38;5;241m=\u001b[39m Path(label_dir) \u001b[38;5;28;01mif\u001b[39;00m label_dir \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Collect sorted file paths for images\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "image_dir = Path(image_dir)\n",
    "label_dir = Path(label_dir) if label_dir else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Collect sorted file paths for images\n",
    "image_files = sorted(list(image_dir.glob(\"*.png\")))\n",
    "image_files[:194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label shape: torch.Size([630, 630]), Label dtype: torch.float32\n",
      "Label min value: 0.0, Label max value: 255.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "label = Image.open('./datasets/labels/train/ctfdeconvolved_vol_0_slice_000.png').convert('L')\n",
    "label_tensor = torch.Tensor(np.array(label))\n",
    "\n",
    "print(f\"Label min value: {label_tensor.min().item()}, Label max value: {label_tensor.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([2, 11, 224, 224])\n",
      "Labels shape: torch.Size([2, 224, 224])\n",
      "Unique label values: tensor([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "class MultiChannelCryoETDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir=None, num_channels=11, slice_size=(224, 224), stride=112, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.label_dir = Path(label_dir) if label_dir else None\n",
    "        self.num_channels = num_channels\n",
    "        self.slice_size = slice_size\n",
    "        self.stride = stride\n",
    "        self.transform = transform\n",
    "\n",
    "        # 볼륨별 슬라이스 그룹화\n",
    "        self.volume_slices = self._group_slices_by_volume()\n",
    "        self.slices = self._generate_slices()\n",
    "\n",
    "        # 유효 클래스 정의 및 매핑\n",
    "        self.valid_classes = [0, 42, 85, 128, 170, 213, 255]  # 원본 값\n",
    "        self.class_map = {v: i for i, v in enumerate(self.valid_classes)}  # 클래스 매핑\n",
    "\n",
    "    def _group_slices_by_volume(self):\n",
    "        volume_groups = defaultdict(list)\n",
    "        for file_path in sorted(self.image_dir.glob(\"*.png\")):\n",
    "            parts = file_path.stem.split(\"_\")\n",
    "            volume_id = parts[2]  # \"vol_0\"\n",
    "            slice_id = int(parts[4])  # \"slice_001\"\n",
    "            volume_groups[volume_id].append((slice_id, file_path))\n",
    "        for key in volume_groups:\n",
    "            volume_groups[key] = sorted(volume_groups[key], key=lambda x: x[0])\n",
    "        return volume_groups\n",
    "\n",
    "    def _generate_slices(self):\n",
    "        slices = []\n",
    "        for volume_id, slice_list in self.volume_slices.items():\n",
    "            for i in range(0, len(slice_list) - self.num_channels + 1):\n",
    "                slice_range = slice_list[i:i + self.num_channels]\n",
    "                slices.append({\"volume_id\": volume_id, \"slice_range\": slice_range})\n",
    "        return slices\n",
    "\n",
    "    def _extract_patches(self, image, size, stride):\n",
    "        \"\"\"이미지에서 슬라이싱된 패치들을 추출\"\"\"\n",
    "        patches = []\n",
    "        h, w = image.shape\n",
    "        ph, pw = size\n",
    "        for y in range(0, h - ph + 1, stride):\n",
    "            for x in range(0, w - pw + 1, stride):\n",
    "                patches.append(image[y:y + ph, x:x + pw])\n",
    "        return patches\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        slice_info = self.slices[idx]\n",
    "        slice_range = slice_info[\"slice_range\"]\n",
    "\n",
    "        # 다채널 이미지 생성\n",
    "        channels = []\n",
    "        for _, file_path in slice_range:\n",
    "            img = np.array(Image.open(file_path).convert(\"L\"), dtype=np.float32)\n",
    "            channels.append(img)\n",
    "\n",
    "        # 다채널 입력 이미지 생성\n",
    "        input_image = np.stack(channels, axis=0)  # (num_channels, H, W)\n",
    "\n",
    "        # 슬라이싱\n",
    "        input_patches = self._extract_patches(input_image, self.slice_size, self.stride)\n",
    "\n",
    "        # 라벨 처리\n",
    "        if self.label_dir:\n",
    "            label_path = self.label_dir / slice_range[0][1].name\n",
    "            label = np.array(Image.open(label_path), dtype=np.int64)\n",
    "\n",
    "            # 슬라이싱\n",
    "            label_patches = self._extract_patches(label, self.slice_size, self.stride)\n",
    "\n",
    "            # 클래스 매핑\n",
    "            label_patches = [self._remap_labels(patch) for patch in label_patches]\n",
    "        else:\n",
    "            label_patches = [np.zeros(self.slice_size, dtype=np.int64) for _ in input_patches]\n",
    "\n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            input_patches, label_patches = self.transform(input_patches, label_patches)\n",
    "\n",
    "        # Tensor 변환\n",
    "        input_patches = torch.tensor(input_patches, dtype=torch.float32)  # (num_patches, num_channels, H, W)\n",
    "        label_patches = torch.tensor(label_patches, dtype=torch.long)  # (num_patches, H, W)\n",
    "\n",
    "        return input_patches, label_patches\n",
    "\n",
    "    def _remap_labels(self, label):\n",
    "        \"\"\"라벨 데이터를 유효 클래스 값으로 매핑\"\"\"\n",
    "        remapped_label = np.zeros_like(label, dtype=np.int64)\n",
    "        for original, new_class in self.class_map.items():\n",
    "            remapped_label[label == original] = new_class\n",
    "        return remapped_label\n",
    "\n",
    "# 데이터 확인\n",
    "for images, labels in dataloader:\n",
    "    print(f\"Images shape: {images.shape}\")  # (B, C, H, W)\n",
    "    print(f\"Labels shape: {labels.shape}\")  # (B, H, W)\n",
    "    print(f\"Unique label values: {torch.unique(labels)}\")  # 라벨 값 확인\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/monai/networks/nets/unet.py:130: UserWarning: `len(strides) > len(channels) - 1`, the last 1 values of strides will not be used.\n",
      "  warnings.warn(f\"`len(strides) > len(channels) - 1`, the last {delta} values of strides will not be used.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 7, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "class UNet2_5D_v2(nn.Module):\n",
    "    def __init__(self, out_channels=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 초기 3D 처리 레이어\n",
    "        self.init_3d = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=(11, 3, 3), padding=(0, 1, 1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 2D UNet\n",
    "        self.unet = UNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=64,  # 3D 컨볼루션 출력 채널\n",
    "            out_channels=out_channels,\n",
    "            channels=(64, 128, 256, 512),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 1, 11, H, W)\n",
    "        # 3D 처리\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.init_3d(x)  # (batch, 64, 1, H, W)\n",
    "        x = x.squeeze(2)     # (batch, 64, H, W)\n",
    "        \n",
    "        # 2D UNet\n",
    "        return self.unet(x)\n",
    "\n",
    "# 테스트 코드\n",
    "if __name__ == \"__main__\":\n",
    "    model = UNet2_5D_v2(out_channels=7)\n",
    "    x = torch.randn(2, 11, 224, 224)\n",
    "    output = model(x)\n",
    "    print(f\"Output shape: {output.shape}\")  # Expected: (8, 6, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max label value: 6\n",
      "Num classes (model output): 7\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in dataloader:\n",
    "    print(f\"Max label value: {targets.max().item()}\")\n",
    "    print(f\"Num classes (model output): {outputs.shape[1]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets unique values: tensor([0, 1, 2, 3, 5, 6]), dtype: torch.int64\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "labels should have a channel with length equal to one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)  \u001b[38;5;66;03m# outputs: (B, 7, H, W)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 손실 계산\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# targets: (B, H, W)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update weights\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dust/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dust/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dust/lib/python3.12/site-packages/monai/losses/dice.py:158\u001b[0m, in \u001b[0;36mDiceLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    156\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle channel prediction, `to_onehot_y=True` ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m         target \u001b[38;5;241m=\u001b[39m \u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_pred_ch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_background:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_pred_ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dust/lib/python3.12/site-packages/monai/networks/utils.py:211\u001b[0m, in \u001b[0;36mone_hot\u001b[0;34m(labels, num_classes, dtype, dim)\u001b[0m\n\u001b[1;32m    208\u001b[0m sh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sh[dim] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels should have a channel with length equal to one.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m sh[dim] \u001b[38;5;241m=\u001b[39m num_classes\n\u001b[1;32m    215\u001b[0m o \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(size\u001b[38;5;241m=\u001b[39msh, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mAssertionError\u001b[0m: labels should have a channel with length equal to one."
     ]
    }
   ],
   "source": [
    "from monai.losses import DiceLoss\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = DiceLoss(to_onehot_y=True, softmax=True)  # Dice Loss with softmax\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Loop\n",
    "# Training Loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 라벨 데이터 정수형 확인 및 변환\n",
    "        targets = targets.long()  # 정수형으로 변환\n",
    "        print(f\"Targets unique values: {torch.unique(targets)}, dtype: {targets.dtype}\")\n",
    "\n",
    "        # 모델 출력\n",
    "        outputs = model(inputs)  # outputs: (B, 7, H, W)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, targets)  # targets: (B, H, W)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6931\n",
      "Epoch [2/5], Loss: 0.6931\n",
      "Epoch [3/5], Loss: 0.6931\n",
      "Epoch [4/5], Loss: 0.6931\n",
      "Epoch [5/5], Loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the model (U-Net)\n",
    "# class DoubleConv(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(DoubleConv, self).__init__()\n",
    "#         self.double_conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.double_conv(x)\n",
    "\n",
    "\n",
    "# class UNet(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(UNet, self).__init__()\n",
    "#         self.enc1 = DoubleConv(in_channels, 64)\n",
    "#         self.pool1 = nn.MaxPool2d(2)\n",
    "#         self.enc2 = DoubleConv(64, 128)\n",
    "#         self.pool2 = nn.MaxPool2d(2)\n",
    "#         self.enc3 = DoubleConv(128, 256)\n",
    "#         self.pool3 = nn.MaxPool2d(2)\n",
    "#         self.bridge = DoubleConv(256, 512)\n",
    "#         self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "#         self.dec3 = DoubleConv(512, 256)\n",
    "#         self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "#         self.dec2 = DoubleConv(256, 128)\n",
    "#         self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "#         self.dec1 = DoubleConv(128, 64)\n",
    "#         self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         enc1 = self.enc1(x)\n",
    "#         enc2 = self.enc2(self.pool1(enc1))\n",
    "#         enc3 = self.enc3(self.pool2(enc2))\n",
    "#         bridge = self.bridge(self.pool3(enc3))\n",
    "#         dec3 = self.dec3(torch.cat([self.upconv3(bridge), enc3], dim=1))\n",
    "#         dec2 = self.dec2(torch.cat([self.upconv2(dec3), enc2], dim=1))\n",
    "#         dec1 = self.dec1(torch.cat([self.upconv1(dec2), enc1], dim=1))\n",
    "#         return self.out_conv(dec1)\n",
    "\n",
    "\n",
    "# # Instantiate model, loss, and optimizer\n",
    "# model = UNet(in_channels=11, out_channels=2)  # 2 classes for segmentation\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# # Training Loop\n",
    "# for epoch in range(5):  # 5 epochs for demonstration\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, targets in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)  # Forward pass\n",
    "#         loss = criterion(outputs, targets)  # Compute loss\n",
    "#         loss.backward()  # Backpropagation\n",
    "#         optimizer.step()  # Update weights\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(dataloader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
