{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from thop import profile\n",
    "import torch\n",
    "\n",
    "def print_model_summary(model, input_size):\n",
    "    input_tensor = torch.randn(input_size)\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"FLOPs: {flops:,}, GFLOPs: {flops / 1e9:.2f}\")\n",
    "    print(f\"Parameters: {params:,}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: CSPBlock\n",
      "FLOPs: 51,640,270,848.0, GFLOPs: 51.64\n",
      "Parameters: 466,944.0\n",
      "--------------------------------------------------\n",
      "UnetResBlock Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm3d'>.\n",
      "Model: UnetResBlock\n",
      "FLOPs: 74,459,381,760.0, GFLOPs: 74.46\n",
      "Parameters: 672,512.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models import CSPBlock, UnetResBlock\n",
    "\n",
    "\n",
    "in_channels = 64\n",
    "out_channels = 128\n",
    "imgsz  = 96\n",
    "block = CSPBlock(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,  # 입력 채널 수정\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=2,\n",
    "        norm_name=\"batch\",\n",
    "        act_name=(\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout=None,\n",
    "        split_ratio=0.5,\n",
    "        n=2\n",
    "    )\n",
    "x = (1, in_channels, imgsz, imgsz, imgsz)\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinTransformer Summary:\")\n",
    "print_model_summary(block, x)\n",
    "\n",
    "block = UnetResBlock(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=2,\n",
    "        norm_name=\"batch\",\n",
    "        act_name=(\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout=None,\n",
    "     \n",
    "    )\n",
    "\n",
    "# Print summaries\n",
    "print(\"UnetResBlock Summary:\")\n",
    "print_model_summary(block, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNETR_mix Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: SwinCSPUNETR_unet\n",
      "FLOPs: 290,186,906,136.0, GFLOPs: 290.19\n",
      "Parameters: 43,524,919.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models.swincspunetr_unet import SwinCSPUNETR_unet\n",
    "x = (1, 1, 96, 96, 96)\n",
    "swin_unetr = SwinCSPUNETR_unet(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNETR_unet Summary:\")\n",
    "print_model_summary(swin_unetr, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: src.models.swincspunetr SwinCSPUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNETR Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: SwinCSPUNETR\n",
      "FLOPs: 289,518,045,720.0, GFLOPs: 289.52\n",
      "Parameters: 62,104,375.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models.swincspunetr import SwinCSPUNETR\n",
    "x = (1, 1, 96, 96, 96)\n",
    "swin_unetr = SwinCSPUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNETR Summary:\")\n",
    "print_model_summary(swin_unetr, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete SwinUNETR Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "torch.Size([1, 48, 48, 48, 48])\n",
      "torch.Size([1, 96, 24, 24, 24])\n",
      "torch.Size([1, 192, 12, 12, 12])\n",
      "torch.Size([1, 384, 6, 6, 6])\n",
      "torch.Size([1, 768, 3, 3, 3])\n",
      "enc0: torch.Size([1, 48, 96, 96, 96])\n",
      "enc1 torch.Size([1, 48, 48, 48, 48])\n",
      "torch.Size([1, 96, 24, 24, 24])\n",
      "torch.Size([1, 192, 12, 12, 12])\n",
      "torch.Size([1, 768, 3, 3, 3])\n",
      "Model: SwinUNETR\n",
      "FLOPs: 355,370,190,360.0, GFLOPs: 355.37\n",
      "Parameters: 72,564,583.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example model\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import SwinUNETR, SwinTransformer\n",
    "\n",
    "# SwinTransformer 테스트\n",
    "swin_transformer = SwinTransformer(\n",
    "    in_chans=1,\n",
    "    embed_dim=48,\n",
    "    window_size=(7, 7, 7),\n",
    "    patch_size=(2, 2, 2),\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    mlp_ratio=4.0,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_path_rate=0.0,\n",
    "    norm_layer=nn.LayerNorm,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "# 전체 SwinUNETR 모델\n",
    "swin_unetr = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "# Input sizes\n",
    "swin_transformer_input = (1, 1, 96, 96, 96)\n",
    "swin_unetr_input = (1, 1, 96, 96, 96)\n",
    "\n",
    "# # Print summaries\n",
    "# print(\"SwinTransformer Summary:\")\n",
    "# print_model_summary(swin_transformer, swin_transformer_input)\n",
    "\n",
    "print(\"\\nComplete SwinUNETR Summary:\")\n",
    "print_model_summary(swin_unetr, swin_unetr_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([1, 48, 48, 48, 48])\n",
    "torch.Size([1, 96, 24, 24, 24])\n",
    "torch.Size([1, 192, 12, 12, 12])\n",
    "torch.Size([1, 384, 6, 6, 6])\n",
    "torch.Size([1, 768, 3, 3, 3])\n",
    "enc0: torch.Size([1, 48, 96, 96, 96])\n",
    "enc1 torch.Size([1, 48, 48, 48, 48])\n",
    "torch.Size([1, 96, 24, 24, 24])\n",
    "torch.Size([1, 192, 12, 12, 12])\n",
    "torch.Size([1, 768, 3, 3, 3])\n",
    "Model: SwinUNETR\n",
    "FLOPs: 329,543,087,640.0, GFLOPs: 329.54\n",
    "Parameters: 61,989,223.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
