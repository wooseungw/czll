{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "import torch\n",
    "from torch.profiler import ProfilerActivity\n",
    "from torch.profiler import profile as profilee\n",
    "    \n",
    "\n",
    "def print_model_summary(model, input_size):\n",
    "    input_tensor = torch.randn(input_size)\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"FLOPs: {flops:,}, GFLOPs: {flops / 1e9:.2f}\")\n",
    "    print(f\"Parameters: {params:,}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def profile_model(model, input_size, log_dir='./log'):\n",
    "\n",
    "    input_tensor = torch.randn(input_size)\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    # 프로파일링\n",
    "    with profilee(\n",
    "        activities=[\n",
    "            ProfilerActivity.CPU, \n",
    "            ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(log_dir),  # TensorBoard 연동\n",
    "        record_shapes=True,\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        model(input_tensor)\n",
    "\n",
    "    # 프로파일링 결과 출력\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = (1, 1, 96, 96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlexibleUNet(\n",
      "  (encoder_blocks): ModuleList(\n",
      "    (0): SingleEncoderBlock(\n",
      "      (stack): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): SingleEncoderBlock(\n",
      "      (stack): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): SingleEncoderBlock(\n",
      "      (stack): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): SingleEncoderBlock(\n",
      "      (stack): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): SingleDecoderBlock(\n",
      "      (main_aligner): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (skip_aligners): ModuleList(\n",
      "        (0): SkipAlign(\n",
      "          (upsample): ResizeLayer()\n",
      "          (conv1x1): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "      )\n",
      "      (conv_stack): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): ConvTranspose3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): SingleDecoderBlock(\n",
      "      (main_aligner): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (skip_aligners): ModuleList(\n",
      "        (0): SkipAlign(\n",
      "          (upsample): ResizeLayer()\n",
      "          (conv1x1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "        (1): SkipAlign(\n",
      "          (upsample): ResizeLayer()\n",
      "        )\n",
      "      )\n",
      "      (conv_stack): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): ConvTranspose3d(192, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): SingleDecoderBlock(\n",
      "      (main_aligner): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (skip_aligners): ModuleList(\n",
      "        (0): SkipAlign(\n",
      "          (upsample): ResizeLayer()\n",
      "          (conv1x1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "        (1): SkipAlign(\n",
      "          (upsample): ResizeLayer()\n",
      "          (conv1x1): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "        (2): SkipAlign(\n",
      "          (upsample): ResizeLayer()\n",
      "          (conv1x1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "      )\n",
      "      (conv_stack): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): ConvTranspose3d(256, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Convolution(\n",
      "    (conv): Conv3d(32, 7, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      ")\n",
      "Output shape: torch.Size([1, 7, 96, 96, 96])\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: FlexibleUNet\n",
      "FLOPs: 245,414,264,832.0, GFLOPs: 245.41\n",
      "Parameters: 2,240,135.0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torch/autograd/profiler.py:228: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n",
      "STAGE:2025-01-18 21:43:01 86212:2197662 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                        aten::to         0.00%       0.000us         0.00%       0.000us       0.000us             7  \n",
      "                    aten::conv3d         0.01%      41.000us        16.59%      51.522ms       3.963ms            13  \n",
      "               aten::convolution         0.06%     171.000us        81.83%     254.076ms      15.880ms            16  \n",
      "              aten::_convolution        -0.39%   -1203.000us        81.78%     253.905ms      15.869ms            16  \n",
      "               aten::slow_conv3d         0.43%       1.344ms        16.51%      51.273ms       3.944ms            13  \n",
      "       aten::slow_conv3d_forward        13.71%      42.569ms        16.50%      51.235ms       3.941ms            13  \n",
      "                     aten::empty         0.02%      76.000us         0.02%      76.000us       0.644us           118  \n",
      "                      aten::view         0.01%      17.000us         0.01%      17.000us       0.486us            35  \n",
      "                   aten::resize_         0.43%       1.333ms         0.43%       1.333ms      83.312us            16  \n",
      "                   aten::reshape         0.00%       5.000us         0.00%       7.000us       0.538us            13  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 310.483ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-01-18 21:43:02 86212:2197662 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-01-18 21:43:02 86212:2197662 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from src.models import *\n",
    "\n",
    "enc_channels = (32, 64, 128, 256)\n",
    "enc_strides = (2, 2, 2)\n",
    "num_layers_enc = (1, 1, 1, 1)\n",
    "\n",
    "core_channels = 64\n",
    "dec_channels = (128, 64, 32)\n",
    "dec_strides = (2, 2, 2)\n",
    "num_layers_dec = (1, 1, 1)\n",
    "\n",
    "# 디코더간 스킵 예시:\n",
    "#   디코더0: (\"enc\",2), (\"dec\", ?) -- 가능하지만 보통 dec_? < dec_0\n",
    "#   디코더1: (\"enc\",1), (\"dec\",0)\n",
    "#   디코더2: (\"enc\",0), (\"dec\",1)\n",
    "# 반드시 \"dec\", j => j < i 여야함\n",
    "skip_map = {\n",
    "0: [(\"enc\", 2)],       # 디코더0 => 인코더2\n",
    "1: [(\"enc\", 3), (\"enc\", 1)],  # 디코더1 => 인코더1 + 디코더0\n",
    "2: [(\"enc\", 3), (\"dec\", 0), (\"enc\", 0)]   # 디코더2 => 인코더0 + 디코더1\n",
    "}\n",
    "\n",
    "\n",
    "net = FlexibleUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    encoder_channels=enc_channels,\n",
    "    encoder_strides=enc_strides,\n",
    "    decoder_channels=dec_channels,\n",
    "    decoder_strides=dec_strides,\n",
    "    num_layers_encoder=num_layers_enc,\n",
    "    num_layers_decoder=num_layers_dec,\n",
    "    skip_connections=skip_map,\n",
    "    kernel_size=3,\n",
    "    up_kernel_size=3,\n",
    "    dropout=0.0,\n",
    "    bias=True,\n",
    ")\n",
    "\n",
    "print(net)\n",
    "x = torch.randn(1, 1, 96, 96, 96)\n",
    "with torch.no_grad():\n",
    "    y = net(x)\n",
    "print(\"Output shape:\", y.shape)\n",
    "\n",
    "print_model_summary(net, x.shape)\n",
    "profile_model(net, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "Model: conv3d_block\n",
      "FLOPs: 5,159,780,352.0, GFLOPs: 5.16\n",
      "Parameters: 884,736.0\n",
      "--------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "Model: conv3d_dp_block\n",
      "FLOPs: 26,407,296.0, GFLOPs: 0.03\n",
      "Parameters: 36,224.0\n",
      "--------------------------------------------------\n",
      "----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                        Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::conv3d         0.25%      38.000us       100.00%      15.046ms      15.046ms       9.000us         0.06%      14.998ms      14.998ms             1  \n",
      "           aten::convolution         0.41%      62.200us        99.75%      15.008ms      15.008ms      40.000us         0.27%      14.989ms      14.989ms             1  \n",
      "          aten::_convolution         0.19%      28.800us        99.33%      14.946ms      14.946ms      28.000us         0.19%      14.949ms      14.949ms             1  \n",
      "    aten::mkldnn_convolution        98.94%      14.887ms        99.14%      14.917ms      14.917ms      14.887ms        99.26%      14.921ms      14.921ms             1  \n",
      "                 aten::empty         0.13%      19.800us         0.13%      19.800us       9.900us      14.000us         0.09%      14.000us       7.000us             2  \n",
      "           aten::as_strided_         0.05%       7.600us         0.05%       7.600us       7.600us      13.000us         0.09%      13.000us      13.000us             1  \n",
      "               aten::resize_         0.02%       2.600us         0.02%       2.600us       2.600us       7.000us         0.05%       7.000us       7.000us             1  \n",
      "----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 15.046ms\n",
      "Self CUDA time total: 14.998ms\n",
      "\n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 aten::conv3d         1.27%      28.600us       100.00%       2.247ms       1.124ms      11.000us         0.50%       2.189ms       1.095ms             2  \n",
      "            aten::convolution         2.10%      47.100us        98.73%       2.219ms       1.109ms      31.000us         1.42%       2.178ms       1.089ms             2  \n",
      "           aten::_convolution         1.55%      34.800us        96.63%       2.172ms       1.086ms      22.000us         1.01%       2.147ms       1.073ms             2  \n",
      "     aten::mkldnn_convolution        42.47%     954.500us        65.43%       1.470ms       1.470ms     927.000us        42.35%       1.457ms       1.457ms             1  \n",
      "            aten::slow_conv3d         0.86%      19.400us        29.65%     666.300us     666.300us       8.000us         0.37%     668.000us     668.000us             1  \n",
      "    aten::slow_conv3d_forward        28.32%     636.500us        28.79%     646.900us     646.900us     635.000us        29.01%     660.000us     660.000us             1  \n",
      "             aten::contiguous         7.63%     171.500us        22.32%     501.600us     501.600us     167.000us         7.63%     502.000us     502.000us             1  \n",
      "                  aten::clone        10.23%     230.000us        14.69%     330.100us     330.100us     216.000us         9.87%     335.000us     335.000us             1  \n",
      "                  aten::copy_         3.75%      84.300us         3.75%      84.300us      84.300us     104.000us         4.75%     104.000us     104.000us             1  \n",
      "                  aten::empty         0.56%      12.600us         0.56%      12.600us       3.150us      24.000us         1.10%      24.000us       6.000us             4  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.247ms\n",
      "Self CUDA time total: 2.189ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "x = (1, 128, 18, 18, 18)\n",
    "feature = 256\n",
    "\n",
    "conv3d = nn.Conv3d(1, feature, 3, padding=1, bias=False)\n",
    "\n",
    "class conv3d_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias):\n",
    "        super(conv3d_block, self).__init__()\n",
    "        self.d3conv = nn.Conv3d(in_channels, out_channels, 3, padding=1, bias=False)\n",
    "                                    \n",
    "    def forward(self, x):\n",
    "        x = self.d3conv(x)\n",
    "        return x\n",
    "\n",
    "class conv3d_dp_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias):\n",
    "        super(conv3d_dp_block, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv3d(in_channels, in_channels, kernel_size, stride, padding,\n",
    "                                      groups=in_channels, bias=bias)\n",
    "        self.pointwise_conv = nn.Conv3d(in_channels, out_channels, 1, 1, 0, bias=bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        depthwise_conv = self.depthwise_conv(x)\n",
    "        \n",
    "        x = self.pointwise_conv(depthwise_conv)\n",
    "        return x \n",
    "    \n",
    "conv3d_block = conv3d_block(128, feature, 3, 2, 1, False)\n",
    "conv3d_dp_block = conv3d_dp_block(128, feature, 3, 2, 1, False)\n",
    "\n",
    "print_model_summary(conv3d_block, x)\n",
    "print_model_summary(conv3d_dp_block, x)\n",
    "profile_model(conv3d_block, x, './log')\n",
    "profile_model(conv3d_dp_block, x, './log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: UNet_CBAM\n",
      "FLOPs: 34,904,951,936.0, GFLOPs: 34.90\n",
      "Parameters: 1,965,635.0\n",
      "--------------------------------------------------\n",
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    aten::convolution         3.23%     327.200us        26.88%       2.719ms     339.900us     264.000us         2.05%       3.636ms     454.500us             8  \n",
      "                   aten::_convolution         9.28%     938.200us        23.65%       2.392ms     299.000us     572.000us         4.44%       3.372ms     421.500us             8  \n",
      "                            aten::cat         7.80%     788.900us        14.72%       1.489ms     372.300us       2.252ms        17.48%       2.936ms     734.000us             4  \n",
      "                  aten::instance_norm         2.71%     274.100us        26.29%       2.659ms     443.150us     126.000us         0.98%       2.673ms     445.500us             6  \n",
      "                     aten::batch_norm         2.66%     269.200us        22.79%       2.305ms     384.200us     287.000us         2.23%       2.461ms     410.167us             6  \n",
      "         aten::_batch_norm_impl_index         5.44%     550.100us        20.13%       2.036ms     339.333us     575.000us         4.46%       2.174ms     362.333us             6  \n",
      "                         aten::conv3d         1.12%     113.000us        18.12%       1.833ms     366.660us     168.000us         1.30%       2.009ms     401.800us             5  \n",
      "               aten::conv_transpose3d         0.54%      55.100us        10.42%       1.054ms     351.333us      78.000us         0.61%       1.873ms     624.333us             3  \n",
      "    aten::cudnn_convolution_transpose         5.35%     540.700us         5.35%     540.700us     180.233us       1.631ms        12.66%       1.631ms     543.667us             3  \n",
      "              aten::native_batch_norm        11.20%       1.133ms        14.45%       1.462ms     243.650us     997.000us         7.74%       1.562ms     260.333us             6  \n",
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 10.115ms\n",
      "Self CUDA time total: 12.886ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models import UNet_CBAM\n",
    "model = UNet_CBAM(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=[32, 64, 128, 256],\n",
    "    strides=(2,2,2),\n",
    "\n",
    ").to(device)\n",
    "print_model_summary(model, x)\n",
    "profile_model(model, x, './log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: UNet\n",
      "FLOPs: 34,904,825,856.0, GFLOPs: 34.90\n",
      "Parameters: 1,948,909.0\n",
      "--------------------------------------------------\n",
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    aten::convolution         3.98%     180.900us        32.04%       1.456ms     208.029us     176.000us         3.13%       2.829ms     404.143us             7  \n",
      "                   aten::_convolution         6.98%     317.100us        28.06%       1.275ms     182.186us     163.000us         2.90%       2.653ms     379.000us             7  \n",
      "               aten::conv_transpose3d         0.74%      33.600us        10.51%     477.400us     159.133us      89.000us         1.58%       1.659ms     553.000us             3  \n",
      "                  aten::instance_norm         4.89%     222.200us        40.37%       1.834ms     305.733us     187.000us         3.33%       1.608ms     268.000us             6  \n",
      "    aten::cudnn_convolution_transpose         5.07%     230.600us         5.07%     230.600us      76.867us       1.432ms        25.50%       1.432ms     477.333us             3  \n",
      "                         aten::conv3d         2.06%      93.700us        24.34%       1.106ms     276.525us      73.000us         1.30%       1.332ms     333.000us             4  \n",
      "                     aten::batch_norm         2.42%     110.000us        33.68%       1.531ms     255.100us      58.000us         1.03%       1.323ms     220.500us             6  \n",
      "         aten::_batch_norm_impl_index         4.30%     195.600us        31.26%       1.421ms     236.767us     138.000us         2.46%       1.265ms     210.833us             6  \n",
      "              aten::native_batch_norm        18.81%     854.900us        26.44%       1.201ms     200.217us     619.000us        11.02%       1.065ms     177.500us             6  \n",
      "              aten::cudnn_convolution        11.26%     511.800us        11.26%     511.800us     127.950us     884.000us        15.74%     884.000us     221.000us             4  \n",
      "-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.544ms\n",
      "Self CUDA time total: 5.616ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\czii\\Lib\\site-packages\\thop\\vision\\calc_func.py:53: UserWarning: This API is being deprecated\n",
      "  warnings.warn(\"This API is being deprecated\")\n"
     ]
    }
   ],
   "source": [
    "from src.models import UNet\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=[32, 64, 128, 256],\n",
    "    strides=(2,2,2),\n",
    "\n",
    ").to(device)\n",
    "print_model_summary(model, x)\n",
    "profile_model(model, x, './log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformerblock: <class 'src.models.deformer_lka_blocks.TransformerBlock_3D_single_deform_LKA'>\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using skip connection in decoder: True\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using skip connection in decoder: True\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using skip connection in decoder: True\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using LKA Attention with one deformable layer\n",
      "Using skip connection in decoder: True\n",
      "D_LKA_Net Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: D_LKA_Net\n",
      "FLOPs: 172,432,889,856.0, GFLOPs: 172.43\n",
      "Parameters: 25,235,530.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models import  D_LKA_Net\n",
    "from src.models.deformer_lka_blocks import TransformerBlock\n",
    "\n",
    "model = D_LKA_Net(\n",
    "    in_channels=x[1],\n",
    "    out_channels=7,\n",
    "    \n",
    "    ).to(device)\n",
    "# Print summaries\n",
    "print(\"D_LKA_Net Summary:\")\n",
    "print_model_summary(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name(0))  # GPU 이름 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNET3Plus Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: MiTUnet\n",
      "FLOPs: 62,496,175,104.0, GFLOPs: 62.50\n",
      "Parameters: 12,031,811.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models import MiTUnet\n",
    "# (7, 1, 3))\n",
    "x = (1, 1, 96, 96, 96)\n",
    "model = MiTUnet(\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size = 16,\n",
    "    heads=(1, 2, 2, 4, 8),\n",
    "    ff_expansion=(2, 8, 8, 4, 4),\n",
    "    reduction_ratio=(16, 8, 4, 2, 1),\n",
    "    num_layers=(1,1,2,2,2),\n",
    "    channels=1,\n",
    "    stage_kernel_stride_pad = ((3,1,1), (3, 2, 1), (3, 2, 1), (3, 2, 1), (3, 2, 1)),\n",
    "    \n",
    "    spatial_dims=3,\n",
    "    out_channels=7,\n",
    "    norm_name=\"instance\",\n",
    "    act_name = (\"leakyrelu \", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNET3Plus Summary:\")\n",
    "print_model_summary(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNET3Plus Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: MiTCSPUnet\n",
      "FLOPs: 80,926,995,456.0, GFLOPs: 80.93\n",
      "Parameters: 15,698,243.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models import MiTCSPUnet\n",
    "# (7, 1, 3))\n",
    "x = (1, 1, 96, 96, 96)\n",
    "model = MiTCSPUnet(\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size = 16,\n",
    "    heads=(1, 2, 2, 4, 8),\n",
    "    ff_expansion=(2, 8, 8, 4, 4),\n",
    "    reduction_ratio=(16, 8, 4, 2, 1),\n",
    "    num_layers=(1,1,2,2,2),\n",
    "    channels=1,\n",
    "    stage_kernel_stride_pad = ((3,1,1), (3, 2, 1), (3, 2, 1), (3, 2, 1), (3, 2, 1)),\n",
    "    \n",
    "    spatial_dims=3,\n",
    "    out_channels=7,\n",
    "    norm_name=\"instance\",\n",
    "    act_name = (\"leakyrelu \", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNET3Plus Summary:\")\n",
    "print_model_summary(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer Summary:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'print_model_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Print summaries\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSwinTransformer Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mprint_model_summary\u001b[49m(block, x)\n\u001b[1;32m     25\u001b[0m block \u001b[38;5;241m=\u001b[39m UnetResBlock(\n\u001b[1;32m     26\u001b[0m         spatial_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     27\u001b[0m         in_channels\u001b[38;5;241m=\u001b[39min_channels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m      \n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Print summaries\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'print_model_summary' is not defined"
     ]
    }
   ],
   "source": [
    "# from src.models import CSPBlock, UnetResBlock\n",
    "\n",
    "\n",
    "# in_channels = 64\n",
    "# out_channels = 128\n",
    "# imgsz  = 96\n",
    "# block = CSPBlock(\n",
    "#         spatial_dims=3,\n",
    "#         in_channels=in_channels,  # 입력 채널 수정\n",
    "#         out_channels=out_channels,\n",
    "#         kernel_size=3,\n",
    "#         stride=2,\n",
    "#         norm_name=\"batch\",\n",
    "#         act_name=(\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "#         dropout=None,\n",
    "#         split_ratio=0.5,\n",
    "#         n=2\n",
    "#     )\n",
    "# x = (1, in_channels, imgsz, imgsz, imgsz)\n",
    "\n",
    "# # Print summaries\n",
    "# print(\"SwinTransformer Summary:\")\n",
    "# print_model_summary(block, x)\n",
    "\n",
    "# block = UnetResBlock(\n",
    "#         spatial_dims=3,\n",
    "#         in_channels=in_channels,\n",
    "#         out_channels=out_channels,\n",
    "#         kernel_size=3,\n",
    "#         stride=2,\n",
    "#         norm_name=\"batch\",\n",
    "#         act_name=(\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "#         dropout=None,\n",
    "     \n",
    "#     )\n",
    "\n",
    "# # Print summaries\n",
    "# print(\"UnetResBlock Summary:\")\n",
    "# print_model_summary(block, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNETR_mix Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: SwinCSPUNETR_unet\n",
      "FLOPs: 290,186,906,136.0, GFLOPs: 290.19\n",
      "Parameters: 43,524,919.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models.swincspunetr_unet import SwinCSPUNETR_unet\n",
    "x = (1, 1, 96, 96, 96)\n",
    "swin_unetr = SwinCSPUNETR_unet(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNETR_unet Summary:\")\n",
    "print_model_summary(swin_unetr, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: src.models.swincspunetr SwinCSPUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNETR Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: SwinCSPUNETR\n",
      "FLOPs: 289,518,045,720.0, GFLOPs: 289.52\n",
      "Parameters: 62,104,375.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models.swincspunetr import SwinCSPUNETR\n",
    "x = (1, 1, 96, 96, 96)\n",
    "swin_unetr = SwinCSPUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNETR Summary:\")\n",
    "print_model_summary(swin_unetr, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete SwinUNETR Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "torch.Size([1, 48, 48, 48, 48])\n",
      "torch.Size([1, 96, 24, 24, 24])\n",
      "torch.Size([1, 192, 12, 12, 12])\n",
      "torch.Size([1, 384, 6, 6, 6])\n",
      "torch.Size([1, 768, 3, 3, 3])\n",
      "enc0: torch.Size([1, 48, 96, 96, 96])\n",
      "enc1 torch.Size([1, 48, 48, 48, 48])\n",
      "torch.Size([1, 96, 24, 24, 24])\n",
      "torch.Size([1, 192, 12, 12, 12])\n",
      "torch.Size([1, 768, 3, 3, 3])\n",
      "Model: SwinUNETR\n",
      "FLOPs: 355,370,190,360.0, GFLOPs: 355.37\n",
      "Parameters: 72,564,583.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example model\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import SwinUNETR, SwinTransformer\n",
    "\n",
    "# SwinTransformer 테스트\n",
    "swin_transformer = SwinTransformer(\n",
    "    in_chans=1,\n",
    "    embed_dim=48,\n",
    "    window_size=(7, 7, 7),\n",
    "    patch_size=(2, 2, 2),\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    mlp_ratio=4.0,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_path_rate=0.0,\n",
    "    norm_layer=nn.LayerNorm,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "# 전체 SwinUNETR 모델\n",
    "swin_unetr = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "# Input sizes\n",
    "swin_transformer_input = (1, 1, 96, 96, 96)\n",
    "swin_unetr_input = (1, 1, 96, 96, 96)\n",
    "\n",
    "# # Print summaries\n",
    "# print(\"SwinTransformer Summary:\")\n",
    "# print_model_summary(swin_transformer, swin_transformer_input)\n",
    "\n",
    "print(\"\\nComplete SwinUNETR Summary:\")\n",
    "print_model_summary(swin_unetr, swin_unetr_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([1, 48, 48, 48, 48])\n",
    "torch.Size([1, 96, 24, 24, 24])\n",
    "torch.Size([1, 192, 12, 12, 12])\n",
    "torch.Size([1, 384, 6, 6, 6])\n",
    "torch.Size([1, 768, 3, 3, 3])\n",
    "enc0: torch.Size([1, 48, 96, 96, 96])\n",
    "enc1 torch.Size([1, 48, 48, 48, 48])\n",
    "torch.Size([1, 96, 24, 24, 24])\n",
    "torch.Size([1, 192, 12, 12, 12])\n",
    "torch.Size([1, 768, 3, 3, 3])\n",
    "Model: SwinUNETR\n",
    "FLOPs: 329,543,087,640.0, GFLOPs: 329.54\n",
    "Parameters: 61,989,223.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
