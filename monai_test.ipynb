{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from monai.data import Dataset, DataLoader, CacheDataset\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, NormalizeIntensityd,\n",
    "    Orientationd, CropForegroundd, GaussianSmoothd, ScaleIntensityd,\n",
    "    RandSpatialCropd, RandRotate90d, RandFlipd, RandGaussianNoised,\n",
    "    ToTensord, RandCropByLabelClassesd\n",
    ")\n",
    "import torch\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "# from monai.inferers import sliding_window_inference\n",
    "# inputs = MetaTensor or Tensor\n",
    "# outputs = sliding_window_inference(\n",
    "#     inputs=inputs,\n",
    "#     roi_size=(96, 96, 96),\n",
    "#     sw_batch_size=4,\n",
    "#     predictor=model.forward\n",
    "# )\n",
    "# output shape은 input의 shape과 동일하다.\n",
    "# validation(task)의 chacing된 데이터셋을 사용해야함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"./datasets/train/images\"\n",
    "TRAIN_LABEL_DIR = \"./datasets/train/labels\"\n",
    "VAL_IMG_DIR = \"./datasets/val/images\"\n",
    "VAL_LABEL_DIR = \"./datasets/val/labels\"\n",
    "\n",
    "train_list = os.listdir(TRAIN_IMG_DIR)\n",
    "val_list = os.listdir(VAL_IMG_DIR)\n",
    "train_files = []\n",
    "valid_files = []\n",
    "\n",
    "\n",
    "for name in train_list:\n",
    "    image = np.load(os.path.join(TRAIN_IMG_DIR, f\"{name}\"))    \n",
    "    label = np.load(os.path.join(TRAIN_LABEL_DIR, f\"{name.replace(\"image\", \"label\")}\"))\n",
    "\n",
    "    train_files.append({\"image\": image, \"label\": label})    \n",
    "\n",
    "for name in val_list:\n",
    "    image = np.load(os.path.join(VAL_IMG_DIR, f\"{name}\"))\n",
    "    label = np.load(os.path.join(VAL_LABEL_DIR, f\"{name.replace(\"image\", \"label\")}\"))\n",
    "\n",
    "    valid_files.append({\"image\": image, \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 4/4 [00:00<00:00,  9.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Non-random transforms to be cached\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")\n",
    "])\n",
    "# Create the cached dataset with non-random transforms\n",
    "val_ds = CacheDataset(data=valid_files, transform=non_random_transforms, cache_rate=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import Compose, RandCropByLabelClassesd, RandRotate90d, RandFlipd\n",
    "from monai.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Define the random transforms\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[3, 96, 96],\n",
    "        num_classes=7,\n",
    "        num_samples=8  # num_samples 값을 양의 정수로 설정\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[1,2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),    \n",
    "])\n",
    "\n",
    "# Apply random transforms to the cached dataset\n",
    "val_ds = Dataset(data=val_ds, transform=random_transforms)\n",
    "\n",
    "train_loader = DataLoader(val_ds, batch_size=2, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 3, 96, 96]) torch.Size([16, 1, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch[\"image\"], batch[\"label\"]\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "out_img = images\n",
    "print(out_img.shape)\n",
    "out_meta = images.meta\n",
    "center = out_img.shape[2] // 2\n",
    "prev_image = out_img[:, :, 0:center, :, :]\n",
    "image = out_img[:, :, center:center+1, :, :]\n",
    "next_image = out_img[:, :, center+1:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 96, 96])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.squeeze(1)\n",
    "labels = labels[:, center:center+1, :, :]\n",
    "labels.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
