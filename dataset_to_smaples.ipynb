{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 비율: {0: 0.0, 1: 0.16393442622950818, 2: 0.01639344262295082, 3: 0.2459016393442623, 4: 0.16393442622950818, 5: 0.2459016393442623, 6: 0.16393442622950818}\n",
      "최종 합계: 1.0\n",
      "클래스 비율 리스트: [0.0, 0.16393442622950818, 0.01639344262295082, 0.2459016393442623, 0.16393442622950818, 0.2459016393442623, 0.16393442622950818]\n"
     ]
    }
   ],
   "source": [
    "class_info = {\n",
    "    0: {\"name\": \"background\", \"weight\": 0},  # weight 없음\n",
    "    1: {\"name\": \"apo-ferritin\", \"weight\": 1000},\n",
    "    2: {\"name\": \"beta-amylase\", \"weight\": 100}, # 4130\n",
    "    3: {\"name\": \"beta-galactosidase\", \"weight\": 1500}, #3080\n",
    "    4: {\"name\": \"ribosome\", \"weight\": 1000},\n",
    "    5: {\"name\": \"thyroglobulin\", \"weight\": 1500},\n",
    "    6: {\"name\": \"virus-like-particle\", \"weight\": 1000},\n",
    "}\n",
    "\n",
    "# 가중치에 비례한 비율 계산\n",
    "raw_ratios = {\n",
    "    k: (v[\"weight\"] if v[\"weight\"] is not None else 0.01)  # 가중치 비례, None일 경우 기본값a\n",
    "    for k, v in class_info.items()\n",
    "}\n",
    "total = sum(raw_ratios.values())\n",
    "ratios = {k: v / total for k, v in raw_ratios.items()}\n",
    "\n",
    "# 최종 합계가 1인지 확인\n",
    "final_total = sum(ratios.values())\n",
    "print(\"클래스 비율:\", ratios)\n",
    "print(\"최종 합계:\", final_total)\n",
    "\n",
    "# 비율을 리스트로 변환\n",
    "ratios_list = [ratios[k] for k in sorted(ratios.keys())]\n",
    "print(\"클래스 비율 리스트:\", ratios_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 6/6 [00:09<00:00,  1.66s/it]\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.dataset.dataset import create_dataloaders\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, NormalizeIntensityd,\n",
    "    Orientationd, CropForegroundd, GaussianSmoothd, ScaleIntensityd,\n",
    "    RandSpatialCropd, RandRotate90d, RandFlipd, RandGaussianNoised,\n",
    "    ToTensord, RandCropByLabelClassesd\n",
    ")\n",
    "\n",
    "train_img_dir = \"./datasets/train/images\"\n",
    "train_label_dir = \"./datasets/train/labels\"\n",
    "val_img_dir = \"./datasets/val/images\"\n",
    "val_label_dir = \"./datasets/val/labels\"\n",
    "# DATA CONFIG\n",
    "img_depth = 96\n",
    "img_size =  96 # Match your patch size\n",
    "n_classes = 7\n",
    "batch_size =10 # 13.8GB GPU memory required for 128x128 img size\n",
    "num_samples = batch_size # 한 이미지에서 뽑을 샘플 수\n",
    "loader_batch = 1\n",
    "# # CLASS_WEIGHTS\n",
    "# class_weights = None\n",
    "# class_weights = torch.tensor([0.001, 1, 0.001, 1.1, 1, 1.1, 1], dtype=torch.float32)  # 클래스별 가중치\n",
    "\n",
    "accumulation_steps = 4\n",
    "# INIT\n",
    "start_epoch = 0\n",
    "best_val_loss = float('inf')\n",
    "best_val_fbeta_score = 0\n",
    "\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    GaussianSmoothd(\n",
    "        keys=[\"image\"],      # 변환을 적용할 키\n",
    "        sigma=[1.0, 1.0, 1.0]  # 각 축(x, y, z)의 시그마 값\n",
    "        ),\n",
    "])\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[img_depth, img_size, img_size],\n",
    "        num_classes=n_classes,\n",
    "        num_samples=num_samples, \n",
    "        ratios=ratios_list,\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[1, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "])\n",
    "\n",
    "train_loader, val_loader = None, None\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_img_dir, \n",
    "    train_label_dir, \n",
    "    val_img_dir, \n",
    "    val_label_dir, \n",
    "    non_random_transforms = non_random_transforms, \n",
    "    random_transforms = random_transforms, \n",
    "    batch_size = loader_batch,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 샘플 저장 함수 (채널 처리 포함)\n",
    "def save_samples(data_loader, save_dir, save_format=\"npy\", remove_channel_dim=True):\n",
    "    \"\"\"\n",
    "    데이터 로더에서 샘플을 저장하는 함수\n",
    "\n",
    "    Args:\n",
    "        data_loader: 데이터 로더 객체\n",
    "        save_dir: 저장 디렉토리 경로\n",
    "        save_format: 저장 형식 (\"npy\" 또는 \"tensor\")\n",
    "        remove_channel_dim: True면 채널 차원을 제거합니다. (1, depth, width, height -> depth, width, height)\n",
    "    \"\"\"\n",
    "    image_save_dir = os.path.join(save_dir, \"images\")\n",
    "    label_save_dir = os.path.join(save_dir, \"labels\")\n",
    "    os.makedirs(image_save_dir, exist_ok=True)\n",
    "    os.makedirs(label_save_dir, exist_ok=True)\n",
    "\n",
    "    sample_count = 0\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        images = batch[\"image\"]  # (batch_size, 1, depth, width, height)\n",
    "        labels = batch[\"label\"]  # (batch_size, depth, width, height) or similar\n",
    "\n",
    "        for i in range(images.shape[0]):\n",
    "            \n",
    "            # 채널 차원 제거 (필요 시)\n",
    "            image = images[i]  # (1, depth, width, height)\n",
    "            label = labels[i]  # (depth, width, height)\n",
    "\n",
    "            if remove_channel_dim and image.shape[0] == 1:\n",
    "                image = image.squeeze(0)  # (depth, width, height)\n",
    "\n",
    "            # 저장 경로 생성\n",
    "            image_save_path = os.path.join(image_save_dir, f\"image_{sample_count}.{save_format}\")\n",
    "            label_save_path = os.path.join(label_save_dir, f\"label_{sample_count}.{save_format}\")\n",
    "            \n",
    "            # 저장\n",
    "            if save_format == \"npy\":\n",
    "                np.save(image_save_path, image.numpy())\n",
    "                np.save(label_save_path, label.numpy())\n",
    "            elif save_format == \"tensor\":\n",
    "                torch.save(image, image_save_path)\n",
    "                torch.save(label, label_save_path)\n",
    "            else:\n",
    "                raise ValueError(\"지원되지 않는 저장 형식입니다. 'npy' 또는 'tensor'만 사용 가능합니다.\")\n",
    "            \n",
    "            print(f\"샘플 {sample_count} 저장 완료!\")\n",
    "            sample_count += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 0 저장 완료!\n",
      "샘플 1 저장 완료!\n",
      "샘플 2 저장 완료!\n",
      "샘플 3 저장 완료!\n",
      "샘플 4 저장 완료!\n",
      "샘플 5 저장 완료!\n",
      "샘플 6 저장 완료!\n",
      "샘플 7 저장 완료!\n",
      "샘플 8 저장 완료!\n",
      "샘플 9 저장 완료!\n",
      "샘플 10 저장 완료!\n",
      "샘플 11 저장 완료!\n",
      "샘플 12 저장 완료!\n",
      "샘플 13 저장 완료!\n",
      "샘플 14 저장 완료!\n",
      "샘플 15 저장 완료!\n",
      "샘플 16 저장 완료!\n",
      "샘플 17 저장 완료!\n",
      "샘플 18 저장 완료!\n",
      "샘플 19 저장 완료!\n",
      "샘플 20 저장 완료!\n",
      "샘플 21 저장 완료!\n",
      "샘플 22 저장 완료!\n",
      "샘플 23 저장 완료!\n",
      "샘플 24 저장 완료!\n",
      "샘플 25 저장 완료!\n",
      "샘플 26 저장 완료!\n",
      "샘플 27 저장 완료!\n",
      "샘플 28 저장 완료!\n",
      "샘플 29 저장 완료!\n",
      "샘플 30 저장 완료!\n",
      "샘플 31 저장 완료!\n",
      "샘플 32 저장 완료!\n",
      "샘플 33 저장 완료!\n",
      "샘플 34 저장 완료!\n",
      "샘플 35 저장 완료!\n",
      "샘플 36 저장 완료!\n",
      "샘플 37 저장 완료!\n",
      "샘플 38 저장 완료!\n",
      "샘플 39 저장 완료!\n",
      "샘플 40 저장 완료!\n",
      "샘플 41 저장 완료!\n",
      "샘플 42 저장 완료!\n",
      "샘플 43 저장 완료!\n",
      "샘플 44 저장 완료!\n",
      "샘플 45 저장 완료!\n",
      "샘플 46 저장 완료!\n",
      "샘플 47 저장 완료!\n",
      "샘플 48 저장 완료!\n",
      "샘플 49 저장 완료!\n",
      "샘플 50 저장 완료!\n",
      "샘플 51 저장 완료!\n",
      "샘플 52 저장 완료!\n",
      "샘플 53 저장 완료!\n",
      "샘플 54 저장 완료!\n",
      "샘플 55 저장 완료!\n",
      "샘플 56 저장 완료!\n",
      "샘플 57 저장 완료!\n",
      "샘플 58 저장 완료!\n",
      "샘플 59 저장 완료!\n",
      "샘플 0 저장 완료!\n",
      "샘플 1 저장 완료!\n",
      "샘플 2 저장 완료!\n",
      "샘플 3 저장 완료!\n",
      "샘플 4 저장 완료!\n",
      "샘플 5 저장 완료!\n",
      "샘플 6 저장 완료!\n",
      "샘플 7 저장 완료!\n",
      "샘플 8 저장 완료!\n",
      "샘플 9 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# Train 데이터 저장 예제\n",
    "save_samples(train_loader,  save_dir=\"./sample_dataset/train\", save_format=\"tensor\", remove_channel_dim=False)\n",
    "# Validation 데이터 저장 예제\n",
    "save_samples(val_loader, save_dir=\"./sample_dataset/valid\", save_format=\"tensor\", remove_channel_dim=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 96, 96])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.load(\"./sample_dataset/train/images/image_0.tensor\")  # (depth, width, height)\n",
    "image = image.squeeze(0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_3d_tensor_with_labels_as_grid(image_tensor, label_tensor, axis=0, cols=5):\n",
    "    \"\"\"\n",
    "    3D 텐서와 라벨 데이터를 슬라이스 단위로 그리드 형태로 시각화합니다.\n",
    "    \n",
    "    Args:\n",
    "        image_tensor (torch.Tensor): 3D 이미지 텐서 (depth, width, height)\n",
    "        label_tensor (torch.Tensor): 3D 라벨 텐서 (depth, width, height)\n",
    "        axis (int): 시각화할 축 (0, 1, 2 중 선택)\n",
    "        cols (int): 그리드의 열 개수\n",
    "    \"\"\"\n",
    "    image_tensor = image_tensor.squeeze(0)  # (1, depth, width, height) -> (depth, width, height)\n",
    "    label_tensor = label_tensor.squeeze(0)  # (1, depth, width, height) -> (depth, width, height)\n",
    "    \n",
    "    # NumPy 배열로 변환\n",
    "    image_tensor = image_tensor.numpy() if isinstance(image_tensor, torch.Tensor) else image_tensor\n",
    "    label_tensor = label_tensor.numpy() if isinstance(label_tensor, torch.Tensor) else label_tensor\n",
    "    \n",
    "    num_slices = image_tensor.shape[axis]\n",
    "    \n",
    "    # 행 개수 계산 (이미지와 라벨은 쌍으로 표시되므로 두 배로 늘림)\n",
    "    rows = (num_slices * 2 + cols - 1) // cols  # 올림 계산\n",
    "    \n",
    "    # 그리드 생성\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(len(axes)):\n",
    "        slice_idx = i // 2  # 이미지-라벨 쌍\n",
    "        if slice_idx < num_slices:\n",
    "            if i % 2 == 0:\n",
    "                # 이미지 슬라이스\n",
    "                slice_img = image_tensor.take(slice_idx, axis=axis)\n",
    "                axes[i].imshow(slice_img, cmap=\"gray\")\n",
    "                axes[i].set_title(f\"Image Slice {slice_idx}\")\n",
    "            else:\n",
    "                # 라벨 슬라이스\n",
    "                slice_label = label_tensor.take(slice_idx, axis=axis)\n",
    "                axes[i].imshow(slice_label, cmap=\"viridis\")  # 컬러 맵을 사용해 시각화\n",
    "                axes[i].set_title(f\"Label Slice {slice_idx}\")\n",
    "        else:\n",
    "            axes[i].axis(\"off\")  # 비어 있는 서브플롯 비활성화\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 예제: 이미지와 라벨 시각화\n",
    "image_tensor = torch.load(\"./sample_dataset/train/images/image_8.tensor\")  # (1, depth, width, height)\n",
    "label_tensor = torch.load(\"./sample_dataset/train/labels/label_8.tensor\")  # (1, depth, width, height)\n",
    "\n",
    "visualize_3d_tensor_with_labels_as_grid(image_tensor, label_tensor, axis=0, cols=8)  # depth 축 기준\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
