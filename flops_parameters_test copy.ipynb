{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from thop import profile\n",
    "import torch\n",
    "from torch.profiler import ProfilerActivity\n",
    "from torch.profiler import profile as profilee\n",
    "    \n",
    "def print_model_summary(model, input_size):\n",
    "    input_tensor = torch.randn(input_size)\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"FLOPs: {flops:,}, GFLOPs: {flops / 1e9:.2f}\")\n",
    "    print(f\"Parameters: {params:,}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def profile_model(model, input_size, log_dir='./log'):\n",
    "\n",
    "    input_tensor = torch.randn(input_size)\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    # 프로파일링\n",
    "    with profilee(\n",
    "        activities=[\n",
    "            ProfilerActivity.CPU, \n",
    "            ProfilerActivity.CUDA\n",
    "        ],\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(log_dir),  # TensorBoard 연동\n",
    "        record_shapes=True,\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        model(input_tensor)\n",
    "\n",
    "    # 프로파일링 결과 출력\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/thop/vision/calc_func.py:53: UserWarning: This API is being deprecated\n",
      "  warnings.warn(\"This API is being deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: UNet_CBAM_bw\n",
      "FLOPs: 47,617,304,064.0, GFLOPs: 47.62\n",
      "Parameters: 870,050.0\n",
      "--------------------------------------------------\n",
      "UNet_CBAM_bw(\n",
      "  (encoder1): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(48, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder3): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(64, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(80, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder3): c_Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(160, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (skip_cbam): CBAM3D(\n",
      "      (channel_attention): ChannelAttention3D(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=80, out_features=10, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=10, out_features=80, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (spatial_attention): SpatialAttention3D(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cbam): CBAM3D(\n",
      "      (channel_attention): ChannelAttention3D(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (spatial_attention): SpatialAttention3D(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder2): c_Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(128, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (skip_cbam): CBAM3D(\n",
      "      (channel_attention): ChannelAttention3D(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (spatial_attention): SpatialAttention3D(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cbam): CBAM3D(\n",
      "      (channel_attention): ChannelAttention3D(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=6, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=6, out_features=48, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (spatial_attention): SpatialAttention3D(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder1): c_Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(96, 7, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    )\n",
      "    (skip_cbam): CBAM3D(\n",
      "      (channel_attention): ChannelAttention3D(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=6, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=6, out_features=48, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (spatial_attention): SpatialAttention3D(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cbam): CBAM3D(\n",
      "      (channel_attention): ChannelAttention3D(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=7, out_features=0, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=0, out_features=7, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (spatial_attention): SpatialAttention3D(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder0): c_Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(96, 1, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    )\n",
      "    (skip_cbam): CBAM3D(\n",
      "      (channel_attention): ChannelAttention3D(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=6, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=6, out_features=48, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (spatial_attention): SpatialAttention3D(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cbam): CBAM3D(\n",
      "      (channel_attention): ChannelAttention3D(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=0, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=0, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (spatial_attention): SpatialAttention3D(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv3d() received an invalid combination of arguments - got (tuple, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!tuple of (int, int, int, int, int)!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!tuple of (int, int, int, int, int)!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# 최종 Loss\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pos_loss \u001b[38;5;241m+\u001b[39m neg_loss\n\u001b[0;32m---> 54\u001b[0m x_c, x_iou \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_c\u001b[38;5;241m.\u001b[39mshape, x_iou\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Workspace/czll/src/models/unet_cbam_bw.py:202\u001b[0m, in \u001b[0;36mUNet_CBAM_bw.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 202\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder2(x1)\n\u001b[1;32m    204\u001b[0m     x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder3(x2)\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Workspace/czll/src/models/unet_block.py:186\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/UM2/lib/python3.12/site-packages/torch/nn/modules/conv.py:720\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    710\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    719\u001b[0m     )\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv3d() received an invalid combination of arguments - got (tuple, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!tuple of (int, int, int, int, int)!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!tuple of (int, int, int, int, int)!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !int!)\n"
     ]
    }
   ],
   "source": [
    "from src.models import UNet_CBAM_bw\n",
    "\n",
    "model = UNet_CBAM_bw(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "x = (1, 1, 32, 96, 96)\n",
    "print_model_summary(model, x)\n",
    "\n",
    "print(model)\n",
    "\n",
    "def qfl_loss(cls_pred, quality_pred, gt, beta=2.0):\n",
    "    \"\"\"\n",
    "    Quality Focal Loss for segmentation tasks.\n",
    "    \n",
    "    Args:\n",
    "        cls_pred: Class probabilities [B, C, D, H, W].\n",
    "        quality_pred: Predicted quality scores [B, 1, D, H, W].\n",
    "        gt: Ground truth segmentation mask [B, D, H, W].\n",
    "        beta: Focal Loss hyperparameter.\n",
    "    \n",
    "    Returns:\n",
    "        Loss value (scalar).\n",
    "    \"\"\"\n",
    "    # One-hot encode the ground truth mask\n",
    "    num_classes = cls_pred.shape[1]\n",
    "    gt_onehot = torch.nn.functional.one_hot(gt, num_classes=num_classes).permute(0, 4, 1, 2, 3)  # [B, C, D, H, W]\n",
    "    \n",
    "    # Softmax for class probabilities\n",
    "    prob = torch.softmax(cls_pred, dim=1)  # [B, C, D, H, W]\n",
    "    \n",
    "    # 품질 점수를 IoU로 예측했다고 가정 (Sigmoid 사용)\n",
    "    quality = torch.sigmoid(quality_pred)  # [B, 1, D, H, W]\n",
    "\n",
    "    # Positive Loss: Ground truth mask가 있는 위치에서의 Loss\n",
    "    pos_mask = gt_onehot == 1\n",
    "    pos_loss = -((1 - prob)**2) * torch.log(prob) * quality  # [B, C, D, H, W]\n",
    "    pos_loss = pos_loss[pos_mask].mean()  # Positive 영역 Loss\n",
    "\n",
    "    # Negative Loss: Ground truth가 없는 위치에서의 Loss\n",
    "    neg_mask = gt_onehot == 0\n",
    "    neg_loss = -(prob**beta) * torch.log(1 - prob) * (1 - quality)  # [B, C, D, H, W]\n",
    "    neg_loss = neg_loss[neg_mask].mean()  # Negative 영역 Loss\n",
    "\n",
    "    # 최종 Loss\n",
    "    return pos_loss + neg_loss\n",
    "\n",
    "x_c, x_iou = model(x)\n",
    "print(x_c.shape, x_iou.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: FlexibleUNet\n",
      "FLOPs: 81,743,486,976.0, GFLOPs: 81.74\n",
      "Parameters: 2,238,569.0\n",
      "--------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\thop\\vision\\calc_func.py:57: UserWarning: This API is being deprecated\n",
      "  warnings.warn(\"This API is being deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FlexibleUNet\n",
      "FLOPs: 82,763,145,216.0, GFLOPs: 82.76\n",
      "Parameters: 4,008,298.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models import *\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "\n",
    "enc_channels = (32, 64, 128, 256)\n",
    "enc_strides = (2, 2, 2)\n",
    "num_layers_enc1 = (1, 1, 1, 1)\n",
    "num_layers_enc2 = (1, 1, 1, 2)\n",
    "\n",
    "core_channels = 64\n",
    "dec_channels = (128, 64, 32)\n",
    "dec_strides = (2, 2, 2)\n",
    "num_layers_dec = (1, 1, 1)\n",
    "\n",
    "skip_map = {\n",
    "    0: [(\"enc\", 2)],       # 디코더0 => 인코더2\n",
    "    1: [(\"enc\", 3), (\"enc\", 1)],  # 디코더1 => 인코더1 + 디코더0\n",
    "    2: [(\"enc\", 3), (\"dec\", 0), (\"enc\", 0)]   # 디코더2 => 인코더0 + 디코더1\n",
    "}\n",
    "\n",
    "net1 = FlexibleUNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        encoder_channels=enc_channels,\n",
    "        encoder_strides=enc_strides,\n",
    "        core_channels=core_channels,\n",
    "        decoder_channels=dec_channels,\n",
    "        decoder_strides=dec_strides,\n",
    "        num_layers_encoder=num_layers_enc1,\n",
    "        num_layers_decoder=num_layers_dec,\n",
    "        skip_connections=skip_map,\n",
    "        kernel_size=3,\n",
    "        up_kernel_size=3,\n",
    "        act=Act.PRELU,\n",
    "        norm=Norm.INSTANCE,\n",
    "        dropout=0.0,\n",
    "        bias=True,\n",
    "        mode=\"trilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "net2 = FlexibleUNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        encoder_channels=enc_channels,\n",
    "        encoder_strides=enc_strides,\n",
    "        core_channels=core_channels,\n",
    "        decoder_channels=dec_channels,\n",
    "        decoder_strides=dec_strides,\n",
    "        num_layers_encoder=num_layers_enc2,\n",
    "        num_layers_decoder=num_layers_dec,\n",
    "        skip_connections=skip_map,\n",
    "        kernel_size=3,\n",
    "        up_kernel_size=3,\n",
    "        act=Act.PRELU,\n",
    "        norm=Norm.INSTANCE,\n",
    "        dropout=0.0,\n",
    "        bias=True,\n",
    "        mode=\"trilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "x = (1, 1, 96, 96, 32)\n",
    "print_model_summary(net1, x)\n",
    "print_model_summary(net2, x)\n",
    "# profile_model(net, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: DP_UNet\n",
      "FLOPs: 32,260,349,952.0, GFLOPs: 32.26\n",
      "Parameters: 836,169.0\n",
      "--------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: UNet\n",
      "FLOPs: 34,904,825,856.0, GFLOPs: 34.90\n",
      "Parameters: 1,948,909.0\n",
      "--------------------------------------------------\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    aten::conv3d         0.02%      26.875us        11.04%      18.805ms       2.351ms             8  \n",
      "               aten::convolution         0.08%     132.331us        87.29%     148.720ms      13.520ms            11  \n",
      "              aten::_convolution         0.18%     305.711us        87.21%     148.588ms      13.508ms            11  \n",
      "               aten::slow_conv3d         0.01%      18.916us        10.94%      18.637ms       2.330ms             8  \n",
      "       aten::slow_conv3d_forward         9.97%      16.985ms        10.93%      18.618ms       2.327ms             8  \n",
      "                     aten::empty         0.06%     101.917us         0.06%     101.917us       1.477us            69  \n",
      "                      aten::view         0.06%     103.957us         0.06%     103.957us       2.736us            38  \n",
      "                   aten::resize_         1.47%       2.496ms         1.47%       2.496ms     226.921us            11  \n",
      "                   aten::reshape         0.01%      16.583us         0.03%      46.373us       3.312us            14  \n",
      "                     aten::copy_         0.92%       1.563ms         0.92%       1.563ms     195.412us             8  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 170.384ms\n",
      "\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    aten::conv3d         0.01%      21.375us        18.47%      39.050ms       9.763ms             4  \n",
      "               aten::convolution         0.07%     150.710us        89.99%     190.263ms      27.180ms             7  \n",
      "              aten::_convolution         0.04%      90.500us        89.92%     190.112ms      27.159ms             7  \n",
      "               aten::slow_conv3d         0.02%      39.625us        18.40%      38.894ms       9.724ms             4  \n",
      "       aten::slow_conv3d_forward        17.59%      37.187ms        18.38%      38.855ms       9.714ms             4  \n",
      "                     aten::empty         0.07%     150.252us         0.07%     150.252us       2.312us            65  \n",
      "                      aten::view         0.07%     156.128us         0.07%     156.128us       6.005us            26  \n",
      "                   aten::resize_         1.20%       2.534ms         1.20%       2.534ms     361.996us             7  \n",
      "                   aten::reshape         0.01%      16.459us         0.03%      59.751us       5.975us            10  \n",
      "                     aten::copy_         0.74%       1.563ms         0.74%       1.563ms     390.752us             4  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 211.428ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models import DP_UNet\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "unet_dp = DP_UNet(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(32,64,128,256,512),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "unet = UNet(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(32,64,128,256),\n",
    "    strides=(2, 2, 2),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "x = (1, 1, 96, 96, 96)\n",
    "print_model_summary(unet_dp, x)\n",
    "print_model_summary(unet, x)\n",
    "\n",
    "profile_model(unet_dp, x)\n",
    "profile_model(unet, x)\n",
    "\n",
    "# print(unet_dp)\n",
    "# print(\"====================================\")\n",
    "# print(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: UNet\n",
      "FLOPs: 43,854,151,680.0, GFLOPs: 43.85\n",
      "Parameters: 856,189.0\n",
      "--------------------------------------------------\n",
      "UNet(\n",
      "  (model): Sequential(\n",
      "    (0): Convolution(\n",
      "      (conv): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (1): SkipConnection(\n",
      "      (submodule): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): Conv3d(48, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (1): SkipConnection(\n",
      "          (submodule): Sequential(\n",
      "            (0): Convolution(\n",
      "              (conv): Conv3d(64, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                (D): Dropout(p=0.0, inplace=False)\n",
      "                (A): PReLU(num_parameters=1)\n",
      "              )\n",
      "            )\n",
      "            (1): SkipConnection(\n",
      "              (submodule): Convolution(\n",
      "                (conv): Conv3d(80, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "                (adn): ADN(\n",
      "                  (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                  (D): Dropout(p=0.0, inplace=False)\n",
      "                  (A): PReLU(num_parameters=1)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): Convolution(\n",
      "              (conv): ConvTranspose3d(160, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                (D): Dropout(p=0.0, inplace=False)\n",
      "                (A): PReLU(num_parameters=1)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Convolution(\n",
      "          (conv): ConvTranspose3d(128, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Convolution(\n",
      "      (conv): ConvTranspose3d(96, 7, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import UNet\n",
    "\n",
    "model = UNet(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "x = (1, 1, 96, 96, 96)\n",
    "print_model_summary(model, x)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/thop/vision/calc_func.py:53: UserWarning: This API is being deprecated\n",
      "  warnings.warn(\"This API is being deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: UNet\n",
      "FLOPs: 43,854,151,680.0, GFLOPs: 43.85\n",
      "Parameters: 856,189.0\n",
      "--------------------------------------------------\n",
      "UNet(\n",
      "  (encoder1): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(48, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder3): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(64, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(80, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder3): Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(160, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder2): Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(128, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder1): Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(96, 7, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.models import UNet\n",
    "\n",
    "model = UNet(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "x = (1, 1, 96, 96, 96)\n",
    "print_model_summary(model, x)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: UNETR\n",
      "FLOPs: 82,521,317,376.0, GFLOPs: 82.52\n",
      "Parameters: 92,617,937.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import UNETR\n",
    "\n",
    "model = UNETR(\n",
    "    img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    # channels=(16, 32, 64, 128, 256),\n",
    "    # strides=(2, 2, 2, 2),\n",
    "    # num_res_units=2,\n",
    ")\n",
    "\n",
    "x = (1, 1, 96, 96, 96)\n",
    "print_model_summary(model, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: CSPBlock\n",
      "FLOPs: 51,640,270,848.0, GFLOPs: 51.64\n",
      "Parameters: 466,944.0\n",
      "--------------------------------------------------\n",
      "UnetResBlock Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm3d'>.\n",
      "Model: UnetResBlock\n",
      "FLOPs: 74,459,381,760.0, GFLOPs: 74.46\n",
      "Parameters: 672,512.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models import CSPBlock, UnetResBlock\n",
    "\n",
    "\n",
    "in_channels = 64\n",
    "out_channels = 128\n",
    "imgsz  = 96\n",
    "block = CSPBlock(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,  # 입력 채널 수정\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=2,\n",
    "        norm_name=\"batch\",\n",
    "        act_name=(\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout=None,\n",
    "        split_ratio=0.5,\n",
    "        n=2\n",
    "    )\n",
    "x = (1, in_channels, imgsz, imgsz, imgsz)\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinTransformer Summary:\")\n",
    "print_model_summary(block, x)\n",
    "\n",
    "block = UnetResBlock(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=2,\n",
    "        norm_name=\"batch\",\n",
    "        act_name=(\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout=None,\n",
    "     \n",
    "    )\n",
    "\n",
    "# Print summaries\n",
    "print(\"UnetResBlock Summary:\")\n",
    "print_model_summary(block, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "align_corners=True 실행 시간: 0.007005초\n",
      "align_corners=False 실행 시간: 0.003999초\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# 입력 텐서\n",
    "x = torch.randn(1, 1, 8, 8, 8).cuda()\n",
    "\n",
    "# 업샘플링 설정\n",
    "upsample1 = torch.nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "upsample2 = torch.nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False)\n",
    "\n",
    "# align_corners=True 실행 시간\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y1 = upsample1(x)\n",
    "end = time.time()\n",
    "print(f\"align_corners=True 실행 시간: {end - start:.6f}초\")\n",
    "\n",
    "# align_corners=False 실행 시간\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y2 = upsample2(x)\n",
    "end = time.time()\n",
    "print(f\"align_corners=False 실행 시간: {end - start:.6f}초\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\monai\\utils\\deprecate_utils.py:221: FutureWarning: src.models.swincspunetr3plus SwinCSPUNETR3plus.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNETR_unet Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: SwinCSPUNETR3plus\n",
      "FLOPs: 629,032,886,808.0, GFLOPs: 629.03\n",
      "Parameters: 55,484,983.0\n",
      "--------------------------------------------------\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::convolution         0.08%       4.685ms        65.63%        3.667s      33.033ms       4.690ms         0.08%        3.669s      33.050ms           111  \n",
      "               aten::_convolution         2.05%     114.594ms        65.55%        3.662s      32.991ms     114.088ms         2.04%        3.664s      33.008ms           111  \n",
      "                     aten::conv3d         0.05%       2.679ms        62.19%        3.475s      31.587ms       2.522ms         0.05%        3.476s      31.602ms           110  \n",
      "         aten::mkldnn_convolution        57.84%        3.232s        57.90%        3.235s      46.211ms        3.234s        57.72%        3.237s      46.236ms            70  \n",
      "       aten::upsample_trilinear3d         8.66%     484.038ms         8.67%     484.214ms      48.421ms     483.522ms         8.63%     484.378ms      48.438ms            10  \n",
      "                     aten::matmul         0.33%      18.417ms         6.30%     352.062ms      17.603ms      17.024ms         0.30%     352.497ms      17.625ms            20  \n",
      "                    aten::softmax         0.01%     527.600us         6.05%     338.000ms      42.250ms     132.000us         0.00%     338.217ms      42.277ms             8  \n",
      "                   aten::_softmax         6.04%     337.472ms         6.04%     337.472ms      42.184ms     338.085ms         6.03%     338.085ms      42.261ms             8  \n",
      "                        aten::bmm         5.38%     300.610ms         5.38%     300.626ms      18.789ms     301.502ms         5.38%     301.674ms      18.855ms            16  \n",
      "                        aten::add         4.98%     278.063ms         4.98%     278.063ms       5.916ms     280.261ms         5.00%     280.261ms       5.963ms            47  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.587s\n",
      "Self CUDA time total: 5.602s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models.swincspunetr3plus import SwinCSPUNETR3plus\n",
    "x = (1, 1, 96, 96, 96)\n",
    "swin_unetr = SwinCSPUNETR3plus(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNETR_unet Summary:\")\n",
    "print_model_summary(swin_unetr, x)\n",
    "\n",
    "# Call the function\n",
    "profile_model(swin_unetr, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: src.models.swincspunetr SwinCSPUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNETR Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: SwinCSPUNETR\n",
      "FLOPs: 289,518,045,720.0, GFLOPs: 289.52\n",
      "Parameters: 62,104,375.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models.swincspunetr import SwinCSPUNETR\n",
    "x = (1, 1, 96, 96, 96)\n",
    "swin_unetr = SwinCSPUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNETR Summary:\")\n",
    "print_model_summary(swin_unetr, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete SwinUNETR Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "torch.Size([1, 48, 48, 48, 48])\n",
      "torch.Size([1, 96, 24, 24, 24])\n",
      "torch.Size([1, 192, 12, 12, 12])\n",
      "torch.Size([1, 384, 6, 6, 6])\n",
      "torch.Size([1, 768, 3, 3, 3])\n",
      "enc0: torch.Size([1, 48, 96, 96, 96])\n",
      "enc1 torch.Size([1, 48, 48, 48, 48])\n",
      "torch.Size([1, 96, 24, 24, 24])\n",
      "torch.Size([1, 192, 12, 12, 12])\n",
      "torch.Size([1, 768, 3, 3, 3])\n",
      "Model: SwinUNETR\n",
      "FLOPs: 355,370,190,360.0, GFLOPs: 355.37\n",
      "Parameters: 72,564,583.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example model\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import SwinUNETR, SwinTransformer\n",
    "\n",
    "# SwinTransformer 테스트\n",
    "swin_transformer = SwinTransformer(\n",
    "    in_chans=1,\n",
    "    embed_dim=48,\n",
    "    window_size=(7, 7, 7),\n",
    "    patch_size=(2, 2, 2),\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    mlp_ratio=4.0,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_path_rate=0.0,\n",
    "    norm_layer=nn.LayerNorm,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "# 전체 SwinUNETR 모델\n",
    "swin_unetr = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "# Input sizes\n",
    "swin_transformer_input = (1, 1, 96, 96, 96)\n",
    "swin_unetr_input = (1, 1, 96, 96, 96)\n",
    "\n",
    "# # Print summaries\n",
    "# print(\"SwinTransformer Summary:\")\n",
    "# print_model_summary(swin_transformer, swin_transformer_input)\n",
    "\n",
    "print(\"\\nComplete SwinUNETR Summary:\")\n",
    "print_model_summary(swin_unetr, swin_unetr_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([1, 48, 48, 48, 48])\n",
    "torch.Size([1, 96, 24, 24, 24])\n",
    "torch.Size([1, 192, 12, 12, 12])\n",
    "torch.Size([1, 384, 6, 6, 6])\n",
    "torch.Size([1, 768, 3, 3, 3])\n",
    "enc0: torch.Size([1, 48, 96, 96, 96])\n",
    "enc1 torch.Size([1, 48, 48, 48, 48])\n",
    "torch.Size([1, 96, 24, 24, 24])\n",
    "torch.Size([1, 192, 12, 12, 12])\n",
    "torch.Size([1, 768, 3, 3, 3])\n",
    "Model: SwinUNETR\n",
    "FLOPs: 329,543,087,640.0, GFLOPs: 329.54\n",
    "Parameters: 61,989,223.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
