{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from thop import profile\n",
    "import torch\n",
    "from torch.profiler import ProfilerActivity\n",
    "from torch.profiler import profile as profilee\n",
    "    \n",
    "def print_model_summary(model, input_size):\n",
    "    input_tensor = torch.randn(input_size)\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"FLOPs: {flops:,}, GFLOPs: {flops / 1e9:.2f}\")\n",
    "    print(f\"Parameters: {params:,}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def profile_model(model, input_size, log_dir='./log'):\n",
    "\n",
    "    input_tensor = torch.randn(input_size)\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    # 프로파일링\n",
    "    with profilee(\n",
    "        activities=[\n",
    "            ProfilerActivity.CPU, \n",
    "            ProfilerActivity.CUDA\n",
    "        ],\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(log_dir),  # TensorBoard 연동\n",
    "        record_shapes=True,\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        model(input_tensor)\n",
    "\n",
    "    # 프로파일링 결과 출력\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: DP_UNet\n",
      "FLOPs: 3,459,538,944.0, GFLOPs: 3.46\n",
      "Parameters: 95,183.0\n",
      "--------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: UNet\n",
      "FLOPs: 34,904,825,856.0, GFLOPs: 34.90\n",
      "Parameters: 1,948,909.0\n",
      "--------------------------------------------------\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    aten::conv3d         0.01%      40.664us         9.50%      66.907ms       6.082ms            11  \n",
      "               aten::convolution         0.02%     155.708us        94.24%     663.830ms      47.416ms            14  \n",
      "              aten::_convolution         4.31%      30.369ms        94.22%     663.674ms      47.405ms            14  \n",
      "               aten::slow_conv3d         0.00%      29.667us         9.47%      66.675ms       6.061ms            11  \n",
      "       aten::slow_conv3d_forward         8.89%      62.630ms         9.46%      66.645ms       6.059ms            11  \n",
      "                     aten::empty         0.15%       1.062ms         0.15%       1.062ms       0.577us          1839  \n",
      "                      aten::view         0.02%     160.292us         0.02%     160.292us       2.466us            65  \n",
      "                   aten::resize_         0.35%       2.484ms         0.35%       2.484ms       4.231us           587  \n",
      "                   aten::reshape         0.00%      25.086us         0.01%      69.418us       3.018us            23  \n",
      "                     aten::copy_         0.56%       3.927ms         0.56%       3.927ms     357.032us            11  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 704.382ms\n",
      "\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    aten::conv3d         0.01%      14.959us        21.08%      26.373ms       6.593ms             4  \n",
      "               aten::convolution         0.06%      76.377us        88.50%     110.728ms      15.818ms             7  \n",
      "              aten::_convolution         0.04%      50.333us        88.44%     110.651ms      15.807ms             7  \n",
      "               aten::slow_conv3d         0.01%      12.708us        21.01%      26.283ms       6.571ms             4  \n",
      "       aten::slow_conv3d_forward        20.29%      25.387ms        21.00%      26.271ms       6.568ms             4  \n",
      "                     aten::empty         0.05%      61.455us         0.05%      61.455us       0.945us            65  \n",
      "                      aten::view         0.07%      93.088us         0.07%      93.088us       3.580us            26  \n",
      "                   aten::resize_         1.37%       1.720ms         1.37%       1.720ms     245.708us             7  \n",
      "                   aten::reshape         0.01%      10.166us         0.03%      36.501us       3.650us            10  \n",
      "                     aten::copy_         0.67%     843.831us         0.67%     843.831us     210.958us             4  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 125.121ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models import DP_UNet\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "unet_dp = DP_UNet(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(32,64,128,256),\n",
    "    strides=(2, 2, 2),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "unet = UNet(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(32,64,128,256),\n",
    "    strides=(2, 2, 2),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "x = (1, 1, 96, 96, 96)\n",
    "print_model_summary(unet_dp, x)\n",
    "print_model_summary(unet, x)\n",
    "\n",
    "profile_model(unet_dp, x)\n",
    "profile_model(unet, x)\n",
    "# print(unet_dp)\n",
    "# print(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: UNet\n",
      "FLOPs: 43,854,151,680.0, GFLOPs: 43.85\n",
      "Parameters: 856,189.0\n",
      "--------------------------------------------------\n",
      "UNet(\n",
      "  (model): Sequential(\n",
      "    (0): Convolution(\n",
      "      (conv): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (1): SkipConnection(\n",
      "      (submodule): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): Conv3d(48, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (1): SkipConnection(\n",
      "          (submodule): Sequential(\n",
      "            (0): Convolution(\n",
      "              (conv): Conv3d(64, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                (D): Dropout(p=0.0, inplace=False)\n",
      "                (A): PReLU(num_parameters=1)\n",
      "              )\n",
      "            )\n",
      "            (1): SkipConnection(\n",
      "              (submodule): Convolution(\n",
      "                (conv): Conv3d(80, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "                (adn): ADN(\n",
      "                  (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                  (D): Dropout(p=0.0, inplace=False)\n",
      "                  (A): PReLU(num_parameters=1)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): Convolution(\n",
      "              (conv): ConvTranspose3d(160, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                (D): Dropout(p=0.0, inplace=False)\n",
      "                (A): PReLU(num_parameters=1)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Convolution(\n",
      "          (conv): ConvTranspose3d(128, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Convolution(\n",
      "      (conv): ConvTranspose3d(96, 7, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import UNet\n",
    "\n",
    "model = UNet(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "x = (1, 1, 96, 96, 96)\n",
    "print_model_summary(model, x)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/thop/vision/calc_func.py:53: UserWarning: This API is being deprecated\n",
      "  warnings.warn(\"This API is being deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: UNet\n",
      "FLOPs: 43,854,151,680.0, GFLOPs: 43.85\n",
      "Parameters: 856,189.0\n",
      "--------------------------------------------------\n",
      "UNet(\n",
      "  (encoder1): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(48, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder3): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(64, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): Encoder(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(80, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder3): Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(160, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder2): Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(128, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder1): Decoder(\n",
      "    (conv1): Convolution(\n",
      "      (conv): ConvTranspose3d(96, 7, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.models import UNet\n",
    "\n",
    "model = UNet(\n",
    "    # img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    # num_res_units=0,\n",
    ")\n",
    "\n",
    "x = (1, 1, 96, 96, 96)\n",
    "print_model_summary(model, x)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: UNETR\n",
      "FLOPs: 82,521,317,376.0, GFLOPs: 82.52\n",
      "Parameters: 92,617,937.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import UNETR\n",
    "\n",
    "model = UNETR(\n",
    "    img_size = (96, 96, 96),\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    # channels=(16, 32, 64, 128, 256),\n",
    "    # strides=(2, 2, 2, 2),\n",
    "    # num_res_units=2,\n",
    ")\n",
    "\n",
    "x = (1, 1, 96, 96, 96)\n",
    "print_model_summary(model, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Model: CSPBlock\n",
      "FLOPs: 51,640,270,848.0, GFLOPs: 51.64\n",
      "Parameters: 466,944.0\n",
      "--------------------------------------------------\n",
      "UnetResBlock Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm3d'>.\n",
      "Model: UnetResBlock\n",
      "FLOPs: 74,459,381,760.0, GFLOPs: 74.46\n",
      "Parameters: 672,512.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models import CSPBlock, UnetResBlock\n",
    "\n",
    "\n",
    "in_channels = 64\n",
    "out_channels = 128\n",
    "imgsz  = 96\n",
    "block = CSPBlock(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,  # 입력 채널 수정\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=2,\n",
    "        norm_name=\"batch\",\n",
    "        act_name=(\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout=None,\n",
    "        split_ratio=0.5,\n",
    "        n=2\n",
    "    )\n",
    "x = (1, in_channels, imgsz, imgsz, imgsz)\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinTransformer Summary:\")\n",
    "print_model_summary(block, x)\n",
    "\n",
    "block = UnetResBlock(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=2,\n",
    "        norm_name=\"batch\",\n",
    "        act_name=(\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout=None,\n",
    "     \n",
    "    )\n",
    "\n",
    "# Print summaries\n",
    "print(\"UnetResBlock Summary:\")\n",
    "print_model_summary(block, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "align_corners=True 실행 시간: 0.007005초\n",
      "align_corners=False 실행 시간: 0.003999초\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# 입력 텐서\n",
    "x = torch.randn(1, 1, 8, 8, 8).cuda()\n",
    "\n",
    "# 업샘플링 설정\n",
    "upsample1 = torch.nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "upsample2 = torch.nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False)\n",
    "\n",
    "# align_corners=True 실행 시간\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y1 = upsample1(x)\n",
    "end = time.time()\n",
    "print(f\"align_corners=True 실행 시간: {end - start:.6f}초\")\n",
    "\n",
    "# align_corners=False 실행 시간\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y2 = upsample2(x)\n",
    "end = time.time()\n",
    "print(f\"align_corners=False 실행 시간: {end - start:.6f}초\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\monai\\utils\\deprecate_utils.py:221: FutureWarning: src.models.swincspunetr3plus SwinCSPUNETR3plus.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNETR_unet Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: SwinCSPUNETR3plus\n",
      "FLOPs: 629,032,886,808.0, GFLOPs: 629.03\n",
      "Parameters: 55,484,983.0\n",
      "--------------------------------------------------\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::convolution         0.08%       4.685ms        65.63%        3.667s      33.033ms       4.690ms         0.08%        3.669s      33.050ms           111  \n",
      "               aten::_convolution         2.05%     114.594ms        65.55%        3.662s      32.991ms     114.088ms         2.04%        3.664s      33.008ms           111  \n",
      "                     aten::conv3d         0.05%       2.679ms        62.19%        3.475s      31.587ms       2.522ms         0.05%        3.476s      31.602ms           110  \n",
      "         aten::mkldnn_convolution        57.84%        3.232s        57.90%        3.235s      46.211ms        3.234s        57.72%        3.237s      46.236ms            70  \n",
      "       aten::upsample_trilinear3d         8.66%     484.038ms         8.67%     484.214ms      48.421ms     483.522ms         8.63%     484.378ms      48.438ms            10  \n",
      "                     aten::matmul         0.33%      18.417ms         6.30%     352.062ms      17.603ms      17.024ms         0.30%     352.497ms      17.625ms            20  \n",
      "                    aten::softmax         0.01%     527.600us         6.05%     338.000ms      42.250ms     132.000us         0.00%     338.217ms      42.277ms             8  \n",
      "                   aten::_softmax         6.04%     337.472ms         6.04%     337.472ms      42.184ms     338.085ms         6.03%     338.085ms      42.261ms             8  \n",
      "                        aten::bmm         5.38%     300.610ms         5.38%     300.626ms      18.789ms     301.502ms         5.38%     301.674ms      18.855ms            16  \n",
      "                        aten::add         4.98%     278.063ms         4.98%     278.063ms       5.916ms     280.261ms         5.00%     280.261ms       5.963ms            47  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.587s\n",
      "Self CUDA time total: 5.602s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models.swincspunetr3plus import SwinCSPUNETR3plus\n",
    "x = (1, 1, 96, 96, 96)\n",
    "swin_unetr = SwinCSPUNETR3plus(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNETR_unet Summary:\")\n",
    "print_model_summary(swin_unetr, x)\n",
    "\n",
    "# Call the function\n",
    "profile_model(swin_unetr, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungwanlim/miniconda3/envs/UM2/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: src.models.swincspunetr SwinCSPUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinCSPUNETR Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "Model: SwinCSPUNETR\n",
      "FLOPs: 289,518,045,720.0, GFLOPs: 289.52\n",
      "Parameters: 62,104,375.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.models.swincspunetr import SwinCSPUNETR\n",
    "x = (1, 1, 96, 96, 96)\n",
    "swin_unetr = SwinCSPUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Print summaries\n",
    "print(\"SwinCSPUNETR Summary:\")\n",
    "print_model_summary(swin_unetr, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete SwinUNETR Summary:\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "torch.Size([1, 48, 48, 48, 48])\n",
      "torch.Size([1, 96, 24, 24, 24])\n",
      "torch.Size([1, 192, 12, 12, 12])\n",
      "torch.Size([1, 384, 6, 6, 6])\n",
      "torch.Size([1, 768, 3, 3, 3])\n",
      "enc0: torch.Size([1, 48, 96, 96, 96])\n",
      "enc1 torch.Size([1, 48, 48, 48, 48])\n",
      "torch.Size([1, 96, 24, 24, 24])\n",
      "torch.Size([1, 192, 12, 12, 12])\n",
      "torch.Size([1, 768, 3, 3, 3])\n",
      "Model: SwinUNETR\n",
      "FLOPs: 355,370,190,360.0, GFLOPs: 355.37\n",
      "Parameters: 72,564,583.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example model\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import SwinUNETR, SwinTransformer\n",
    "\n",
    "# SwinTransformer 테스트\n",
    "swin_transformer = SwinTransformer(\n",
    "    in_chans=1,\n",
    "    embed_dim=48,\n",
    "    window_size=(7, 7, 7),\n",
    "    patch_size=(2, 2, 2),\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    mlp_ratio=4.0,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_path_rate=0.0,\n",
    "    norm_layer=nn.LayerNorm,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "# 전체 SwinUNETR 모델\n",
    "swin_unetr = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    feature_size=48,\n",
    "    depths=(2, 2, 2, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    norm_name=\"instance\",\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    normalize=True,\n",
    "    use_checkpoint=True,\n",
    "    spatial_dims=3,\n",
    "    downsample=\"merging\",\n",
    "    use_v2=True\n",
    ")\n",
    "\n",
    "# Input sizes\n",
    "swin_transformer_input = (1, 1, 96, 96, 96)\n",
    "swin_unetr_input = (1, 1, 96, 96, 96)\n",
    "\n",
    "# # Print summaries\n",
    "# print(\"SwinTransformer Summary:\")\n",
    "# print_model_summary(swin_transformer, swin_transformer_input)\n",
    "\n",
    "print(\"\\nComplete SwinUNETR Summary:\")\n",
    "print_model_summary(swin_unetr, swin_unetr_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([1, 48, 48, 48, 48])\n",
    "torch.Size([1, 96, 24, 24, 24])\n",
    "torch.Size([1, 192, 12, 12, 12])\n",
    "torch.Size([1, 384, 6, 6, 6])\n",
    "torch.Size([1, 768, 3, 3, 3])\n",
    "enc0: torch.Size([1, 48, 96, 96, 96])\n",
    "enc1 torch.Size([1, 48, 48, 48, 48])\n",
    "torch.Size([1, 96, 24, 24, 24])\n",
    "torch.Size([1, 192, 12, 12, 12])\n",
    "torch.Size([1, 768, 3, 3, 3])\n",
    "Model: SwinUNETR\n",
    "FLOPs: 329,543,087,640.0, GFLOPs: 329.54\n",
    "Parameters: 61,989,223.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
