{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.34 available  Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mmetrics\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\pook0\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3cba70b666fa11b142e97ae6ea113837151ab5a42.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'classify', 'pose', 'obb', 'segment', 'detect'}\n                MODE (required) is one of {'predict', 'val', 'track', 'train', 'benchmark', 'export'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n    \n    5. Streamlit real-time webcam inference GUI\n        yolo streamlit-predict\n        \n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3508\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[2], line 23\u001b[0m\n    result = model.train(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\ultralytics\\engine\\model.py:796\u001b[0m in \u001b[0;35mtrain\u001b[0m\n    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:101\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:251\u001b[0m in \u001b[0;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:436\u001b[1;36m in \u001b[1;35mcheck_dict_alignment\u001b[1;36m\n\u001b[1;33m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>\u001b[1;36m\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '\u001b[31m\u001b[1mmetrics\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\pook0\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3cba70b666fa11b142e97ae6ea113837151ab5a42.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'classify', 'pose', 'obb', 'segment', 'detect'}\n                MODE (required) is one of {'predict', 'val', 'track', 'train', 'benchmark', 'export'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n    \n    5. Streamlit real-time webcam inference GUI\n        yolo streamlit-predict\n        \n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = YOLO('yolo11x.pt')\n",
    "    \n",
    "    result = model.train(\n",
    "        data='./data.yaml',\n",
    "        name=\"x_640_dropout025_hsv_\",\n",
    "        epochs=300,\n",
    "        patience=10,\n",
    "        device='0',\n",
    "        batch=12,\n",
    "        imgsz=640,\n",
    "        optimizer='AdamW',\n",
    "        lr0=0.001,\n",
    "        dropout=0.25,\n",
    "        # 실제 사용 가능한 loss 관련 파라미터\n",
    "        box=7.5,          # box loss gain (높여서 객체 검출 민감도 증가)\n",
    "        cls=0.5,          # cls loss gain\n",
    "        dfl=1.5,          # dfl loss gain\n",
    "        hsv_h=0.015,      # augmentation 파라미터 (데이터 증강으로 견고성 향상)\n",
    "        hsv_s=0.7,\n",
    "        hsv_v=0.4,\n",
    "        degrees=0.0,      # rotation\n",
    "        scale=0.2,        # scale\n",
    "        fliplr=0.5,       # flip left/right\n",
    "        mosaic=1.0,       # mosaic augmentation\n",
    "        mixup=0.1,        # mixup augmentation\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
