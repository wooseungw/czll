{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.data import DataLoader, Dataset, CacheDataset, decollate_batch\n",
    "import os\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    EnsureChannelFirstd, \n",
    "    Orientationd,  \n",
    "    AsDiscrete,  \n",
    "    RandFlipd, \n",
    "    RandRotate90d, \n",
    "    NormalizeIntensityd,\n",
    "    RandCropByLabelClassesd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"./datasets/train/images\"\n",
    "TRAIN_LABEL_DIR = \"./datasets/train/labels\"\n",
    "VAL_IMG_DIR = \"./datasets/val/images\"\n",
    "VAL_LABEL_DIR = \"./datasets/val/labels\"\n",
    "\n",
    "train_list = os.listdir(TRAIN_IMG_DIR)\n",
    "val_list = os.listdir(VAL_IMG_DIR)\n",
    "train_files = []\n",
    "valid_files = []\n",
    "\n",
    "\n",
    "for name in train_list:\n",
    "    train_image = np.load(os.path.join(TRAIN_IMG_DIR, f\"{name}\"))    \n",
    "    train_label = np.load(os.path.join(TRAIN_LABEL_DIR, f\"{name.replace(\"image\", \"label\")}\"))\n",
    "\n",
    "    train_files.append({\"image\": train_image, \"label\": train_label})    \n",
    "\n",
    "for name in val_list:\n",
    "    valid_image = np.load(os.path.join(VAL_IMG_DIR, f\"{name}\"))\n",
    "    valid_label = np.load(os.path.join(VAL_LABEL_DIR, f\"{name.replace(\"image\", \"label\")}\"))\n",
    "\n",
    "    valid_files.append({\"image\": valid_image, \"label\": valid_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 24/24 [00:03<00:00,  6.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Non-random transforms to be cached\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"ASR\")\n",
    "])\n",
    "\n",
    "raw_train_ds = CacheDataset(data=train_files, transform=non_random_transforms, cache_rate=1.0)\n",
    "\n",
    "\n",
    "my_num_samples = 1\n",
    "train_batch_size = 1\n",
    "\n",
    "xy_patch = 96\n",
    "z_patch = 3\n",
    "# Random transforms to be applied during training\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[z_patch, xy_patch, xy_patch],\n",
    "        num_classes=7,\n",
    "        num_samples=my_num_samples\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),    \n",
    "])\n",
    "\n",
    "\n",
    "train_ds = Dataset(data=raw_train_ds, transform=random_transforms)\n",
    "\n",
    "\n",
    "# DataLoader remains the same\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 배치 데이터 검증 ===\n",
      "이미지 shape: torch.Size([1, 1, 96, 96, 3])\n",
      "이미지 dtype: torch.float32\n",
      "이미지 값 범위: [-9.597, 4.349]\n",
      "\n",
      "\n",
      "라벨 shape: torch.Size([1, 1, 96, 96, 3])\n",
      "라벨 dtype: torch.uint8\n",
      "라벨 고유값: tensor([0, 1, 5, 6], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 검증 함수\n",
    "def inspect_batch(loader):\n",
    "    # 첫 번째 배치 가져오기\n",
    "    batch = next(iter(loader))\n",
    "    \n",
    "    print(\"=== 배치 데이터 검증 ===\")\n",
    "    print(f\"이미지 shape: {batch['image'].shape}\")\n",
    "    print(f\"이미지 dtype: {batch['image'].dtype}\")\n",
    "    print(f\"이미지 값 범위: [{batch['image'].min():.3f}, {batch['image'].max():.3f}]\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"라벨 shape: {batch['label'].shape}\")\n",
    "    print(f\"라벨 dtype: {batch['label'].dtype}\")\n",
    "    print(f\"라벨 고유값: {torch.unique(batch['label'])}\")\n",
    "\n",
    "# 실행\n",
    "inspect_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 26496/26496 [00:15<00:00, 1699.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "valid_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\")\n",
    "])\n",
    "\n",
    "def load_validation_patches(patch_dir):\n",
    "    \"\"\"\n",
    "    저장된 validation 패치들을 로드하여 데이터셋용 리스트 생성\n",
    "    Args:\n",
    "        patch_dir: 패치가 저장된 디렉토리 (images, labels 서브디렉토리와 coordinates.json 포함)\n",
    "    \"\"\"\n",
    "    patch_dir = Path(patch_dir)\n",
    "    val_patched_data = []\n",
    "    \n",
    "    # coordinates.json 로드\n",
    "    with open(patch_dir / \"coordinates.json\", 'r') as f:\n",
    "        coordinates = json.load(f)\n",
    "    \n",
    "    # 각 패치에 대해\n",
    "    for coord in coordinates:\n",
    "        image = np.load(patch_dir / \"images\" / coord[\"patch_file\"])\n",
    "        label = np.load(patch_dir / \"labels\" / coord[\"patch_file\"])\n",
    "        \n",
    "        val_patched_data.append({\n",
    "            \"image\": image,      # shape: (11, 96, 96)\n",
    "            \"label\": label,      # shape: (96, 96)\n",
    "            \"coords\": coord      # 원본 위치 정보 (옵션)\n",
    "        })\n",
    "    \n",
    "    return val_patched_data\n",
    "\n",
    "# 패치 데이터 로드\n",
    "val_patched_data = load_validation_patches(\"./datasets/val_patches\")\n",
    "\n",
    "# Dataset과 DataLoader 설정\n",
    "valid_ds = CacheDataset(data=val_patched_data, transform=valid_transforms, cache_rate=1.0)\n",
    "\n",
    "valid_batch_size = 1\n",
    "valid_loader = DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size=valid_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# raw_valid_ds = CacheDataset(data=valid_files, transform=non_random_transforms, cache_rate=1.0)\n",
    "# valid_ds = Dataset(data=raw_valid_ds, transform=random_transforms)\n",
    "# valid_batch_size = 1\n",
    "\n",
    "# # DataLoader remains the same\n",
    "# valid_loader = DataLoader(\n",
    "#     valid_ds,\n",
    "#     batch_size=valid_batch_size,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0,\n",
    "#     pin_memory=torch.cuda.is_available()\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 배치 데이터 검증 ===\n",
      "이미지 shape: torch.Size([1, 1, 3, 96, 96])\n",
      "이미지 dtype: torch.float32\n",
      "이미지 값 범위: [-4.900, 5.728]\n",
      "\n",
      "\n",
      "라벨 shape: torch.Size([1, 1, 96, 96])\n",
      "라벨 dtype: torch.uint8\n",
      "라벨 고유값: tensor([0, 5], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 검증 함수\n",
    "def inspect_batch(loader):\n",
    "    # 첫 번째 배치 가져오기\n",
    "    batch = next(iter(loader))\n",
    "    \n",
    "    print(\"=== 배치 데이터 검증 ===\")\n",
    "    print(f\"이미지 shape: {batch['image'].shape}\")\n",
    "    print(f\"이미지 dtype: {batch['image'].dtype}\")\n",
    "    print(f\"이미지 값 범위: [{batch['image'].min():.3f}, {batch['image'].max():.3f}]\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"라벨 shape: {batch['label'].shape}\")\n",
    "    print(f\"라벨 dtype: {batch['label'].dtype}\")\n",
    "    print(f\"라벨 고유값: {torch.unique(batch['label'])}\")\n",
    "\n",
    "# 실행\n",
    "inspect_batch(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
