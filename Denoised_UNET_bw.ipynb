{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.4.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.4.1+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 46a5272196a6c2590ca2589029eed8e4d56ff008\n",
      "MONAI __file__: c:\\Users\\<username>\\.conda\\envs\\UM\\Lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.3.2\n",
      "scikit-image version: 0.24.0\n",
      "scipy version: 1.14.1\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.18.0\n",
      "gdown version: 5.2.0\n",
      "TorchVision version: 0.19.1+cu121\n",
      "tqdm version: 4.66.5\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 6.0.0\n",
      "pandas version: 2.2.3\n",
      "einops version: 0.8.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: 2.17.2\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "# from src.models.swincspunetr import SwinCSPUNETR\n",
    "# from src.models.swincspunetr_unet import SwinCSPUNETR_unet\n",
    "# from src.models.swincspunetr3plus import SwinCSPUNETR3plus\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_info = {\n",
    "#     0: {\"name\": \"background\", \"weight\": 0},  # weight 없음\n",
    "#     1: {\"name\": \"apo-ferritin\", \"weight\": 1000},\n",
    "#     2: {\"name\": \"beta-amylase\", \"weight\": 100}, # 4130\n",
    "#     3: {\"name\": \"beta-galactosidase\", \"weight\": 1500}, #3080\n",
    "#     4: {\"name\": \"ribosome\", \"weight\": 1000},\n",
    "#     5: {\"name\": \"thyroglobulin\", \"weight\": 1500},\n",
    "#     6: {\"name\": \"virus-like-particle\", \"weight\": 1000},\n",
    "# }\n",
    "\n",
    "# # 가중치에 비례한 비율 계산\n",
    "# raw_ratios = {\n",
    "#     k: (v[\"weight\"] if v[\"weight\"] is not None else 0.01)  # 가중치 비례, None일 경우 기본값a\n",
    "#     for k, v in class_info.items()\n",
    "# }\n",
    "# total = sum(raw_ratios.values())\n",
    "# ratios = {k: v / total for k, v in raw_ratios.items()}\n",
    "\n",
    "# # 최종 합계가 1인지 확인\n",
    "# final_total = sum(ratios.values())\n",
    "# print(\"클래스 비율:\", ratios)\n",
    "# print(\"최종 합계:\", final_total)\n",
    "\n",
    "# # 비율을 리스트로 변환\n",
    "# ratios_list = [ratios[k] for k in sorted(ratios.keys())]\n",
    "# print(\"클래스 비율 리스트:\", ratios_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.dataset import create_dataloaders, create_dataloaders_bw\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, NormalizeIntensityd,\n",
    "    Orientationd, CropForegroundd, GaussianSmoothd, ScaleIntensityd,\n",
    "    RandSpatialCropd, RandRotate90d, RandFlipd, RandGaussianNoised,\n",
    "    ToTensord, RandCropByLabelClassesd, RandCropByPosNegLabeld, RandCropd, RandSpatialCrop,\n",
    ")\n",
    "from monai.transforms import CastToTyped\n",
    "import numpy as np\n",
    "\n",
    "train_img_dir = \"./denoised_datasets/train/images\"\n",
    "train_label_dir = \"./denoised_datasets/train/labels\"\n",
    "val_img_dir = \"./denoised_datasets/val/images\"\n",
    "val_label_dir = \"./denoised_datasets/val/labels\"\n",
    "# DATA CONFIG\n",
    "img_size =  96 # Match your patch size\n",
    "img_depth = img_size\n",
    "n_classes = 256\n",
    "batch_size = 16 # 13.8GB GPU memory required for 128x128 img size\n",
    "loader_batch = 1\n",
    "num_samples = batch_size // loader_batch # 한 이미지에서 뽑을 샘플 수\n",
    "num_repeat = 4\n",
    "# MODEL CONFIG\n",
    "num_epochs = 4000\n",
    "lamda = 0.5\n",
    "ce_weight = 0.4\n",
    "lr = 0.001\n",
    "feature_size = 48\n",
    "use_checkpoint = True\n",
    "use_v2 = True\n",
    "drop_rate= 0.25\n",
    "attn_drop_rate = 0.25\n",
    "num_bottleneck = 2\n",
    "# CLASS_WEIGHTS\n",
    "class_weights = None\n",
    "# class_weights = torch.tensor([0.0001, 1, 0.001, 1.1, 1, 1.1, 1], dtype=torch.float32)  # 클래스별 가중치\n",
    "sigma = 2.0\n",
    "accumulation_steps = 1\n",
    "# INIT\n",
    "start_epoch = 0\n",
    "best_val_loss = float('inf')\n",
    "best_val_fbeta_score = 0\n",
    "\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "])\n",
    "val_non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "])\n",
    "random_transforms = Compose([\n",
    "    RandCropd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        cropper=RandSpatialCrop(roi_size=[img_depth, img_size, img_size], random_center=True, random_size=False)\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[1, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 6/6 [00:00<00:00,  9.96it/s]\n",
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = None, None\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_img_dir, \n",
    "    train_label_dir, \n",
    "    val_img_dir, \n",
    "    val_label_dir, \n",
    "    non_random_transforms = non_random_transforms, \n",
    "    random_transforms = random_transforms, \n",
    "    batch_size = loader_batch,\n",
    "    num_workers=0,train_num_repeat=num_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://monai.io/model-zoo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import TverskyLoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=n_classes,\n",
    "    channels=(48, 64, 80, 80),\n",
    "    strides=(2, 2, 1),\n",
    "    num_res_units=1,\n",
    "    dropout = drop_rate,\n",
    ").to(device)\n",
    "\n",
    "pretrain_str = \"yes\" if use_checkpoint else \"no\"\n",
    "weight_str = \"weighted\" if class_weights is not None else \"\"\n",
    "\n",
    "# 체크포인트 디렉토리 및 파일 설정\n",
    "checkpoint_base_dir = Path(\"./model_checkpoints\")\n",
    "folder_name = f\"Denoising_UNet_{weight_str}_f{feature_size}_d{img_depth}s{img_size}_numb{num_bottleneck}_lr{lr:.0e}_a{lamda:.2f}_b{1-lamda:.2f}_b{batch_size}_r{num_repeat}_ce{ce_weight}_ac{accumulation_steps}\"\n",
    "checkpoint_dir = checkpoint_base_dir / folder_name\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "# 체크포인트 디렉토리 생성\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if checkpoint_dir.exists():\n",
    "    best_model_path = checkpoint_dir / 'best_model.pt'\n",
    "    if best_model_path.exists():\n",
    "        print(f\"기존 best model 발견: {best_model_path}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(best_model_path, map_location=device)\n",
    "            # 체크포인트 내부 키 검증\n",
    "            required_keys = ['model_state_dict', 'optimizer_state_dict', 'epoch', 'best_val_loss']\n",
    "            if all(k in checkpoint for k in required_keys):\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                start_epoch = checkpoint['epoch']\n",
    "                best_val_loss = checkpoint['best_val_loss']\n",
    "                print(\"기존 학습된 가중치를 성공적으로 로드했습니다.\")\n",
    "                checkpoint= None\n",
    "            else:\n",
    "                raise ValueError(\"체크포인트 파일에 필요한 key가 없습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"체크포인트 파일을 로드하는 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 96, 96, 96]) torch.Size([1, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_loader))\n",
    "images, labels = batch[\"image\"], batch[\"label\"]\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpook0612\u001b[0m (\u001b[33mlimbw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Workspace\\czll\\wandb\\run-20250114_200703-navqtux2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/limbw/czii/runs/navqtux2' target=\"_blank\">Denoising_UNet__f48_d96s96_numb2_lr1e-03_a0.50_b0.50_b16_r4_ce0.4_ac1</a></strong> to <a href='https://wandb.ai/limbw/czii' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/limbw/czii' target=\"_blank\">https://wandb.ai/limbw/czii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/limbw/czii/runs/navqtux2' target=\"_blank\">https://wandb.ai/limbw/czii/runs/navqtux2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "run_name = folder_name\n",
    "\n",
    "# wandb 초기화\n",
    "wandb.init(\n",
    "    project='czii',  # 프로젝트 이름 설정\n",
    "    name=run_name,         # 실행(run) 이름 설정\n",
    "    config={\n",
    "        'num_epochs': num_epochs,\n",
    "        'learning_rate': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'lambda': lamda,\n",
    "        \"cross_entropy_weight\": ce_weight,\n",
    "        'feature_size': feature_size,\n",
    "        'img_size': img_size,\n",
    "        # 'sampling_ratio': ratios_list,\n",
    "        'device': device.type,\n",
    "        \"checkpoint_dir\": str(checkpoint_dir),\n",
    "        \"class_weights\": class_weights.tolist() if class_weights is not None else None,\n",
    "        \"use_checkpoint\": use_checkpoint,\n",
    "        \"drop_rate\": drop_rate,\n",
    "        \"attn_drop_rate\": attn_drop_rate,\n",
    "        \"use_v2\": use_v2,\n",
    "        \"accumulation_steps\": accumulation_steps,\n",
    "        \"num_repeat\": num_repeat,\n",
    "        \"num_bottleneck\": num_bottleneck,\n",
    "        \n",
    "        # 필요한 하이퍼파라미터 추가\n",
    "    }\n",
    ")\n",
    "# 모델을 wandb에 연결\n",
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from monai.metrics import DiceMetric\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def processing(batch_data, model, criterion, device):\n",
    "    images = batch_data['image'].to(device)  # Input 이미지 (B, 1, 96, 96, 96)\n",
    "    labels = batch_data['label'].to(device)  # 라벨 (B, 96, 96, 96)\n",
    "    \n",
    "    # print(\"shape:\", images.shape, labels.shape)\n",
    "\n",
    "    labels = labels.squeeze(1)  # (B, 1, 96, 96, 96) → (B, 96, 96, 96)\n",
    "    labels = labels.long()  # 라벨을 정수형으로 변환\n",
    "    # print(\"shape:\", images.shape, labels.shape)\n",
    "    # 원핫 인코딩 (B, H, W, D) → (B, num_classes, H, W, D)\n",
    "    \n",
    "    # labels_onehot = torch.nn.functional.one_hot(labels, num_classes=n_classes)\n",
    "    # labels_onehot = labels_onehot.permute(0, 4, 1, 2, 3).float()  # (B, num_classes, H, W, D)\n",
    "    # print(\"shape:\", images.shape, labels_onehot.shape)\n",
    "    # 모델 예측\n",
    "    outputs = model(images)  # outputs: (B, num_classes, H, W, D)\n",
    "    # print(\"output shape:\", outputs.shape)  \n",
    "\n",
    "    # Loss 계산\n",
    "    loss = criterion(outputs, labels)\n",
    "    # loss = loss_fn(criterion(outputs, labels_onehot),class_weights=class_weights, device=device)\n",
    "    return loss, outputs, labels, outputs.argmax(dim=1)\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, accumulation_steps=4):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    optimizer.zero_grad()  # 그래디언트 초기화\n",
    "    with tqdm(train_loader, desc='Training') as pbar:\n",
    "        for i, batch_data in enumerate(pbar):\n",
    "            # 손실 계산\n",
    "            loss, _, _, _ = processing(batch_data, model, criterion, device)\n",
    "\n",
    "            # 그래디언트를 계산하고 누적\n",
    "            loss = loss / accumulation_steps  # 그래디언트 누적을 위한 스케일링\n",
    "            loss.backward()  # 그래디언트 계산 및 누적\n",
    "            \n",
    "            # 그래디언트 업데이트 (accumulation_steps마다 한 번)\n",
    "            if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
    "                optimizer.step()  # 파라미터 업데이트\n",
    "                optimizer.zero_grad()  # 누적된 그래디언트 초기화\n",
    "            \n",
    "            # 손실값 누적 (스케일링 복구)\n",
    "            epoch_loss += loss.item() * accumulation_steps  # 실제 손실값 반영\n",
    "            pbar.set_postfix(loss=loss.item() * accumulation_steps)  # 실제 손실값 출력\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    wandb.log({'train_epoch_loss': avg_loss, 'epoch': epoch + 1})\n",
    "    return avg_loss\n",
    "\n",
    "def calculate_psnr_ssim(pred, target):\n",
    "    \"\"\"\n",
    "    PSNR과 SSIM을 계산하는 함수\n",
    "    pred: 예측 이미지 (numpy 배열)\n",
    "    target: 실제 이미지 (numpy 배열)\n",
    "    \"\"\"\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    target_np = target.cpu().numpy()\n",
    "    \n",
    "    # print(\"pred min max:\", pred_np.min(), pred_np.max())\n",
    "    # print(\"target min max:\", target_np.min(), target_np.max())\n",
    "    \n",
    "    psnr_value = psnr(target_np, pred_np, data_range=target_np.max() - target_np.min())\n",
    "    # ssim_value, _ = ssim(target_np, pred_np, data_range=target_np.max() - target_np.min(), full=True)\n",
    "    \n",
    "    return psnr_value, 0\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion, device, epoch, calculate_dice_interval):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    class_psnr_scores = {i: [] for i in range(n_classes)}\n",
    "    class_ssim_scores = {i: [] for i in range(n_classes)}\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, desc='Validation') as pbar:\n",
    "            for batch_data in pbar:\n",
    "                loss, _, labels, preds = processing(batch_data, model, criterion, device)\n",
    "                val_loss += loss.item()\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "                # 각 클래스별 Dice 점수 계산\n",
    "                if epoch % calculate_dice_interval == 0:\n",
    "                    for i in range(n_classes):\n",
    "                        pred_i = (preds == i).float()\n",
    "                        label_i = (labels == i).float()\n",
    "                        \n",
    "                        psnr_value, ssim_value = calculate_psnr_ssim(pred_i, label_i)\n",
    "                        class_psnr_scores[i].append(psnr_value)\n",
    "                        class_ssim_scores[i].append(ssim_value)\n",
    "                        # PSNR, SSIM 값을 로깅\n",
    "                        wandb.log({f'class_{i}_psnr': psnr_value, 'epoch': epoch + 1})\n",
    "                        wandb.log({f'class_{i}_ssim': ssim_value, 'epoch': epoch + 1})\n",
    "                        # print(f\"Class {i}: PSNR: {psnr_value:.4f}, SSIM: {ssim_value:.4f}\", end=\", \")\n",
    "                            \n",
    "\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    # 에포크별 평균 손실 로깅\n",
    "    wandb.log({'val_epoch_loss': avg_loss, 'epoch': epoch + 1})\n",
    "    \n",
    "    if epoch % calculate_dice_interval == 0:\n",
    "        print(\"Validation PSNR and SSIM Scores\")\n",
    "        all_classes_psnr_scores = []\n",
    "        all_classes_ssim_scores = []\n",
    "        for i in range(n_classes):\n",
    "            psnr_value = np.mean(class_psnr_scores[i])\n",
    "            ssim_value = np.mean(class_ssim_scores[i])\n",
    "            # wandb.log({f'class_{i}_psnr': psnr_value, 'epoch': epoch + 1})\n",
    "            # wandb.log({f'class_{i}_ssim': ssim_value, 'epoch': epoch + 1})\n",
    "            # print(f\"Class {i}: PSNR: {psnr_value:.4f}, SSIM: {ssim_value:.4f}\", end=\", \")\n",
    "            if i not in [0, 2]:  # 평균에 포함할 클래스만 추가\n",
    "                all_classes_psnr_scores.append(psnr_value)\n",
    "                all_classes_ssim_scores.append(ssim_value)\n",
    "        print()\n",
    "        overall_mean_psnr = np.mean(all_classes_psnr_scores)\n",
    "        overall_mean_ssim = np.mean(all_classes_ssim_scores)\n",
    "        # wandb.log({'overall_mean_psnr': overall_mean_psnr, 'overall_mean_ssim': overall_mean_ssim, 'epoch': epoch + 1})\n",
    "        print(f\"\\nOverall Mean PSNR: {overall_mean_psnr:.4f}\\nOverall Mean SSIM: {overall_mean_ssim:.4f}\\n\")\n",
    "\n",
    "    # if overall_mean_fbeta is None:\n",
    "    #     overall_mean_fbeta = 0\n",
    "\n",
    "    # 시각화 코드\n",
    "    # 예측과 라벨을 시각화\n",
    "    \n",
    "    preds = preds.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    preds = np.squeeze(preds, axis=0)\n",
    "    labels = np.squeeze(labels, axis=0)\n",
    "    # print(preds.shape, labels.shape)\n",
    "    \n",
    "    slice_idx = 50\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Image 1 비교\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(preds[slice_idx], cmap=\"gray\")\n",
    "    plt.title(\"Image: Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(labels[slice_idx], cmap=\"gray\")\n",
    "    plt.title(\"Label: denoised\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return val_loss / len(val_loader), overall_mean_psnr, overall_mean_ssim\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, \n",
    "    device, start_epoch, best_val_loss, best_val_fbeta_score, calculate_dice_interval=1,\n",
    "    accumulation_steps=4\n",
    "):\n",
    "    \"\"\"\n",
    "    모델을 학습하고 검증하는 함수\n",
    "    Args:\n",
    "        model: 학습할 모델\n",
    "        train_loader: 학습 데이터 로더\n",
    "        val_loader: 검증 데이터 로더\n",
    "        criterion: 손실 함수\n",
    "        optimizer: 최적화 알고리즘\n",
    "        num_epochs: 총 학습 epoch 수\n",
    "        patience: early stopping 기준\n",
    "        device: GPU/CPU 장치\n",
    "        start_epoch: 시작 epoch\n",
    "        best_val_loss: 이전 최적 validation loss\n",
    "        best_val_fbeta_score: 이전 최적 validation f-beta score\n",
    "        calculate_dice_interval: Dice 점수 계산 주기\n",
    "    \"\"\"\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Train One Epoch\n",
    "        train_loss = train_one_epoch(\n",
    "            model=model, \n",
    "            train_loader=train_loader, \n",
    "            criterion=criterion, \n",
    "            optimizer=optimizer, \n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "            accumulation_steps= accumulation_steps\n",
    "        )\n",
    "        \n",
    "        scheduler.step(train_loss)\n",
    "        # Validate One Epoch\n",
    "        val_loss, overall_mean_psnr, overall_mean_ssim = validate_one_epoch(\n",
    "            model=model, \n",
    "            val_loader=val_loader, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            epoch=epoch, \n",
    "            calculate_dice_interval=calculate_dice_interval\n",
    "        )\n",
    "\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation PSNR: {overall_mean_psnr:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss and overall_mean_psnr > best_val_fbeta_score:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_fbeta_score = overall_mean_psnr\n",
    "            epochs_no_improve = 0\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_fbeta_score': best_val_fbeta_score\n",
    "            }, checkpoint_path)\n",
    "            print(f\"========================================================\")\n",
    "            print(f\"SUPER Best model saved. Loss:{best_val_loss:.4f}, Score:{best_val_fbeta_score:.4f}\")\n",
    "            print(f\"========================================================\")\n",
    "\n",
    "        # Early stopping 조건 체크\n",
    "        if val_loss >= best_val_loss and overall_mean_psnr <= best_val_fbeta_score:\n",
    "            epochs_no_improve += 1\n",
    "        else:\n",
    "            epochs_no_improve = 0\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'last.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_fbeta_score': best_val_fbeta_score\n",
    "            }, checkpoint_path)\n",
    "            break\n",
    "        # if epochs_no_improve%6 == 0 & epochs_no_improve != 0:\n",
    "        #     # 손실이 개선되지 않았으므로 lambda 감소\n",
    "        #     new_lamda = max(criterion.lamda - 0.01, 0.35)  # 최소값은 0.1로 설정\n",
    "        #     criterion.set_lamda(new_lamda)\n",
    "        #     print(f\"Validation loss did not improve. Reducing lambda to {new_lamda:.4f}\")\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 24/24 [00:51<00:00,  2.14s/it, loss=4.35]\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s, loss=4.28]c:\\Users\\pook0\\.conda\\envs\\UM\\Lib\\site-packages\\skimage\\metrics\\simple_metrics.py:168: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 10 * np.log10((data_range**2) / err)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:  33%|███▎      | 1/3 [00:01<00:03,  1.72s/it, loss=4.09]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:  67%|██████▋   | 2/3 [00:03<00:01,  1.73s/it, loss=4.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 1.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 1.0\n",
      "pred min max: 0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 3/3 [00:05<00:00,  1.73s/it, loss=4.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "pred min max: 0.0 0.0\n",
      "target min max: 0.0 0.0\n",
      "Validation PSNR and SSIM Scores\n",
      "\n",
      "\n",
      "Overall Mean PSNR: nan\n",
      "Overall Mean SSIM: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.5859, Validation Loss: 4.1611, Validation PSNR: nan\n",
      "Epoch 2/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 16/24 [00:11<00:05,  1.43it/s, loss=3.82]"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    patience=5,\n",
    "    device=device,\n",
    "    start_epoch=start_epoch,\n",
    "    best_val_loss=best_val_loss,\n",
    "    best_val_fbeta_score=best_val_fbeta_score,\n",
    "    calculate_dice_interval=1,\n",
    "    accumulation_steps = accumulation_steps\n",
    "     ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (879943805.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    if:\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:fs6utwyo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cc3ae761af43baae5aca60b5d2e7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>class_0_dice_score</td><td>▁</td></tr><tr><td>class_0_f_beta_score</td><td>▁</td></tr><tr><td>class_1_dice_score</td><td>▁</td></tr><tr><td>class_1_f_beta_score</td><td>▁</td></tr><tr><td>class_2_dice_score</td><td>▁</td></tr><tr><td>class_2_f_beta_score</td><td>▁</td></tr><tr><td>class_3_dice_score</td><td>▁</td></tr><tr><td>class_3_f_beta_score</td><td>▁</td></tr><tr><td>class_4_dice_score</td><td>▁</td></tr><tr><td>class_4_f_beta_score</td><td>▁</td></tr><tr><td>class_5_dice_score</td><td>▁</td></tr><tr><td>class_5_f_beta_score</td><td>▁</td></tr><tr><td>class_6_dice_score</td><td>▁</td></tr><tr><td>class_6_f_beta_score</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>overall_mean_dice_score</td><td>▁</td></tr><tr><td>overall_mean_f_beta_score</td><td>▁</td></tr><tr><td>val_epoch_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>class_0_dice_score</td><td>0.65703</td></tr><tr><td>class_0_f_beta_score</td><td>0.50748</td></tr><tr><td>class_1_dice_score</td><td>0.53332</td></tr><tr><td>class_1_f_beta_score</td><td>0.64703</td></tr><tr><td>class_2_dice_score</td><td>0.00286</td></tr><tr><td>class_2_f_beta_score</td><td>0.02334</td></tr><tr><td>class_3_dice_score</td><td>0.23703</td></tr><tr><td>class_3_f_beta_score</td><td>0.23033</td></tr><tr><td>class_4_dice_score</td><td>0.65487</td></tr><tr><td>class_4_f_beta_score</td><td>0.62525</td></tr><tr><td>class_5_dice_score</td><td>0.47899</td></tr><tr><td>class_5_f_beta_score</td><td>0.51448</td></tr><tr><td>class_6_dice_score</td><td>0.42545</td></tr><tr><td>class_6_f_beta_score</td><td>0.47197</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>overall_mean_dice_score</td><td>0.42708</td></tr><tr><td>overall_mean_f_beta_score</td><td>0.43141</td></tr><tr><td>val_epoch_loss</td><td>0.7152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SwinUNETR96_96_lr0.001_lambda0.52_batch2</strong> at: <a href='https://wandb.ai/waooang/czii_SwinUnetR_val/runs/fs6utwyo' target=\"_blank\">https://wandb.ai/waooang/czii_SwinUnetR_val/runs/fs6utwyo</a><br/> View project at: <a href='https://wandb.ai/waooang/czii_SwinUnetR_val' target=\"_blank\">https://wandb.ai/waooang/czii_SwinUnetR_val</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241219_200219-fs6utwyo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:fs6utwyo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Workspace\\czll\\wandb\\run-20241219_200454-121l7bn3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/waooang/czii_SwinUnetR_val/runs/121l7bn3' target=\"_blank\">SwinUNETR96_96_lr0.001_lambda0.52_batch2</a></strong> to <a href='https://wandb.ai/waooang/czii_SwinUnetR_val' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/waooang/czii_SwinUnetR_val' target=\"_blank\">https://wandb.ai/waooang/czii_SwinUnetR_val</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/waooang/czii_SwinUnetR_val/runs/121l7bn3' target=\"_blank\">https://wandb.ai/waooang/czii_SwinUnetR_val/runs/121l7bn3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n",
      "C:\\Users\\Seungwoo\\AppData\\Local\\Temp\\ipykernel_21000\\1177025787.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrain_path, map_location=device)\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.38it/s, loss=0.865]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Score\n",
      "Class 0: 0.6570, Class 1: 0.5333, Class 2: 0.0029, Class 3: 0.2370, \n",
      "Class 4: 0.6549, Class 5: 0.4790, Class 6: 0.4255, \n",
      "Validation F-beta Score\n",
      "Class 0: 0.5075, Class 1: 0.6470, Class 2: 0.0233, Class 3: 0.2303, \n",
      "Class 4: 0.6252, Class 5: 0.5145, Class 6: 0.4720, \n",
      "Overall Mean Dice Score: 0.4659\n",
      "Overall Mean F-beta Score: 0.4978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, NormalizeIntensityd,\n",
    "    Orientationd, CropForegroundd, GaussianSmoothd, ScaleIntensityd,\n",
    "    RandSpatialCropd, RandRotate90d, RandFlipd, RandGaussianNoised,\n",
    "    ToTensord, RandCropByLabelClassesd\n",
    ")\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR, SwinUNETR\n",
    "from monai.losses import TverskyLoss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from src.dataset.dataset import make_val_dataloader\n",
    "\n",
    "val_img_dir = \"./datasets/val/images\"\n",
    "val_label_dir = \"./datasets/val/labels\"\n",
    "img_depth = 96\n",
    "img_size = 96  # Match your patch size\n",
    "n_classes = 7\n",
    "batch_size = 2 # 13.8GB GPU memory required for 128x128 img size\n",
    "num_samples = batch_size # 한 이미지에서 뽑을 샘플 수\n",
    "loader_batch = 1\n",
    "lamda = 0.52\n",
    "\n",
    "wandb.init(\n",
    "    project='czii_SwinUnetR_val',  # 프로젝트 이름 설정\n",
    "    name='SwinUNETR96_96_lr0.001_lambda0.52_batch2',         # 실행(run) 이름 설정\n",
    "    config={\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': batch_size,\n",
    "        'lambda': lamda,\n",
    "        'img_size': img_size,\n",
    "        'device': 'cuda',\n",
    "        \"checkpoint_dir\": \"./model_checkpoints/SwinUNETR96_96_lr0.001_lambda0.52_batch2\",\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    GaussianSmoothd(\n",
    "        keys=[\"image\"],      # 변환을 적용할 키\n",
    "        sigma=[1.0, 1.0, 1.0]  # 각 축(x, y, z)의 시그마 값\n",
    "        ),\n",
    "])\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[img_depth, img_size, img_size],\n",
    "        num_classes=n_classes,\n",
    "        num_samples=num_samples, \n",
    "        ratios=ratios_list,\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[1, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "])\n",
    "\n",
    "val_loader = make_val_dataloader(\n",
    "    val_img_dir, \n",
    "    val_label_dir, \n",
    "    non_random_transforms = non_random_transforms, \n",
    "    random_transforms = random_transforms, \n",
    "    batch_size = loader_batch,\n",
    "    num_workers=0\n",
    ")\n",
    "criterion = TverskyLoss(\n",
    "    alpha= 1 - lamda,  # FP에 대한 가중치\n",
    "    beta=lamda,       # FN에 대한 가중치\n",
    "    include_background=False,  # 배경 클래스 제외\n",
    "    softmax=True\n",
    ")\n",
    "    \n",
    "    \n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "img_size = 96\n",
    "img_depth = img_size\n",
    "n_classes = 7 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrain_path = \"./model_checkpoints/SwinUNETR96_96_lr0.001_lambda0.52_batch2/best_model.pt\"\n",
    "model = SwinUNETR(\n",
    "    img_size=(img_depth, img_size, img_size),\n",
    "    in_channels=1,\n",
    "    out_channels=n_classes,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n",
    "# Pretrained weights 불러오기\n",
    "checkpoint = torch.load(pretrain_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "val_loss, overall_mean_fbeta_score = validate_one_epoch(\n",
    "    model=model, \n",
    "    val_loader=val_loader, \n",
    "    criterion=criterion, \n",
    "    device=device, \n",
    "    epoch=0, \n",
    "    calculate_dice_interval=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.preprocessing import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import Compose, EnsureChannelFirstd, NormalizeIntensityd, Orientationd, GaussianSmoothd\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import copick\n",
    "\n",
    "import torch\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file written to ./kaggle/working/copick.config\n",
      "file length: 7\n"
     ]
    }
   ],
   "source": [
    "config_blob = \"\"\"{\n",
    "    \"name\": \"czii_cryoet_mlchallenge_2024\",\n",
    "    \"description\": \"2024 CZII CryoET ML Challenge training data.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "\n",
    "    \"pickable_objects\": [\n",
    "        {\n",
    "            \"name\": \"apo-ferritin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"4V1W\",\n",
    "            \"label\": 1,\n",
    "            \"color\": [  0, 117, 220, 128],\n",
    "            \"radius\": 60,\n",
    "            \"map_threshold\": 0.0418\n",
    "        },\n",
    "        {\n",
    "          \"name\" : \"beta-amylase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"8ZRZ\",\n",
    "            \"label\": 2,\n",
    "            \"color\": [255, 255, 255, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578  \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"beta-galactosidase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6X1Q\",\n",
    "            \"label\": 3,\n",
    "            \"color\": [ 76,   0,  92, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ribosome\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6EK0\",\n",
    "            \"label\": 4,\n",
    "            \"color\": [  0,  92,  49, 128],\n",
    "            \"radius\": 150,\n",
    "            \"map_threshold\": 0.0374\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"thyroglobulin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6SCJ\",\n",
    "            \"label\": 5,\n",
    "            \"color\": [ 43, 206,  72, 128],\n",
    "            \"radius\": 130,\n",
    "            \"map_threshold\": 0.0278\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"virus-like-particle\",\n",
    "            \"is_particle\": true,\n",
    "            \"label\": 6,\n",
    "            \"color\": [255, 204, 153, 128],\n",
    "            \"radius\": 135,\n",
    "            \"map_threshold\": 0.201\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"membrane\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 8,\n",
    "            \"color\": [100, 100, 100, 128]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"background\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 9,\n",
    "            \"color\": [10, 150, 200, 128]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"overlay_root\": \"./kaggle/working/overlay\",\n",
    "\n",
    "    \"overlay_fs_args\": {\n",
    "        \"auto_mkdir\": true\n",
    "    },\n",
    "\n",
    "    \"static_root\": \"./kaggle/input/czii-cryo-et-object-identification/test/static\"\n",
    "}\"\"\"\n",
    "\n",
    "copick_config_path = \"./kaggle/working/copick.config\"\n",
    "preprocessor = Preprocessor(config_blob,copick_config_path=copick_config_path)\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "    GaussianSmoothd(\n",
    "        keys=[\"image\"],      # 변환을 적용할 키\n",
    "        sigma=[1.0, 1.0, 1.0]  # 각 축(x, y, z)의 시그마 값\n",
    "        ),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ship\\Lib\\site-packages\\monai\\utils\\deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "C:\\Users\\Seungwoo\\AppData\\Local\\Temp\\ipykernel_6248\\2937359115.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrain_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 96\n",
    "img_depth = img_size\n",
    "n_classes = 7 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrain_path = \"./model_checkpoints/SwinUNETR96_96_lr0.001_lambda0.52_batch2/best_model.pt\"\n",
    "model = SwinUNETR(\n",
    "    img_size=(img_depth, img_size, img_size),\n",
    "    in_channels=1,\n",
    "    out_channels=n_classes,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n",
    "# Pretrained weights 불러오기\n",
    "checkpoint = torch.load(pretrain_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/4 [00:03<?, ?it/s, loss=0.764]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcalculate_dice_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 64\u001b[0m, in \u001b[0;36mvalidate_one_epoch\u001b[1;34m(model, val_loader, criterion, device, epoch, calculate_dice_interval)\u001b[0m\n\u001b[0;32m     61\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# 각 클래스별 Dice 점수 계산\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalculate_dice_interval\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes):\n\u001b[0;32m     66\u001b[0m         pred_i \u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m i)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer modulo by zero"
     ]
    }
   ],
   "source": [
    "val_loss = validate_one_epoch(\n",
    "            model=model, \n",
    "            val_loader=val_loader, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            epoch=1, \n",
    "            calculate_dice_interval=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing volume 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing volume 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing volume 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import Compose, NormalizeIntensity\n",
    "import cc3d\n",
    "\n",
    "def dict_to_df(coord_dict, experiment_name):\n",
    "    all_coords = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for label, coords in coord_dict.items():\n",
    "        all_coords.append(coords)\n",
    "        all_labels.extend([label] * len(coords))\n",
    "    \n",
    "    all_coords = np.vstack(all_coords)\n",
    "    df = pd.DataFrame({\n",
    "        'experiment': experiment_name,\n",
    "        'particle_type': all_labels,\n",
    "        'x': all_coords[:, 0],\n",
    "        'y': all_coords[:, 1],\n",
    "        'z': all_coords[:, 2]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "id_to_name = {1: \"apo-ferritin\", \n",
    "              2: \"beta-amylase\",\n",
    "              3: \"beta-galactosidase\", \n",
    "              4: \"ribosome\", \n",
    "              5: \"thyroglobulin\", \n",
    "              6: \"virus-like-particle\"}\n",
    "BLOB_THRESHOLD = 200\n",
    "CERTAINTY_THRESHOLD = 0.05\n",
    "\n",
    "classes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    location_dfs = []  # DataFrame 리스트로 초기화\n",
    "    \n",
    "    for vol_idx, run in enumerate(preprocessor.root.runs):\n",
    "        print(f\"Processing volume {vol_idx + 1}/{len(preprocessor.root.runs)}\")\n",
    "        tomogram = preprocessor.processing(run=run, task=\"task\")\n",
    "        task_files = [{\"image\": tomogram}]\n",
    "        task_ds = CacheDataset(data=task_files, transform=non_random_transforms)\n",
    "        task_loader = DataLoader(task_ds, batch_size=1, num_workers=0)\n",
    "        \n",
    "        for task_data in task_loader:\n",
    "            images = task_data['image'].to(\"cuda\")\n",
    "            outputs = sliding_window_inference(\n",
    "                inputs=images,\n",
    "                roi_size=(96, 96, 96),  # ROI 크기\n",
    "                sw_batch_size=4,\n",
    "                predictor=model.forward,\n",
    "                overlap=0.1,\n",
    "                sw_device=\"cuda\",\n",
    "                device=\"cpu\",\n",
    "                buffer_steps=1,\n",
    "                buffer_dim=-1\n",
    "            )\n",
    "            outputs = outputs.argmax(dim=1).squeeze(0).cpu().numpy()  # 클래스 채널 예측\n",
    "            location = {}  # 좌표 저장용 딕셔너리\n",
    "            for c in classes:\n",
    "                cc = cc3d.connected_components(outputs == c)  # cc3d 라벨링\n",
    "                stats = cc3d.statistics(cc)\n",
    "                zyx = stats['centroids'][1:] * 10.012444  # 스케일 변환\n",
    "                zyx_large = zyx[stats['voxel_counts'][1:] > BLOB_THRESHOLD]  # 크기 필터링\n",
    "                xyz = np.ascontiguousarray(zyx_large[:, ::-1])  # 좌표 스왑 (z, y, x -> x, y, z)\n",
    "\n",
    "                location[id_to_name[c]] = xyz  # ID 이름 매칭 저장\n",
    "\n",
    "            # 데이터프레임 변환\n",
    "            df = dict_to_df(location, run.name)\n",
    "            location_dfs.append(df)  # 리스트에 추가\n",
    "        \n",
    "        # if vol_idx == 2:\n",
    "        #     break\n",
    "    \n",
    "    # DataFrame 병합\n",
    "    final_df = pd.concat(location_dfs, ignore_index=True)\n",
    "    \n",
    "    # ID 추가 및 CSV 저장\n",
    "    final_df.insert(loc=0, column='id', value=np.arange(len(final_df)))\n",
    "    final_df.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Submission saved to: submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
