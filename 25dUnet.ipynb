{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 6, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "class UNet2_5D_v2(nn.Module):\n",
    "    def __init__(self, out_channels=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 초기 3D 처리 레이어\n",
    "        self.init_3d = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=(11, 3, 3), padding=(0, 1, 1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 2D UNet\n",
    "        self.unet = UNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=64,  # 3D 컨볼루션 출력 채널\n",
    "            out_channels=out_channels,\n",
    "            channels=(64, 128, 256, 512),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 1, 11, H, W)\n",
    "        # 3D 처리\n",
    "        x = self.init_3d(x)  # (batch, 64, 1, H, W)\n",
    "        x = x.squeeze(2)     # (batch, 64, H, W)\n",
    "        \n",
    "        # 2D UNet\n",
    "        return self.unet(x)\n",
    "\n",
    "# 테스트 코드\n",
    "if __name__ == \"__main__\":\n",
    "    model = UNet2_5D_v2(out_channels=6)\n",
    "    x = torch.randn(8, 1, 11, 256, 256)\n",
    "    output = model(x)\n",
    "    print(f\"Output shape: {output.shape}\")  # Expected: (8, 6, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"2D Double Convolution Block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"U-Net Encoder\"\"\"\n",
    "    def __init__(self, in_channels, features):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        skip = x\n",
    "        x = self.pool(x)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"U-Net Decoder\"\"\"\n",
    "    def __init__(self, in_channels, skip_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: Up-sampled feature channels\n",
    "            skip_channels: Skip connection feature channels\n",
    "            out_channels: Output feature channels after concatenation\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(out_channels + skip_channels, out_channels)  # Concatenated channels\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        # Up-sample\n",
    "        x = self.upconv(x)\n",
    "        # Ensure spatial dimensions match\n",
    "        if x.shape[-2:] != skip.shape[-2:]:\n",
    "            diffY = skip.size(2) - x.size(2)\n",
    "            diffX = skip.size(3) - x.size(3)\n",
    "            x = F.pad(x, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        # Concatenate with skip connection\n",
    "        x = torch.cat((x, skip), dim=1)\n",
    "        # Apply convolution\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet2_5D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, depth_slices=11, features=[64, 128, 256, 512]):\n",
    "        super(UNet2_5D, self).__init__()\n",
    "        self.depth_slices = depth_slices\n",
    "\n",
    "        # Initial 3D Convolution to merge depth slices\n",
    "        self.init_conv3d = nn.Conv3d(in_channels, features[0], kernel_size=(depth_slices, 3, 3), padding=(0, 1, 1))\n",
    "        self.init_bn3d = nn.BatchNorm3d(features[0])\n",
    "\n",
    "        # Encoder\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for i in range(len(features)):\n",
    "            if i == 0:\n",
    "                self.encoders.append(Encoder(features[0], features[0]))\n",
    "            else:\n",
    "                self.encoders.append(Encoder(features[i-1], features[i]))\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoders = nn.ModuleList()\n",
    "        reversed_features = list(reversed(features))\n",
    "        \n",
    "        # 첫 번째 디코더는 bottleneck의 출력을 처리\n",
    "        self.decoders.append(\n",
    "            Decoder(\n",
    "                in_channels=features[-1] * 2,  # bottleneck의 출력\n",
    "                skip_channels=features[-1],    # 마지막 인코더의 skip connection\n",
    "                out_channels=features[-2]      # 다음 레벨의 특성 수\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 중간 디코더들\n",
    "        for i in range(len(features)-2):\n",
    "            self.decoders.append(\n",
    "                Decoder(\n",
    "                    in_channels=features[-2-i],     # 이전 디코더의 출력\n",
    "                    skip_channels=features[-2-i],   # 해당 레벨의 skip connection\n",
    "                    out_channels=features[-3-i]     # 다음 레벨의 특성 수\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        # 마지막 디코더\n",
    "        self.decoders.append(\n",
    "            Decoder(\n",
    "                in_channels=features[0],     # 이전 디코더의 출력\n",
    "                skip_channels=features[0],   # 첫 번째 인코더의 skip connection\n",
    "                out_channels=features[0]     # 최종 특성 수\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Final Convolution\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 3D Convolution for depth slices\n",
    "        x = F.relu(self.init_bn3d(self.init_conv3d(x)))\n",
    "        x = x.squeeze(2)\n",
    "\n",
    "        # Encoder path\n",
    "        skips = []\n",
    "        for encoder in self.encoders:\n",
    "            x, skip = encoder(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Decoder path with corrected skip connections\n",
    "        skips = skips[::-1]  # 스킵 커넥션 순서 뒤집기\n",
    "        for decoder, skip in zip(self.decoders, skips):\n",
    "            x = decoder(x, skip)\n",
    "\n",
    "        return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CryoETDataset(Dataset):\n",
    "    def __init__(self, images, masks):\n",
    "        self.images = images  # Shape: (N, 1, 11, H, W)\n",
    "        self.masks = masks    # Shape: (N, H, W) with class labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# 데이터 예제 (더미 데이터)\n",
    "images = torch.randn(100, 1, 11, 256, 256)  # 100개의 샘플\n",
    "masks = torch.randint(0, 6, (100, 256, 256))  # 6개 클래스 라벨\n",
    "dataset = CryoETDataset(images, masks)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 초기화\n",
    "model = UNet2_5D(in_channels=1, out_channels=6, depth_slices=11).to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(10):  # 10 epochs\n",
    "    model.train()\n",
    "    for images, masks in dataloader:\n",
    "        images, masks = images.to('cuda'), masks.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
