{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from monai.data import Dataset\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, NormalizeIntensityd,\n",
    "    Orientationd, CropForegroundd, GaussianSmoothd, ScaleIntensityd,\n",
    "    RandSpatialCropd, RandRotate90d, RandFlipd, RandGaussianNoised,\n",
    "    ToTensord\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "TRAIN_IMG_DIR = \"./datasets/train/images\"\n",
    "TRAIN_LABEL_DIR = \"./datasets/train/labels\"\n",
    "VAL_IMG_DIR = \"./datasets/val/images\"\n",
    "VAL_LABEL_DIR = \"./datasets/val/labels\"\n",
    "\n",
    "train_list = os.listdir(TRAIN_IMG_DIR)\n",
    "val_list = os.listdir(VAL_IMG_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.4.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 46a5272196a6c2590ca2589029eed8e4d56ff008\n",
      "MONAI __file__: /Users/<username>/anaconda3/envs/dust/lib/python3.12/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.3.2\n",
      "scikit-image version: 0.24.0\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.4.0\n",
      "Tensorboard version: 2.17.1\n",
      "gdown version: 5.2.0\n",
      "TorchVision version: 0.17.1\n",
      "tqdm version: 4.66.5\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.1\n",
      "einops version: 0.7.0\n",
      "transformers version: 4.45.2\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import ImageDataset, create_test_image_3d, decollate_batch, DataLoader\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    RandRotate90,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "\n",
    "\n",
    "def main():\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "    train_files = []\n",
    "    valid_files = []\n",
    "    \n",
    "    train_imgs = []\n",
    "    train_labels = []\n",
    "    val_imgs = []\n",
    "    val_labels = []\n",
    "\n",
    "    for name in train_list:\n",
    "        train_image = np.load(os.path.join(TRAIN_IMG_DIR, f\"{name}\"))\n",
    "        train_imgs.append(train_image)\n",
    "        train_label = np.load(os.path.join(TRAIN_LABEL_DIR, f\"{name.replace('image', 'label')}\"))\n",
    "        train_labels.append(train_label)\n",
    "        # train_files.append({\"image\": train_image, \"label\": train_label, \"name\": name})\n",
    "\n",
    "    for name in val_list:\n",
    "        valid_image = np.load(os.path.join(VAL_IMG_DIR, f\"{name}\"))\n",
    "        val_imgs.append(valid_image)\n",
    "        valid_label = np.load(os.path.join(VAL_LABEL_DIR, f\"{name.replace('image', 'label')}\"))\n",
    "        val_labels.append(valid_label)\n",
    "        # valid_files.append({\"image\": valid_image, \"label\": valid_label, \"name\": name})\n",
    "\n",
    "\n",
    "    # define transforms for image and segmentation\n",
    "    train_imtrans = Compose(\n",
    "        [\n",
    "            ScaleIntensity(),\n",
    "            EnsureChannelFirst(),\n",
    "            RandSpatialCrop((11, 96, 96), random_size=False),\n",
    "            RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"SRA\")\n",
    "        ]\n",
    "    )\n",
    "    train_segtrans = Compose(\n",
    "        [\n",
    "            EnsureChannelFirst(),\n",
    "            RandSpatialCrop((11, 96, 96), random_size=False),\n",
    "            RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"SRA\")\n",
    "        ]\n",
    "    )\n",
    "    val_imtrans = Compose([ScaleIntensity(), EnsureChannelFirst()])\n",
    "    val_segtrans = Compose([EnsureChannelFirst()])\n",
    "\n",
    "    # define image dataset, data loader\n",
    "    check_ds = ImageDataset(train_imgs, train_labels, transform=train_imtrans, seg_transform=train_segtrans)\n",
    "    check_loader = DataLoader(check_ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "    im, seg = monai.utils.misc.first(check_loader)\n",
    "    print(im.shape, seg.shape)\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = ImageDataset(train_imgs, train_labels, transform=train_imtrans, seg_transform=train_segtrans)\n",
    "    train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "    # create a validation data loader\n",
    "    val_ds = ImageDataset(val_imgs, val_labels, transform=val_imtrans, seg_transform=val_segtrans)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "    # create UNet, DiceLoss and Adam optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = monai.networks.nets.UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "    loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "    # start a typical PyTorch training\n",
    "    val_interval = 2\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(5):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{5}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_images = None\n",
    "                val_labels = None\n",
    "                val_outputs = None\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                    roi_size = (96, 96, 96)\n",
    "                    sw_batch_size = 4\n",
    "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                    val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                    # compute metric for current iteration\n",
    "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                # aggregate the final mean dice result\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                # reset the status for next validation round\n",
    "                dice_metric.reset()\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), \"best_metric_model_segmentation3d_array.pth\")\n",
    "                    print(\"saved new best metric model\")\n",
    "                print(\n",
    "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                    )\n",
    "                )\n",
    "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
