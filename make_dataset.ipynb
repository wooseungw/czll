{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_5_4/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_5_4/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_99_9/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_99_9/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_4/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_4/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_73_6/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_73_6/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_86_3/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_86_3/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_6_6/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_6_6/Picks/curation_0_thyroglobulin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/ribosome.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_ribosome.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/virus-like-particle.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_virus-like-particle.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/beta-galactosidase.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_beta-galactosidase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/beta-amylase.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_beta-amylase.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/apo-ferritin.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_apo-ferritin.json\n",
      "Copied ./kaggle/input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/TS_69_2/Picks/thyroglobulin.json to ./kaggle/working/overlay/ExperimentRuns/TS_69_2/Picks/curation_0_thyroglobulin.json\n"
     ]
    }
   ],
   "source": [
    "# Make a copick project\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "config_blob = \"\"\"{\n",
    "    \"name\": \"czii_cryoet_mlchallenge_2024\",\n",
    "    \"description\": \"2024 CZII CryoET ML Challenge training data.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "\n",
    "    \"pickable_objects\": [\n",
    "        {\n",
    "            \"name\": \"apo-ferritin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"4V1W\",\n",
    "            \"label\": 1,\n",
    "            \"color\": [  0, 117, 220, 128],\n",
    "            \"radius\": 60,\n",
    "            \"map_threshold\": 0.0418\n",
    "        },\n",
    "        {\n",
    "          \"name\" : \"beta-amylase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"8ZRZ\",\n",
    "            \"label\": 2,\n",
    "            \"color\": [255, 255, 255, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578  \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"beta-galactosidase\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6X1Q\",\n",
    "            \"label\": 3,\n",
    "            \"color\": [ 76,   0,  92, 128],\n",
    "            \"radius\": 90,\n",
    "            \"map_threshold\": 0.0578\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ribosome\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6EK0\",\n",
    "            \"label\": 4,\n",
    "            \"color\": [  0,  92,  49, 128],\n",
    "            \"radius\": 150,\n",
    "            \"map_threshold\": 0.0374\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"thyroglobulin\",\n",
    "            \"is_particle\": true,\n",
    "            \"pdb_id\": \"6SCJ\",\n",
    "            \"label\": 5,\n",
    "            \"color\": [ 43, 206,  72, 128],\n",
    "            \"radius\": 130,\n",
    "            \"map_threshold\": 0.0278\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"virus-like-particle\",\n",
    "            \"is_particle\": true,\n",
    "            \"label\": 6,\n",
    "            \"color\": [255, 204, 153, 128],\n",
    "            \"radius\": 135,\n",
    "            \"map_threshold\": 0.201\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"membrane\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 8,\n",
    "            \"color\": [100, 100, 100, 128]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"background\",\n",
    "            \"is_particle\": false,\n",
    "            \"label\": 9,\n",
    "            \"color\": [10, 150, 200, 128]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"overlay_root\": \"./kaggle/working/overlay\",\n",
    "\n",
    "    \"overlay_fs_args\": {\n",
    "        \"auto_mkdir\": true\n",
    "    },\n",
    "\n",
    "    \"static_root\": \"./kaggle/input/czii-cryo-et-object-identification/train/static\"\n",
    "}\"\"\"\n",
    "\n",
    "copick_config_path = \"./kaggle/working/copick.config\"\n",
    "output_overlay = \"./kaggle/working/overlay\"\n",
    "\n",
    "\n",
    "with open(copick_config_path, \"w\") as f:\n",
    "    f.write(config_blob)\n",
    "    \n",
    "# Update the overlay\n",
    "# Define source and destination directories\n",
    "source_dir = './kaggle/input/czii-cryo-et-object-identification/train/overlay'\n",
    "destination_dir = './kaggle/working/overlay'\n",
    "\n",
    "# Walk through the source directory\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    # Create corresponding subdirectories in the destination\n",
    "    relative_path = os.path.relpath(root, source_dir)\n",
    "    target_dir = os.path.join(destination_dir, relative_path)\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy and rename each file\n",
    "    for file in files:\n",
    "        if file.startswith(\"curation_0_\"):\n",
    "            new_filename = file\n",
    "        else:\n",
    "            new_filename = f\"curation_0_{file}\"\n",
    "            \n",
    "        \n",
    "        # Define full paths for the source and destination files\n",
    "        source_file = os.path.join(root, file)\n",
    "        destination_file = os.path.join(target_dir, new_filename)\n",
    "        \n",
    "        # Copy the file with the new name\n",
    "        shutil.copy2(source_file, destination_file)\n",
    "        print(f\"Copied {source_file} to {destination_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"denoised\" data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/vt4hj2ln3hs6c97_qllsy7lh0000gn/T/ipykernel_16865/192730300.py:5: DeprecationWarning: config_type not found in config file, defaulting to filesystem\n",
      "  root = copick.from_file(copick_config_path)\n"
     ]
    }
   ],
   "source": [
    "import copick\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = copick.from_file(copick_config_path)\n",
    "\n",
    "copick_user_name = \"copickUtils\"\n",
    "copick_segmentation_name = \"paintedPicks\"\n",
    "voxel_size = 10\n",
    "tomo_tpye_list = [\"ctfdeconvolved\",\"denoised\",\"isonetcorrected\",\"wbp\"]\n",
    "################# 1. Choose Type of Data #################\n",
    "tomo_type = tomo_tpye_list[1]\n",
    "print(f\"Processing \\\"{tomo_type}\\\" data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.31it/s]\n",
      "100%|██████████| 7/7 [00:01<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from copick_utils.segmentation import segmentation_from_picks\n",
    "from copick_utils.writers import write\n",
    "from collections import defaultdict\n",
    "\n",
    "# Just do this once\n",
    "generate_masks = True\n",
    "\n",
    "if generate_masks:\n",
    "    target_objects = defaultdict(dict)\n",
    "    for object in root.pickable_objects:\n",
    "        if object.is_particle:\n",
    "            target_objects[object.name]['label'] = object.label\n",
    "            target_objects[object.name]['radius'] = object.radius\n",
    "\n",
    "\n",
    "    for run in tqdm(root.runs):\n",
    "        tomo = run.get_voxel_spacing(10)\n",
    "        tomo = tomo.get_tomogram(tomo_type).numpy()\n",
    "        target = np.zeros(tomo.shape, dtype=np.uint8)\n",
    "        for pickable_object in root.pickable_objects:\n",
    "            pick = run.get_picks(object_name=pickable_object.name, user_id=\"curation\")\n",
    "            if len(pick):  \n",
    "                target = segmentation_from_picks.from_picks(pick[0], \n",
    "                                                            target, \n",
    "                                                            target_objects[pickable_object.name]['radius'] * 0.8, # 3d Mask Size = Radius in mask\n",
    "                                                            target_objects[pickable_object.name]['label'] # label_value\n",
    "                                                            )\n",
    "        write.segmentation(run, target, copick_user_name, name=copick_segmentation_name)\n",
    "\n",
    "data_dicts = []\n",
    "for run in tqdm(root.runs):\n",
    "    tomogram = run.get_voxel_spacing(voxel_size).get_tomogram(tomo_type).numpy()\n",
    "    segmentation = run.get_segmentations(name=copick_segmentation_name, user_id=copick_user_name, voxel_size=voxel_size, is_multilabel=True)[0].numpy()\n",
    "    data_dicts.append({\"image\": tomogram, \"label\": segmentation})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved volume 0 to train dataset\n",
      "Saved volume 1 to train dataset\n",
      "Saved volume 2 to train dataset\n",
      "Saved volume 3 to train dataset\n",
      "Saved volume 4 to train dataset\n",
      "Saved volume 5 to train dataset\n",
      "Saved volume 6 to test dataset\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def convert_polygon_to_yolo(label):\n",
    "    \"\"\"\n",
    "    3D 세그멘테이션 마스크의 모든 슬라이스의 폴리곤을 YOLO 포맷으로 변환\n",
    "    \"\"\"\n",
    "    D, H, W = label.shape\n",
    "    all_slice_labels = {}\n",
    "    \n",
    "    # 각 슬라이스에 대해 처리\n",
    "    for slice_idx in range(D):\n",
    "        yolo_labels = []\n",
    "        \n",
    "        # 각 unique 라벨에 대해 처리\n",
    "        for label_val in np.unique(label[slice_idx]):\n",
    "            if label_val == 0:  # 배경 무시\n",
    "                continue\n",
    "                \n",
    "            # 현재 라벨에 대한 이진 마스크 생성\n",
    "            binary_mask = (label[slice_idx] == label_val)\n",
    "            \n",
    "            # 폴리곤 찾기\n",
    "            contours = measure.find_contours(binary_mask, 0.5)\n",
    "            \n",
    "            # 각 컨투어에 대해\n",
    "            for contour in contours:\n",
    "                # 폴리곤 포인트 정규화\n",
    "                points_y = contour[:, 0] / H\n",
    "                points_x = contour[:, 1] / W\n",
    "                \n",
    "                # class와 좌표들을 하나의 문자열로 결합\n",
    "                coords = []\n",
    "                for x, y in zip(points_x, points_y):\n",
    "                    coords.extend([f\"{x:.6f}\", f\"{y:.6f}\"])\n",
    "                \n",
    "                label_str = f\"{int(label_val)-1} {' '.join(coords)}\"\n",
    "                yolo_labels.append(label_str)\n",
    "        \n",
    "        if yolo_labels:  # 라벨이 있는 경우만 저장\n",
    "            all_slice_labels[slice_idx] = yolo_labels\n",
    "    \n",
    "    return all_slice_labels\n",
    "\n",
    "# 데이터셋 디렉토리 생성\n",
    "train_label_dir = Path('./datasets/labels/train')\n",
    "train_image_dir = Path('./datasets/images/train')\n",
    "test_label_dir = Path('./datasets/labels/val')\n",
    "test_image_dir = Path('./datasets/images/val')\n",
    "\n",
    "for dir_path in [train_label_dir, train_image_dir, test_label_dir, test_image_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 각 볼륨에 대해 처리\n",
    "for vol_idx, data in enumerate(data_dicts):\n",
    "    img = data[\"image\"]\n",
    "    labels_dict = convert_polygon_to_yolo(data[\"label\"])\n",
    "    \n",
    "    # 마지막 볼륨인지 확인\n",
    "    is_test = (vol_idx == len(data_dicts) - 1)\n",
    "    \n",
    "    # 저장 경로 설정\n",
    "    label_dir = test_label_dir if is_test else train_label_dir\n",
    "    image_dir = test_image_dir if is_test else train_image_dir\n",
    "    \n",
    "    # 각 슬라이스에 대해 라벨과 이미지 파일 저장\n",
    "    for slice_idx, labels in labels_dict.items():\n",
    "        # 파일명 생성\n",
    "        base_filename = f\"image_{vol_idx:01d}_{slice_idx:03d}\"\n",
    "        \n",
    "        # 라벨 저장\n",
    "        with open(label_dir / f\"{base_filename}.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(labels))\n",
    "        \n",
    "        # 이미지 정규화 및 저장\n",
    "        slice_img = img[slice_idx]\n",
    "        norm_img = ((slice_img - slice_img.min()) / (slice_img.max() - slice_img.min()) * 255).astype(np.uint8)\n",
    "        plt.imsave(image_dir / f\"{base_filename}.png\", norm_img, cmap='gray')\n",
    "\n",
    "    # 저장 정보 출력\n",
    "    dataset_type = \"test\" if is_test else \"train\"\n",
    "    print(f\"Saved volume {vol_idx} to {dataset_type} dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset/data.yaml with classes: ['apo-ferritin', 'beta-amylase', 'beta-galactosidase', 'ribosome', 'thyroglobulin', 'virus-like-particle']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# JSON 문자열 파싱\n",
    "config = json.loads(config_blob)\n",
    "pickable_objects = config[\"pickable_objects\"]\n",
    "\n",
    "# 클래스 이름 추출 (is_particle=true인 객체만)\n",
    "classes = [obj[\"name\"] for obj in pickable_objects if obj.get(\"is_particle\", False)]\n",
    "\n",
    "# yaml 파일 내용 생성\n",
    "yaml_content = f\"\"\"\n",
    "path: ./  # dataset root dir\n",
    "train: images/train  # train images\n",
    "val: images/val  # val images\n",
    "test:  # test images (optional)\n",
    "\n",
    "# Classes\n",
    "names:\\n{chr(10).join(f'  {i}: {name}' for i, name in enumerate(classes))}\n",
    "\n",
    "# Download script/URL (optional)\n",
    "download: False\n",
    "\"\"\"\n",
    "\n",
    "# yaml 파일 저장\n",
    "dataset_dir = Path('./')\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "with open(dataset_dir / 'data.yaml', 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"Created dataset/data.yaml with classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import numpy as np\n",
    "\n",
    "def visualize_polygons(image, label, slice_idx=100):\n",
    "    # 이미지 정규화\n",
    "    img_norm = (image[slice_idx] - image[slice_idx].min()) / (image[slice_idx].max() - image[slice_idx].min())\n",
    "    \n",
    "    # 시각화\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 원본 이미지\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Normalized Tomogram')\n",
    "    plt.imshow(img_norm, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 세그멘테이션 마스크\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Segmentation Mask')\n",
    "    label_norm = label[slice_idx].astype(float) / label[slice_idx].max()\n",
    "    mask = plt.imshow(label_norm, cmap='viridis')\n",
    "    plt.colorbar(mask, label='Normalized Label Values')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 폴리곤 오버레이\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Polygon Overlay')\n",
    "    plt.imshow(img_norm, cmap='gray')\n",
    "    \n",
    "    # 각 라벨에 대해 폴리곤 추출\n",
    "    unique_labels = np.unique(label[slice_idx])\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    for label_val, color in zip(unique_labels[unique_labels > 0], colors):\n",
    "        # 현재 라벨에 대한 이진 마스크 생성\n",
    "        binary_mask = (label[slice_idx] == label_val)\n",
    "        \n",
    "        # 폴리곤 찾기\n",
    "        contours = measure.find_contours(binary_mask, 0.5)\n",
    "        \n",
    "        # 폴리곤 그리기\n",
    "        for contour in contours:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], color=color, linewidth=2, \n",
    "                    label=f'Label {label_val}')\n",
    "    \n",
    "    # plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 데이터셋의 각 샘플에 대해 시각화\n",
    "for i in range(len(data_dicts)):\n",
    "    print(f\"\\nSample {i}\")\n",
    "    print(f\"Unique labels: {np.unique(data_dicts[i]['label'])}\")\n",
    "    visualize_polygons(data_dicts[i]['image'], data_dicts[i]['label'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
